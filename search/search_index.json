{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NetGraph","text":"<p>NetGraph is a scenario-based network modeling and analysis library in Python. Define topology, failure policies, traffic demands, and workflows in one YAML file; run it programmatically or via CLI; inspect results and iterate.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation Guide - Python package installation</li> <li>Quickstart - Run scenarios (CLI) and minimal code</li> </ul>"},{"location":"#examples","title":"Examples","text":"<ul> <li>Bundled Scenarios - Ready-to-run scenarios (<code>square_mesh</code>, <code>backbone_clos</code>, <code>nsfnet</code>)</li> <li>Basic Example - A simple graph example</li> <li>Clos Fabric Analysis - Analyze a 3-tier Clos network</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Design - Architecture, model, algorithms, and workflow</li> <li>DSL Reference - YAML syntax guide</li> <li>Workflow Reference - Analysis workflow configuration</li> <li>CLI Reference - Command line interface</li> <li>Schema Reference - JSON Schema and validation</li> <li>API Reference - Python API documentation</li> <li>Auto-Generated API Reference - Complete API docs</li> </ul>"},{"location":"examples/basic/","title":"Basic Example","text":"<p>This example builds a tiny topology inline to show APIs. For real analysis, prefer running a provided scenario and generating metrics via the CLI.</p> <p>See Quickstart for CLI usage and bundled scenarios.</p>"},{"location":"examples/basic/#creating-a-simple-network","title":"Creating a Simple Network","text":"<p>Network Topology:</p> <pre><code>             [1,1] &amp; [1,2]     [1,1] &amp; [1,2]\n      A \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 B \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 C\n      \u2502                                      \u2502\n      \u2502    [2,3]                             \u2502 [2,3]\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 D \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n[1,1] and [1,2] are parallel edges between A and B.\nThey have the same metric of 1 but different capacities (1 and 2).\n</code></pre> <p>Let's create this network by using NetGraph's scenario system:</p> <pre><code>from ngraph.scenario import Scenario\nfrom ngraph.algorithms.base import FlowPlacement\n\n# Define network topology with parallel paths\nscenario_yaml = \"\"\"\nseed: 1234  # Optional: ensures reproducible results\n\nnetwork:\n  name: \"fundamentals_example\"\n\n  # Create individual nodes\n  nodes:\n    A: {}\n    B: {}\n    C: {}\n    D: {}\n\n  # Create links with different capacities and costs\n  links:\n    # Parallel edges between A\u2192B\n    - source: A\n      target: B\n      link_params:\n        capacity: 1\n        cost: 1\n    - source: A\n      target: B\n      link_params:\n        capacity: 2\n        cost: 1\n\n    # Parallel edges between B\u2192C\n    - source: B\n      target: C\n      link_params:\n        capacity: 1\n        cost: 1\n    - source: B\n      target: C\n      link_params:\n        capacity: 2\n        cost: 1\n\n    # Alternative path A\u2192D\u2192C\n    - source: A\n      target: D\n      link_params:\n        capacity: 3\n        cost: 2\n    - source: D\n      target: C\n      link_params:\n        capacity: 3\n        cost: 2\n\"\"\"\n\n# Create the network\nscenario = Scenario.from_yaml(scenario_yaml)\nnetwork = scenario.network\n</code></pre> <p>Note that here we used a simple <code>nodes</code> and <code>links</code> structure to directly define the network topology. The optional <code>seed</code> parameter ensures reproducible results when using randomized workflow steps. In more complex scenarios, you would typically use <code>groups</code> and <code>adjacency</code> to define groups of nodes and their connections, or even leverage the <code>blueprints</code> to create reusable components. This advanced functionality is explained in the DSL Reference and used in the Clos Fabric Analysis example.</p>"},{"location":"examples/basic/#flow-analysis-variants","title":"Flow Analysis Variants","text":"<p>Now let's run MaxFlow using the high-level Network API:</p> <pre><code># 1. \"True\" maximum flow (uses all available paths)\nmax_flow_all = network.max_flow(source_path=\"A\", sink_path=\"C\")\nprint(f\"Maximum flow (all paths): {max_flow_all}\")\n# Result: 6.0 (uses both A\u2192B\u2192C path capacity of 3 and A\u2192D\u2192C path capacity of 3)\n\n# 2. Flow along shortest paths only\nmax_flow_shortest = network.max_flow(\n    source_path=\"A\",\n    sink_path=\"C\",\n    shortest_path=True\n)\nprint(f\"Flow on shortest paths: {max_flow_shortest}\")\n# Result: 3.0 (only uses A\u2192B\u2192C path, ignoring higher-cost A\u2192D\u2192C path)\n\n# 3. Equal-balanced flow placement on shortest paths\nmax_flow_shortest_balanced = network.max_flow(\n    source_path=\"A\",\n    sink_path=\"C\",\n    shortest_path=True,\n    flow_placement=FlowPlacement.EQUAL_BALANCED\n)\nprint(f\"Equal-balanced flow: {max_flow_shortest_balanced}\")\n# Result: 2.0 (splits flow equally across parallel edges in A\u2192B and B\u2192C)\n</code></pre>"},{"location":"examples/basic/#results-interpretation","title":"Results Interpretation","text":"<ul> <li>\"True\" MaxFlow: Uses all available paths regardless of their cost</li> <li>Shortest Path: Only uses paths with the minimum cost</li> <li>EQUAL_BALANCED Flow Placement: Distributes flows equally across all parallel paths. The total flow can be limited by the smallest capacity path.</li> </ul> <p>Note that <code>EQUAL_BALANCED</code> flow placement is only applicable when calculating MaxFlow on shortest paths.</p>"},{"location":"examples/basic/#cost-distribution-concise","title":"Cost Distribution (concise)","text":"<p>Cost distribution shows how flow splits across path costs for latency/span analysis.</p> <pre><code># Get flow analysis with cost distribution\nresult = network.max_flow_with_summary(\n    source_path=\"A\",\n    sink_path=\"C\",\n    mode=\"combine\"\n)\n\n# Extract flow value and summary\n(src_label, sink_label), (flow_value, summary) = next(iter(result.items()))\n\nprint(f\"Total flow: {flow_value}\")\nprint(f\"Cost distribution: {summary.cost_distribution}\")\n\n# Example output:\n# Total flow: 6.0\n# Cost distribution: {2.0: 3.0, 4.0: 3.0}\n#\n# This means:\n# - 3.0 units of flow use paths with total cost 2.0 (A\u2192B\u2192C path)\n# - 3.0 units of flow use paths with total cost 4.0 (A\u2192D\u2192C path)\n</code></pre>"},{"location":"examples/basic/#latency-span-optional","title":"Latency Span (optional)","text":"<p>If link costs approximate latency, you can derive a quick span summary:</p> <pre><code>def analyze_latency_span(cost_distribution):\n    \"\"\"Analyze latency characteristics from cost distribution.\"\"\"\n    if not cost_distribution:\n        return \"No flow paths available\"\n\n    total_flow = sum(cost_distribution.values())\n    weighted_avg_latency = sum(cost * flow for cost, flow in cost_distribution.items()) / total_flow\n\n    min_latency = min(cost_distribution.keys())\n    max_latency = max(cost_distribution.keys())\n    latency_span = max_latency - min_latency\n\n    print(f\"Latency Analysis:\")\n    print(f\"  Average latency: {weighted_avg_latency:.2f}\")\n    print(f\"  Latency range: {min_latency:.1f} - {max_latency:.1f}\")\n    print(f\"  Latency span: {latency_span:.1f}\")\n    print(f\"  Flow distribution:\")\n    for cost, flow in sorted(cost_distribution.items()):\n        percentage = (flow / total_flow) * 100\n        print(f\"    {percentage:.1f}% of traffic uses paths with latency {cost:.1f}\")\n\n# Example usage\nanalyze_latency_span(summary.cost_distribution)\n</code></pre> <p>This helps identify traffic concentration, latency span, and potential bottlenecks.</p>"},{"location":"examples/basic/#advanced-analysis-sensitivity-analysis","title":"Advanced Analysis: Sensitivity Analysis","text":"<p>For network analysis, you can use the low-level graph algorithms to run sensitivity analysis and identify bottleneck edges:</p> <pre><code>from ngraph.algorithms.max_flow import calc_max_flow, saturated_edges, run_sensitivity\n\n# Get the underlying graph for low-level analysis\ngraph = network.to_strict_multidigraph()\n\n# Identify bottleneck (saturated) edges\nbottlenecks = saturated_edges(graph, \"A\", \"C\")\nprint(f\"Bottleneck edges: {bottlenecks}\")\n\n# Perform sensitivity analysis - test increasing capacity by 1 unit\nsensitivity_increase = run_sensitivity(graph, \"A\", \"C\", change_amount=1.0)\nprint(f\"Sensitivity to capacity increases: {sensitivity_increase}\")\n\n# Test sensitivity to capacity decreases\nsensitivity_decrease = run_sensitivity(graph, \"A\", \"C\", change_amount=-1.0)\nprint(f\"Sensitivity to capacity decreases: {sensitivity_decrease}\")\n</code></pre> <p>This analysis helps identify:</p> <ul> <li>Bottleneck edges: Links that are fully utilized and limit overall flow</li> <li>High-impact upgrades: Which capacity increases provide the most benefit</li> <li>Vulnerability assessment: How flow decreases when links are degraded</li> </ul>"},{"location":"examples/basic/#next-steps","title":"Next Steps","text":"<ul> <li>Bundled Scenarios - Ready-to-run examples</li> <li>Clos Fabric Analysis - More complex example</li> <li>Workflow Reference - Analysis workflows and Monte Carlo simulation</li> <li>DSL Reference - Learn the full YAML syntax for scenarios</li> <li>API Reference - Explore the Python API for advanced usage</li> </ul>"},{"location":"examples/bundled-scenarios/","title":"Bundled Scenarios","text":"<p>NetGraph ships with ready-to-run scenarios that demonstrate the DSL, workflow steps, and results export. Use these to validate your environment and as starting points for your own models.</p>"},{"location":"examples/bundled-scenarios/#how-to-run","title":"How to run","text":"<p>Inspect first, then run:</p> <pre><code># Inspect (structure, steps, matrices, failure policies)\nngraph inspect scenarios/backbone_clos.yml --detail\n\n# Run and write JSON results next to the scenario (or under --output)\nngraph run scenarios/backbone_clos.yml --output out\n</code></pre> <p>You can filter output by workflow step names with <code>--keys</code> (see each scenario section for step names).</p>"},{"location":"examples/bundled-scenarios/#scenariossquare_meshyaml","title":"<code>scenarios/square_mesh.yaml</code>","text":"<ul> <li>Purpose: Toy 4-node full mesh to exercise MSD search, TM placement, and pairwise MaxFlow.</li> <li> <p>Highlights:</p> </li> <li> <p>Failure policy: single link choice (<code>failure_policy_set.single_link_failure</code>)</p> </li> <li>Traffic matrix: pairwise demands across all nodes (<code>baseline_traffic_matrix</code>)</li> <li>Workflow steps: <code>msd_baseline</code>, <code>tm_placement</code>, <code>node_to_node_capacity_matrix</code></li> </ul> <p>Run:</p> <pre><code>ngraph inspect scenarios/square_mesh.yaml --detail\nngraph run scenarios/square_mesh.yaml --output out\n\n# Filter to MSD only and print to stdout\nngraph run scenarios/square_mesh.yaml --keys msd_baseline --stdout\n</code></pre>"},{"location":"examples/bundled-scenarios/#scenariosbackbone_closyml","title":"<code>scenarios/backbone_clos.yml</code>","text":"<ul> <li>Purpose: Small Clos/metro fabric with components, SRLG-like risk groups, and multi-step workflow.</li> <li> <p>Highlights:</p> </li> <li> <p>Uses <code>blueprints</code>, attribute-based adjacency selectors, and hardware component attrs</p> </li> <li>Failure policy: weighted multi-mode (<code>failure_policy_set.weighted_modes</code>)</li> <li>Traffic matrix: inter-metro DC flows with TE/WCMP policy</li> <li>Workflow steps: <code>network_statistics</code>, <code>msd_baseline</code>, <code>tm_placement</code>, <code>cost_power</code></li> </ul> <p>Run:</p> <pre><code>ngraph inspect scenarios/backbone_clos.yml --detail\nngraph run scenarios/backbone_clos.yml --output out\n\n# Export only selected steps\nngraph run scenarios/backbone_clos.yml --keys network_statistics tm_placement --results clos_filtered.json\n</code></pre>"},{"location":"examples/bundled-scenarios/#scenariosnsfnetyaml","title":"<code>scenarios/nsfnet.yaml</code>","text":"<ul> <li>Purpose: Historic NSFNET T3 (1992) backbone with parallel circuits and SRLG-style risk groups.</li> <li> <p>Highlights:</p> </li> <li> <p>Explicit nodes/links with capacities and costs; rich <code>risk_groups</code></p> </li> <li>Failure policies: single-link and availability-based random failures</li> <li>Workflow steps: <code>node_to_node_capacity_matrix_1</code>, <code>node_to_node_capacity_matrix_2</code></li> </ul> <p>Run:</p> <pre><code>ngraph inspect scenarios/nsfnet.yaml --detail\nngraph run scenarios/nsfnet.yaml --output out\n\n# Filter to a specific matrix computation\nngraph run scenarios/nsfnet.yaml --keys node_to_node_capacity_matrix_1 --stdout\n</code></pre>"},{"location":"examples/bundled-scenarios/#notes-on-results","title":"Notes on results","text":"<p>All runs emit a consistent JSON shape with <code>workflow</code>, <code>steps</code>, and <code>scenario</code> sections. Steps like <code>MaxFlow</code> and <code>TrafficMatrixPlacement</code> store per-iteration lists under <code>data.flow_results</code> with <code>summary</code> and optional <code>cost_distribution</code> or <code>min_cut</code> fields. See Reference \u2192 Workflow for the exact schema.</p>"},{"location":"examples/clos-fabric/","title":"Clos Fabric Analysis","text":"<p>This example demonstrates analysis of a 3-tier Clos fabric. For production use, run the bundled scenario and generate metrics via CLI, then iterate in Python if needed.</p> <p>Refer to Quickstart for running bundled scenarios via CLI.</p>"},{"location":"examples/clos-fabric/#scenario-overview","title":"Scenario Overview","text":"<p>We'll create two separate 3-tier Clos networks and analyze the maximum flow capacity between them. This scenario showcases:</p> <ul> <li>Hierarchical blueprint composition</li> <li>Complex adjacency patterns</li> <li>Flow analysis with different placement policies</li> </ul>"},{"location":"examples/clos-fabric/#programmatic-scenario","title":"Programmatic scenario","text":"<pre><code>from ngraph.scenario import Scenario\nfrom ngraph.algorithms.base import FlowPlacement\n\nscenario_yaml = \"\"\"\nblueprints:\n  brick_2tier:\n    groups:\n      t1:\n        node_count: 8\n        name_template: t1-{node_num}\n      t2:\n        node_count: 8\n        name_template: t2-{node_num}\n\n    adjacency:\n      - source: /t1\n        target: /t2\n        pattern: mesh\n        link_params:\n          capacity: 2\n          cost: 1\n\n  3tier_clos:\n    groups:\n      b1:\n        use_blueprint: brick_2tier\n      b2:\n        use_blueprint: brick_2tier\n      spine:\n        node_count: 64\n        name_template: t3-{node_num}\n\n    adjacency:\n      - source: b1/t2\n        target: spine\n        pattern: one_to_one\n        link_params:\n          capacity: 2\n          cost: 1\n      - source: b2/t2\n        target: spine\n        pattern: one_to_one\n        link_params:\n          capacity: 2\n          cost: 1\n\nnetwork:\n  name: \"3tier_clos_network\"\n  version: 1.0\n\n  groups:\n    my_clos1:\n      use_blueprint: 3tier_clos\n\n    my_clos2:\n      use_blueprint: 3tier_clos\n\n  adjacency:\n    - source: my_clos1/spine\n      target: my_clos2/spine\n      pattern: one_to_one\n      link_count: 4\n      link_params:\n        capacity: 1\n        cost: 1\n\"\"\"\n\n# Create and analyze the scenario\nscenario = Scenario.from_yaml(scenario_yaml)\nnetwork = scenario.network\n\n# Calculate maximum flow with ECMP (Equal Cost Multi-Path)\nmax_flow_ecmp = network.max_flow(\n    source_path=r\"my_clos1.*(b[0-9]*)/t1\",\n    sink_path=r\"my_clos2.*(b[0-9]*)/t1\",\n    mode=\"combine\",\n    shortest_path=True,\n    flow_placement=FlowPlacement.EQUAL_BALANCED,\n)\n\nprint(f\"Maximum flow with ECMP: {max_flow_ecmp}\")\n# Result: {('b1|b2', 'b1|b2'): 256.0}\n</code></pre>"},{"location":"examples/clos-fabric/#understanding-the-results","title":"Understanding the Results","text":"<p>The result <code>{('b1|b2', 'b1|b2'): 256.0}</code> means:</p> <ul> <li>Source: All t1 nodes in both b1 and b2 segments of my_clos1</li> <li>Sink: All t1 nodes in both b1 and b2 segments of my_clos2</li> <li>Capacity: Maximum flow of 256.0 units</li> </ul>"},{"location":"examples/clos-fabric/#ecmp-vs-wcmp-impact-of-link-failures","title":"ECMP vs WCMP: Impact of Link Failures","text":"<p>NetGraph supports different flow placement policies:</p> <ul> <li><code>FlowPlacement.EQUAL_BALANCED</code>: Equal split across equal-cost paths</li> <li><code>FlowPlacement.PROPORTIONAL</code>: Capacity-weighted split across equal-cost paths</li> </ul> <p>Combined with the path selection settings (shortest_path=True|False), we can achieve different flow placement policies emulating ECMP, WCMP, and TE behavior in IP/MPLS networks.</p> <p>In this example, we use the <code>FlowPlacement.EQUAL_BALANCED</code> policy and <code>shortest_path=True</code> to emulate ECMP behavior and we will compare it with WCMP <code>FlowPlacement.PROPORTIONAL</code> (capacity-weighted split across equal-cost paths) under two conditions:</p> <ul> <li>Baseline: symmetric parallel inter-spine links \u2192 ECMP = WCMP (256.0).</li> <li>Uneven links: make capacities within each equal-cost bundle different \u2192 WCMP   achieves higher throughput than ECMP, which is limited by equal splitting.</li> </ul> <p>We emulate partial inter-spine degradation by making capacities uneven across the 4 parallel spine-to-spine links per pair while keeping equal costs. This isolates the effect of the splitting policy.</p> <pre><code>from ngraph.algorithms.base import FlowPlacement\nfrom ngraph.scenario import Scenario\n\nscenario_yaml = \"\"\"\nblueprints:\n  brick_2tier:\n    groups:\n      t1: {node_count: 8, name_template: t1-{node_num}}\n      t2: {node_count: 8, name_template: t2-{node_num}}\n    adjacency:\n      - {source: /t1, target: /t2, pattern: mesh, link_params: {capacity: 2, cost: 1}}\n  3tier_clos:\n    groups:\n      b1: {use_blueprint: brick_2tier}\n      b2: {use_blueprint: brick_2tier}\n      spine: {node_count: 64, name_template: t3-{node_num}}\n    adjacency:\n      - {source: b1/t2, target: spine, pattern: one_to_one, link_params: {capacity: 2, cost: 1}}\n      - {source: b2/t2, target: spine, pattern: one_to_one, link_params: {capacity: 2, cost: 1}}\nnetwork:\n  name: 3tier_clos_network\n  groups:\n    my_clos1: {use_blueprint: 3tier_clos}\n    my_clos2: {use_blueprint: 3tier_clos}\n  adjacency:\n    - {source: my_clos1/spine, target: my_clos2/spine, pattern: one_to_one, link_count: 4, link_params: {capacity: 1, cost: 1}}\n\"\"\"\n\nscenario = Scenario.from_yaml(scenario_yaml)\nnetwork = scenario.network\n\n# Baseline (symmetric)\nbaseline_ecmp = network.max_flow(\n    source_path=r\"my_clos1.*(b[0-9]*)/t1\",\n    sink_path=r\"my_clos2.*(b[0-9]*)/t1\",\n    mode=\"combine\", shortest_path=True,\n    flow_placement=FlowPlacement.EQUAL_BALANCED,\n)\nbaseline_wcmp = network.max_flow(\n    source_path=r\"my_clos1.*(b[0-9]*)/t1\",\n    sink_path=r\"my_clos2.*(b[0-9]*)/t1\",\n    mode=\"combine\", shortest_path=True,\n    flow_placement=FlowPlacement.PROPORTIONAL,\n)\n\n# Make parallel inter-spine links uneven (keeps equal cost)\nfrom collections import defaultdict\ngroups = defaultdict(list)\nfor lk in network.links.values():\n    s, t = lk.source, lk.target\n    if (s.startswith(\"my_clos1/spine\") and t.startswith(\"my_clos2/spine\")) or \\\n       (s.startswith(\"my_clos2/spine\") and t.startswith(\"my_clos1/spine\")):\n        groups[(s, t)].append(lk)\nfor i, key in enumerate(sorted(groups.keys())):\n    links = sorted(groups[key], key=lambda x: (x.source, x.target, id(x)))\n    caps = [4.0, 0.25, 0.25, 0.25] if i % 2 == 0 else [2.0, 1.0, 0.5, 0.25]\n    for lk, cap in zip(links, caps):\n        lk.capacity = cap\n\necmp = network.max_flow(\n    source_path=r\"my_clos1.*(b[0-9]*)/t1\",\n    sink_path=r\"my_clos2.*(b[0-9]*)/t1\",\n    mode=\"combine\", shortest_path=True,\n    flow_placement=FlowPlacement.EQUAL_BALANCED,\n)\nwcmp = network.max_flow(\n    source_path=r\"my_clos1.*(b[0-9]*)/t1\",\n    sink_path=r\"my_clos2.*(b[0-9]*)/t1\",\n    mode=\"combine\", shortest_path=True,\n    flow_placement=FlowPlacement.PROPORTIONAL,\n)\nprint(\"Baseline ECMP:\", baseline_ecmp)\nprint(\"Baseline WCMP:\", baseline_wcmp)\nprint(\"Uneven ECMP:\", ecmp)\nprint(\"Uneven WCMP:\", wcmp)\n</code></pre> <p>Example output:</p> <pre><code>Baseline ECMP: {('b1|b2', 'b1|b2'): 256.0}\nBaseline WCMP: {('b1|b2', 'b1|b2'): 256.0}\nUneven ECMP: {('b1|b2', 'b1|b2'): 64.0}\nUneven WCMP: {('b1|b2', 'b1|b2'): 248.0}\n</code></pre> <p>As expected, WCMP achieves higher throughput than ECMP when parallel links within equal-cost bundles have uneven capacities. ECMP is limited by the link with the lowest capacity in the equal-cost group.</p>"},{"location":"examples/clos-fabric/#network-structure-analysis","title":"Network Structure Analysis","text":"<p>We can also analyze the network structure to understand the flow distribution.</p> <pre><code>from ngraph.explorer import NetworkExplorer\n\n# Explore the network topology\nexplorer = NetworkExplorer.explore_network(network)\nexplorer.print_tree(skip_leaves=True, detailed=False)\n\n# Analyze specific paths between border nodes\nfrom ngraph.algorithms.spf import spf\nfrom ngraph.algorithms.paths import resolve_to_paths\n\n# Get border nodes from different segments\nborder_nodes = [node for node in network.nodes.values() if '/b1/t1' in node.name or '/b2/t1' in node.name]\nsrc_node = next(node.name for node in border_nodes if \"my_clos1/b1/t1\" in node.name)\ndst_node = next(node.name for node in border_nodes if \"my_clos2/b1/t1\" in node.name)\n\n# Find shortest paths using SPF\ncosts, pred = spf(network.to_strict_multidigraph(), src_node)\npaths = list(resolve_to_paths(src_node, dst_node, pred))\nprint(f\"Found {len(paths)} paths between segments\")\n</code></pre>"},{"location":"examples/clos-fabric/#next-steps","title":"Next Steps","text":"<ul> <li>Bundled Scenarios - Ready-to-run examples</li> <li>Workflow Reference - Analysis workflows and Monte Carlo simulation</li> <li>DSL Reference - YAML syntax reference</li> <li>API Reference - Explore the Python API in detail</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Use NetGraph as a Python package in your environment.</p>"},{"location":"getting-started/installation/#using-the-python-package","title":"Using the Python Package","text":"<ul> <li>Requires Python 3.11 or higher. Use a virtual environment (<code>python -m venv .venv &amp;&amp; source .venv/bin/activate</code>).</li> </ul> <pre><code>pip install ngraph\n</code></pre> <p>Verify installation:</p> <pre><code>ngraph --help\n</code></pre> <p>Next: see Quickstart for running scenarios and minimal programmatic usage.</p>"},{"location":"getting-started/tutorial/","title":"Quickstart","text":"<p>This guide shows the fastest way to run a scenario from the CLI and a minimal programmatic example. Use examples for detailed scenarios and policies.</p>"},{"location":"getting-started/tutorial/#cli-run-and-inspect","title":"CLI: run and inspect","text":"<pre><code># Inspect (validate and preview structure, steps, matrices)\nngraph inspect scenarios/square_mesh.yaml --detail\n\n# Run and store results (JSON) next to the scenario or under --output\nngraph run scenarios/square_mesh.yaml --output out\n\n# Filter exported results by workflow step names\nngraph run scenarios/square_mesh.yaml --keys msd_baseline --stdout\n</code></pre> <p>See also: <code>scenarios/backbone_clos.yml</code> and <code>scenarios/nsfnet.yaml</code>.</p>"},{"location":"getting-started/tutorial/#programmatic-minimal-example","title":"Programmatic: minimal example","text":"<pre><code>from ngraph.scenario import Scenario\n\nscenario_yaml = \"\"\"\nnetwork:\n  nodes:\n    A: {}\n    B: {}\n  links:\n    - {source: A, target: B, link_params: {capacity: 10.0, cost: 1.0}}\nworkflow:\n  - step_type: NetworkStats\n    name: baseline_stats\n\"\"\"\n\nscenario = Scenario.from_yaml(scenario_yaml)\nscenario.run()\n\nexported = scenario.results.to_dict()\nprint(list(exported[\"steps\"].keys()))\n</code></pre>"},{"location":"getting-started/tutorial/#results-shape-high-level","title":"Results shape (high level)","text":"<p>Results are exported as a fixed shape with <code>workflow</code>, <code>steps</code>, and <code>scenario</code>. Steps such as <code>MaxFlow</code>, <code>TrafficMatrixPlacement</code>, and <code>MaximumSupportedDemand</code> write under their step name. See Reference \u2192 Workflow for exact fields.</p>"},{"location":"getting-started/tutorial/#next-steps","title":"Next steps","text":"<ul> <li>Examples \u2192 Bundled Scenarios</li> <li>Reference \u2192 DSL, Workflow, CLI</li> </ul>"},{"location":"reference/api-full/","title":"API Full","text":""},{"location":"reference/api-full/#netgraph-api-reference-auto-generated","title":"NetGraph API Reference (Auto-Generated)","text":"<p>This is the complete auto-generated API documentation for NetGraph. For a curated, example-driven API guide, see api.md.</p> <p>Quick links:</p> <ul> <li>Main API Guide (api.md)</li> <li>This Document (api-full.md)</li> <li>CLI Reference</li> <li>DSL Reference</li> </ul> <p>Generated from source code on: September 06, 2025 at 23:54 UTC</p> <p>Modules auto-discovered: 61</p>"},{"location":"reference/api-full/#ngraphcli","title":"ngraph.cli","text":"<p>Command-line interface for NetGraph.</p>"},{"location":"reference/api-full/#mainargv-optionalliststr-none-none","title":"main(argv: 'Optional[List[str]]' = None) -&gt; 'None'","text":"<p>Entry point for the <code>ngraph</code> command.</p> <p>Args:     argv: Optional list of command-line arguments. If <code>None</code>, <code>sys.argv</code>         is used.</p>"},{"location":"reference/api-full/#ngraphcomponents","title":"ngraph.components","text":"<p>Component and ComponentsLibrary classes for hardware capex/power modeling.</p>"},{"location":"reference/api-full/#component","title":"Component","text":"<p>A generic component that can represent chassis, line cards, optics, etc. Components can have nested children, each with their own capex, power, etc.</p> <p>Attributes:     name (str): Name of the component (e.g., \"SpineChassis\" or \"400G-LR4\").     component_type (str): A string label (e.g., \"chassis\", \"linecard\", \"optic\").     description (str): A human-readable description of this component.     capex (float): Monetary capex of a single instance of this component.     power_watts (float): Typical/nominal power usage (watts) for one instance.     power_watts_max (float): Maximum/peak power usage (watts) for one instance.     capacity (float): A generic capacity measure (e.g., platform capacity).     ports (int): Number of ports if relevant for this component.     count (int): How many identical copies of this component are present.     attrs (Dict[str, Any]): Arbitrary key-value attributes for extra metadata.     children (Dict[str, Component]): Nested child components (e.g., line cards         inside a chassis), keyed by child name.</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>component_type</code> (str) = generic</li> <li><code>description</code> (str)</li> <li><code>capex</code> (float) = 0.0</li> <li><code>power_watts</code> (float) = 0.0</li> <li><code>power_watts_max</code> (float) = 0.0</li> <li><code>capacity</code> (float) = 0.0</li> <li><code>ports</code> (int) = 0</li> <li><code>count</code> (int) = 1</li> <li><code>attrs</code> (Dict[str, Any]) = {}</li> <li><code>children</code> (Dict[str, Component]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>as_dict(self, include_children: 'bool' = True) -&gt; 'Dict[str, Any]'</code> - Returns a dictionary containing all properties of this component.</li> <li><code>total_capacity(self) -&gt; 'float'</code> - Computes the total (recursive) capacity of this component,</li> <li><code>total_capex(self) -&gt; 'float'</code> - Computes total capex including children, multiplied by count.</li> <li><code>total_power(self) -&gt; 'float'</code> - Computes the total typical (recursive) power usage of this component,</li> <li><code>total_power_max(self) -&gt; 'float'</code> - Computes the total peak (recursive) power usage of this component,</li> </ul>"},{"location":"reference/api-full/#componentslibrary","title":"ComponentsLibrary","text":"<p>Holds a collection of named Components. Each entry is a top-level \"template\" that can be referenced for cost/power/capacity lookups, possibly with nested children.</p> <p>Example (YAML-like):     components:       BigSwitch:         component_type: chassis         cost: 20000         power_watts: 1750         capacity: 25600         children:           PIM16Q-16x200G:             component_type: linecard             cost: 1000             power_watts: 10             ports: 16             count: 8       200G-FR4:         component_type: optic         cost: 2000         power_watts: 6         power_watts_max: 6.5</p> <p>Attributes:</p> <ul> <li><code>components</code> (Dict[str, Component]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>clone(self) -&gt; 'ComponentsLibrary'</code> - Creates a deep copy of this ComponentsLibrary.</li> <li><code>from_dict(data: 'Dict[str, Any]') -&gt; 'ComponentsLibrary'</code> - Constructs a ComponentsLibrary from a dictionary of raw component definitions.</li> <li><code>from_yaml(yaml_str: 'str') -&gt; 'ComponentsLibrary'</code> - Constructs a ComponentsLibrary from a YAML string. If the YAML contains</li> <li><code>get(self, name: 'str') -&gt; 'Optional[Component]'</code> - Retrieves a Component by its name from the library.</li> <li><code>merge(self, other: 'ComponentsLibrary', override: 'bool' = True) -&gt; 'ComponentsLibrary'</code> - Merges another ComponentsLibrary into this one. By default (override=True),</li> </ul>"},{"location":"reference/api-full/#resolve_link_end_componentsattrs-dictstr-any-library-componentslibrary-tupletupleoptionalcomponent-float-bool-tupleoptionalcomponent-float-bool-bool","title":"resolve_link_end_components(attrs: 'Dict[str, Any]', library: 'ComponentsLibrary') -&gt; 'tuple[tuple[Optional[Component], float, bool], tuple[Optional[Component], float, bool], bool]'","text":"<p>Resolve per-end hardware components for a link.</p> <p>Input format inside <code>link.attrs</code>:</p> <p>Structured mapping under <code>hardware</code> key only:   <code>{\"hardware\": {\"source\": {\"component\": NAME, \"count\": N},                    \"target\": {\"component\": NAME, \"count\": N}}}</code></p> <p>Args:     attrs: Link attributes mapping.     library: Components library for lookups.</p> <p>Exclusive usage:</p> <ul> <li> <p>Optional <code>exclusive: true</code> per end indicates unsharable usage.</p> <p>For exclusive ends, validation and BOM counting should round-up counts to integers.</p> </li> </ul> <p>Returns:     ((src_comp, src_count, src_exclusive), (dst_comp, dst_count, dst_exclusive), per_end_specified)     where components may be <code>None</code> if name is absent/unknown. <code>per_end_specified</code>     is True when a structured per-end mapping is present.</p>"},{"location":"reference/api-full/#resolve_node_hardwareattrs-dictstr-any-library-componentslibrary-tupleoptionalcomponent-float","title":"resolve_node_hardware(attrs: 'Dict[str, Any]', library: 'ComponentsLibrary') -&gt; 'Tuple[Optional[Component], float]'","text":"<p>Resolve node hardware from <code>attrs['hardware']</code>.</p> <p>Expects the mapping: <code>{\"hardware\": {\"component\": NAME, \"count\": N}}</code>. <code>count</code> defaults to 1 if missing or invalid. If <code>component</code> is missing or unknown, returns <code>(None, 1.0)</code>.</p> <p>Args:     attrs: Node attributes mapping.     library: Component library used for lookups.</p> <p>Returns:     Tuple of (component or None, positive multiplier).</p>"},{"location":"reference/api-full/#totals_with_multipliercomp-component-hw_count-float-tuplefloat-float-float","title":"totals_with_multiplier(comp: 'Component', hw_count: 'float') -&gt; 'Tuple[float, float, float]'","text":"<p>Return (capex, power_watts, capacity) totals multiplied by <code>hw_count</code>.</p> <p>Args:     comp: Component definition (may include nested children and internal <code>count</code>).     hw_count: External multiplier (e.g., number of modules used for a link or node).</p> <p>Returns:     Tuple of total capex, total power (typical), and total capacity as floats.</p>"},{"location":"reference/api-full/#ngraphconfig","title":"ngraph.config","text":"<p>Configuration classes for NetGraph components.</p>"},{"location":"reference/api-full/#trafficmanagerconfig","title":"TrafficManagerConfig","text":"<p>Configuration for traffic demand placement estimation.</p> <p>Attributes:</p> <ul> <li><code>default_rounds</code> (int) = 5</li> <li><code>min_rounds</code> (int) = 5</li> <li><code>max_rounds</code> (int) = 100</li> <li><code>ratio_base</code> (int) = 5</li> <li><code>ratio_multiplier</code> (int) = 5</li> </ul> <p>Methods:</p> <ul> <li><code>estimate_rounds(self, demand_capacity_ratio: float) -&gt; int</code> - Calculate placement rounds based on demand to capacity ratio.</li> </ul>"},{"location":"reference/api-full/#ngraphexplorer","title":"ngraph.explorer","text":"<p>NetworkExplorer class for analyzing network hierarchy and structure.</p>"},{"location":"reference/api-full/#externallinkbreakdown","title":"ExternalLinkBreakdown","text":"<p>Holds stats for external links to a particular other subtree.</p> <p>Attributes:     link_count (int): Number of links to that other subtree.     link_capacity (float): Sum of capacities for those links.</p> <p>Attributes:</p> <ul> <li><code>link_count</code> (int) = 0</li> <li><code>link_capacity</code> (float) = 0.0</li> </ul>"},{"location":"reference/api-full/#linkcapacityissue","title":"LinkCapacityIssue","text":"<p>Represents a link capacity constraint violation in active topology.</p> <p>Attributes:     source: Source node name.     target: Target node name.     capacity: Configured link capacity.     limit: Effective capacity limit from per-end hardware (min of ends).     reason: Brief reason tag.</p> <p>Attributes:</p> <ul> <li><code>source</code> (str)</li> <li><code>target</code> (str)</li> <li><code>capacity</code> (float)</li> <li><code>limit</code> (float)</li> <li><code>reason</code> (str)</li> </ul>"},{"location":"reference/api-full/#networkexplorer","title":"NetworkExplorer","text":"<p>Provides hierarchical exploration of a Network, computing statistics in two modes: 'all' (ignores disabled) and 'active' (only enabled).</p> <p>Methods:</p> <ul> <li><code>explore_network(network: 'Network', components_library: 'Optional[ComponentsLibrary]' = None, strict_validation: 'bool' = True) -&gt; 'NetworkExplorer'</code> - Build a NetworkExplorer, constructing a tree plus 'all' and 'active' stats.</li> <li><code>get_bom(self, include_disabled: 'bool' = True) -&gt; 'Dict[str, float]'</code> - Return aggregated hardware BOM for the whole network.</li> <li><code>get_bom_by_path(self, path: 'str', include_disabled: 'bool' = True) -&gt; 'Dict[str, float]'</code> - Return the hardware BOM for a specific hierarchy path.</li> <li><code>get_bom_map(self, include_disabled: 'bool' = True, include_root: 'bool' = True, root_label: 'str' = '') -&gt; 'Dict[str, Dict[str, float]]'</code> - Return a mapping from hierarchy path to BOM for each subtree.</li> <li><code>get_link_issues(self) -&gt; 'List[LinkCapacityIssue]'</code> - Return recorded link capacity issues discovered in non-strict mode.</li> <li><code>get_node_utilization(self, include_disabled: 'bool' = True) -&gt; 'List[NodeUtilization]'</code> - Return hardware utilization per node based on active topology.</li> <li><code>print_tree(self, node: 'Optional[TreeNode]' = None, indent: 'int' = 0, max_depth: 'Optional[int]' = None, skip_leaves: 'bool' = False, detailed: 'bool' = False, include_disabled: 'bool' = True, max_external_lines: 'Optional[int]' = None, line_prefix: 'str' = '') -&gt; 'None'</code> - Print the hierarchy from 'node' down (default: root).</li> </ul>"},{"location":"reference/api-full/#nodeutilization","title":"NodeUtilization","text":"<p>Per-node hardware utilization snapshot based on active topology.</p> <p>Attributes:     node_name: Fully qualified node name.     component_name: Hardware component name if present.     hw_count: Hardware multiplicity used for capacity/power scaling.     capacity_supported: Total capacity supported by node hardware.     attached_capacity_active: Sum of capacities of enabled adjacent links where the         opposite endpoint is also enabled.     capacity_utilization: Ratio of attached to supported capacity (0.0 when N/A).     ports_available: Total port equivalents available on the node (0.0 when N/A).     ports_used: Sum of port equivalents used by per-end link optics attached to this         node on active links.     ports_utilization: Ratio of used to available ports (0.0 when N/A).     capacity_violation: True if attached capacity exceeds supported capacity.     ports_violation: True if used ports exceed available ports.     disabled: True if the node itself is disabled.</p> <p>Attributes:</p> <ul> <li><code>node_name</code> (str)</li> <li><code>component_name</code> (Optional[str])</li> <li><code>hw_count</code> (float)</li> <li><code>capacity_supported</code> (float)</li> <li><code>attached_capacity_active</code> (float)</li> <li><code>capacity_utilization</code> (float)</li> <li><code>ports_available</code> (float)</li> <li><code>ports_used</code> (float)</li> <li><code>ports_utilization</code> (float)</li> <li><code>capacity_violation</code> (bool)</li> <li><code>ports_violation</code> (bool)</li> <li><code>disabled</code> (bool)</li> </ul>"},{"location":"reference/api-full/#treenode","title":"TreeNode","text":"<p>Represents a node in the hierarchical tree.</p> <p>Attributes:     name (str): Name/label of this node.     parent (Optional[TreeNode]): Pointer to the parent tree node.     children (Dict[str, TreeNode]): Mapping of child name -&gt; child TreeNode.     subtree_nodes (Set[str]): Node names in the subtree (all nodes, ignoring disabled).     active_subtree_nodes (Set[str]): Node names in the subtree (only enabled).     stats (TreeStats): Aggregated stats for \"all\" view.     active_stats (TreeStats): Aggregated stats for \"active\" (only enabled) view.     raw_nodes (List[Node]): Direct Node objects at this hierarchy level.</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>parent</code> (Optional[TreeNode])</li> <li><code>children</code> (Dict[str, TreeNode]) = {}</li> <li><code>subtree_nodes</code> (Set[str]) = set()</li> <li><code>active_subtree_nodes</code> (Set[str]) = set()</li> <li><code>stats</code> (TreeStats) = TreeStats(node_count=0, internal_link_count=0, internal_link_capacity=0.0, external_link_count=0, external_link_capacity=0.0, external_link_details={}, total_capex=0.0, total_power=0.0, bom={}, active_bom={})</li> <li><code>active_stats</code> (TreeStats) = TreeStats(node_count=0, internal_link_count=0, internal_link_capacity=0.0, external_link_count=0, external_link_capacity=0.0, external_link_details={}, total_capex=0.0, total_power=0.0, bom={}, active_bom={})</li> <li><code>raw_nodes</code> (List[Node]) = []</li> </ul> <p>Methods:</p> <ul> <li><code>add_child(self, child_name: 'str') -&gt; 'TreeNode'</code> - Ensure a child node named 'child_name' exists and return it.</li> <li><code>is_leaf(self) -&gt; 'bool'</code> - Return True if this node has no children.</li> </ul>"},{"location":"reference/api-full/#treestats","title":"TreeStats","text":"<p>Aggregated statistics for a single tree node (subtree).</p> <p>Attributes:     node_count (int): Total number of nodes in this subtree.     internal_link_count (int): Number of internal links in this subtree.     internal_link_capacity (float): Sum of capacities for those internal links.     external_link_count (int): Number of external links from this subtree to another.     external_link_capacity (float): Sum of capacities for those external links.     external_link_details (Dict[str, ExternalLinkBreakdown]): Breakdown by other subtree path.     total_capex (float): Cumulative capex (nodes + links).     total_power (float): Cumulative power (nodes + links).</p> <p>Attributes:</p> <ul> <li><code>node_count</code> (int) = 0</li> <li><code>internal_link_count</code> (int) = 0</li> <li><code>internal_link_capacity</code> (float) = 0.0</li> <li><code>external_link_count</code> (int) = 0</li> <li><code>external_link_capacity</code> (float) = 0.0</li> <li><code>external_link_details</code> (Dict[str, ExternalLinkBreakdown]) = {}</li> <li><code>total_capex</code> (float) = 0.0</li> <li><code>total_power</code> (float) = 0.0</li> <li><code>bom</code> (Dict[str, float]) = {}</li> <li><code>active_bom</code> (Dict[str, float]) = {}</li> </ul>"},{"location":"reference/api-full/#ngraphlogging","title":"ngraph.logging","text":"<p>Centralized logging configuration for NetGraph.</p>"},{"location":"reference/api-full/#disable_debug_logging-none","title":"disable_debug_logging() -&gt; None","text":"<p>Disable debug logging, set to INFO level.</p>"},{"location":"reference/api-full/#enable_debug_logging-none","title":"enable_debug_logging() -&gt; None","text":"<p>Enable debug logging for the entire package.</p>"},{"location":"reference/api-full/#get_loggername-str-logginglogger","title":"get_logger(name: str) -&gt; logging.Logger","text":"<p>Get a logger with NetGraph's standard configuration.</p> <p>This is the main function that should be used throughout the package. All loggers will inherit from the root 'ngraph' logger configuration.</p> <p>Args:     name: Logger name (typically name from calling module).</p> <p>Returns:     Configured logger instance.</p>"},{"location":"reference/api-full/#reset_logging-none","title":"reset_logging() -&gt; None","text":"<p>Reset logging configuration (mainly for testing).</p>"},{"location":"reference/api-full/#set_global_log_levellevel-int-none","title":"set_global_log_level(level: int) -&gt; None","text":"<p>Set the log level for all NetGraph loggers.</p> <p>Args:     level: Logging level (e.g., logging.DEBUG, logging.INFO).</p>"},{"location":"reference/api-full/#setup_root_loggerlevel-int-20-format_string-optionalstr-none-handler-optionallogginghandler-none-none","title":"setup_root_logger(level: int = 20, format_string: Optional[str] = None, handler: Optional[logging.Handler] = None) -&gt; None","text":"<p>Set up the root NetGraph logger with a single handler.</p> <p>This should only be called once to avoid duplicate handlers.</p> <p>Args:     level: Logging level (default: INFO).     format_string: Custom format string (optional).     handler: Custom handler (optional, defaults to StreamHandler).</p>"},{"location":"reference/api-full/#ngraphscenario","title":"ngraph.scenario","text":"<p>Scenario class for defining network analysis workflows from YAML.</p>"},{"location":"reference/api-full/#scenario","title":"Scenario","text":"<p>Represents a complete scenario for building and executing network workflows.</p> <p>This scenario includes:</p> <ul> <li>A network (nodes/links), constructed via blueprint expansion.</li> <li>A failure policy set (one or more named failure policies).</li> <li>A traffic matrix set containing one or more named traffic matrices.</li> <li>A list of workflow steps to execute.</li> <li>A results container for storing outputs.</li> <li>A components_library for hardware/optics definitions.</li> <li>A seed for reproducible random operations (optional).</li> </ul> <p>Typical usage example:</p> <pre><code>scenario = Scenario.from_yaml(yaml_str, default_components=default_lib)\nscenario.run()\n# Inspect scenario.results\n</code></pre> <p>Attributes:</p> <ul> <li><code>network</code> (Network)</li> <li><code>workflow</code> (List[WorkflowStep])</li> <li><code>failure_policy_set</code> (FailurePolicySet) = FailurePolicySet(policies={})</li> <li><code>traffic_matrix_set</code> (TrafficMatrixSet) = TrafficMatrixSet(matrices={})</li> <li><code>results</code> (Results) = Results(_store={}, _metadata={}, _active_step=None, _scenario={})</li> <li><code>components_library</code> (ComponentsLibrary) = ComponentsLibrary(components={})</li> <li><code>seed</code> (Optional[int])</li> </ul> <p>Methods:</p> <ul> <li><code>from_yaml(yaml_str: 'str', default_components: 'Optional[ComponentsLibrary]' = None) -&gt; 'Scenario'</code> - Constructs a Scenario from a YAML string, optionally merging</li> <li><code>run(self) -&gt; 'None'</code> - Executes the scenario's workflow steps in order.</li> </ul>"},{"location":"reference/api-full/#ngraphseed_manager","title":"ngraph.seed_manager","text":"<p>Deterministic seed derivation to avoid global random.seed() order dependencies.</p>"},{"location":"reference/api-full/#seedmanager","title":"SeedManager","text":"<p>Manages deterministic seed derivation for isolated component reproducibility.</p> <p>Global random.seed() creates order dependencies and component interference. SeedManager derives unique seeds per component from a master seed using SHA-256, ensuring reproducible results regardless of execution order or parallelism.</p> <p>Usage:     seed_mgr = SeedManager(42)     failure_seed = seed_mgr.derive_seed(\"failure_policy\", \"default\")</p> <p>Methods:</p> <ul> <li><code>create_random_state(self, *components: 'Any') -&gt; 'random.Random'</code> - Create a new Random instance with derived seed.</li> <li><code>derive_seed(self, *components: 'Any') -&gt; 'Optional[int]'</code> - Derive a deterministic seed from master seed and component identifiers.</li> <li><code>seed_global_random(self, *components: 'Any') -&gt; 'None'</code> - Seed the global random module with derived seed.</li> </ul>"},{"location":"reference/api-full/#ngraphyaml_utils","title":"ngraph.yaml_utils","text":"<p>Utilities for handling YAML parsing quirks and common operations.</p>"},{"location":"reference/api-full/#normalize_yaml_dict_keysdata-dictany-v-dictstr-v","title":"normalize_yaml_dict_keys(data: Dict[Any, ~V]) -&gt; Dict[str, ~V]","text":"<p>Normalize dictionary keys from YAML parsing to ensure consistent string keys.</p> <p>YAML 1.1 boolean keys (e.g., true, false, yes, no, on, off) get converted to Python True/False boolean values. This function converts them to predictable string representations (\"True\"/\"False\") and ensures all keys are strings.</p> <p>Args:     data: Dictionary that may contain boolean or other non-string keys from YAML parsing</p> <p>Returns:     Dictionary with all keys converted to strings, boolean keys converted to \"True\"/\"False\"</p> <p>Examples:     &gt;&gt;&gt; normalize_yaml_dict_keys({True: \"value1\", False: \"value2\", \"normal\": \"value3\"})     {\"True\": \"value1\", \"False\": \"value2\", \"normal\": \"value3\"}</p> <pre><code>&gt;&gt;&gt; # In YAML: true:, yes:, on: all become Python True\n&gt;&gt;&gt; # In YAML: false:, no:, off: all become Python False\n</code></pre>"},{"location":"reference/api-full/#ngraphgraphconvert","title":"ngraph.graph.convert","text":"<p>Graph conversion utilities between StrictMultiDiGraph and NetworkX graphs.</p> <p>Functions in this module consolidate or expand multi-edges and can preserve original edge data for reversion through a special <code>_uv_edges</code> attribute.</p>"},{"location":"reference/api-full/#from_digraphnx_graph-networkxclassesdigraphdigraph-ngraphgraphstrict_multidigraphstrictmultidigraph","title":"from_digraph(nx_graph: networkx.classes.digraph.DiGraph) -&gt; ngraph.graph.strict_multidigraph.StrictMultiDiGraph","text":"<p>Convert a revertible NetworkX DiGraph to a StrictMultiDiGraph.</p> <p>This function reconstructs the original StrictMultiDiGraph by restoring multi-edge information from the '_uv_edges' attribute of each edge.</p> <p>Args:     nx_graph: A revertible NetworkX DiGraph with <code>_uv_edges</code> attributes.</p> <p>Returns:     A StrictMultiDiGraph reconstructed from the input DiGraph.</p>"},{"location":"reference/api-full/#from_graphnx_graph-networkxclassesgraphgraph-ngraphgraphstrict_multidigraphstrictmultidigraph","title":"from_graph(nx_graph: networkx.classes.graph.Graph) -&gt; ngraph.graph.strict_multidigraph.StrictMultiDiGraph","text":"<p>Convert a revertible NetworkX Graph to a StrictMultiDiGraph.</p> <p>Restores the original multi-edge structure from the '_uv_edges' attribute stored in each consolidated edge.</p> <p>Args:     nx_graph: A revertible NetworkX Graph with <code>_uv_edges</code> attributes.</p> <p>Returns:     A StrictMultiDiGraph reconstructed from the input Graph.</p>"},{"location":"reference/api-full/#to_digraphgraph-ngraphgraphstrict_multidigraphstrictmultidigraph-edge_func-optionalcallablengraphgraphstrict_multidigraphstrictmultidigraph-hashable-hashable-dict-dict-none-revertible-bool-true-networkxclassesdigraphdigraph","title":"to_digraph(graph: ngraph.graph.strict_multidigraph.StrictMultiDiGraph, edge_func: Optional[Callable[[ngraph.graph.strict_multidigraph.StrictMultiDiGraph, Hashable, Hashable, dict], dict]] = None, revertible: bool = True) -&gt; networkx.classes.digraph.DiGraph","text":"<p>Convert a StrictMultiDiGraph to a NetworkX DiGraph.</p> <p>This function consolidates multi-edges between nodes into a single edge. Optionally, a custom edge function can be provided to compute edge attributes. If <code>revertible</code> is True, the original multi-edge data is stored in the '_uv_edges' attribute of each consolidated edge, allowing for later reversion.</p> <p>Args:     graph: The StrictMultiDiGraph to convert.     edge_func: Optional function to compute consolidated edge attributes.         The callable receives <code>(graph, u, v, edges)</code> and returns a dict.     revertible: If True, store the original multi-edge data for reversion.</p> <p>Returns:     A NetworkX DiGraph representing the input graph.</p>"},{"location":"reference/api-full/#to_graphgraph-ngraphgraphstrict_multidigraphstrictmultidigraph-edge_func-optionalcallablengraphgraphstrict_multidigraphstrictmultidigraph-hashable-hashable-dict-dict-none-revertible-bool-true-networkxclassesgraphgraph","title":"to_graph(graph: ngraph.graph.strict_multidigraph.StrictMultiDiGraph, edge_func: Optional[Callable[[ngraph.graph.strict_multidigraph.StrictMultiDiGraph, Hashable, Hashable, dict], dict]] = None, revertible: bool = True) -&gt; networkx.classes.graph.Graph","text":"<p>Convert a StrictMultiDiGraph to a NetworkX Graph.</p> <p>This function works similarly to <code>to_digraph</code> but returns an undirected graph.</p> <p>Args:     graph: The StrictMultiDiGraph to convert.     edge_func: Optional function to compute consolidated edge attributes.     revertible: If True, store the original multi-edge data for reversion.</p> <p>Returns:     A NetworkX Graph representing the input graph.</p>"},{"location":"reference/api-full/#ngraphgraphio","title":"ngraph.graph.io","text":"<p>Graph serialization functions for node-link and edge-list formats.</p>"},{"location":"reference/api-full/#edgelist_to_graphlines-iterablestr-columns-liststr-separator-str-graph-optionalstrictmultidigraph-none-source-str-src-target-str-dst-key-str-key-strictmultidigraph","title":"edgelist_to_graph(lines: 'Iterable[str]', columns: 'List[str]', separator: 'str' = ' ', graph: 'Optional[StrictMultiDiGraph]' = None, source: 'str' = 'src', target: 'str' = 'dst', key: 'str' = 'key') -&gt; 'StrictMultiDiGraph'","text":"<p>Build or update a StrictMultiDiGraph from an edge list.</p> <p>Each line in the input is split by the specified separator into tokens. These tokens are mapped to column names provided in <code>columns</code>. The tokens corresponding to <code>source</code> and <code>target</code> become the node IDs. If a <code>key</code> column exists, its token is used as the edge ID; remaining tokens are added as edge attributes.</p> <p>Args:     lines: An iterable of strings, each representing one edge.     columns: A list of column names, e.g. [\"src\", \"dst\", \"cost\"].     separator: The separator used to split each line (default is a space).     graph: An existing StrictMultiDiGraph to update; if None, a new graph is created.     source: The column name for the source node ID.     target: The column name for the target node ID.     key: The column name for a custom edge ID (if present).</p> <p>Returns:     The updated (or newly created) StrictMultiDiGraph.</p> <p>Raises:     RuntimeError: If a line does not match the expected number of columns.</p>"},{"location":"reference/api-full/#graph_to_edgelistgraph-strictmultidigraph-columns-optionalliststr-none-separator-str-source_col-str-src-target_col-str-dst-key_col-str-key-liststr","title":"graph_to_edgelist(graph: 'StrictMultiDiGraph', columns: 'Optional[List[str]]' = None, separator: 'str' = ' ', source_col: 'str' = 'src', target_col: 'str' = 'dst', key_col: 'str' = 'key') -&gt; 'List[str]'","text":"<p>Convert a StrictMultiDiGraph into an edge-list text representation.</p> <p>Each line in the output represents one edge with tokens joined by the given separator. By default, the output columns are:     [source_col, target_col, key_col] + sorted(edge_attribute_names)</p> <p>If an explicit list of columns is provided, those columns (in that order) are used, and any missing values are output as an empty string.</p> <p>Args:     graph: The StrictMultiDiGraph to export.     columns: Optional list of column names. If None, they are auto-generated.     separator: The string used to join tokens (default is a space).     source_col: The column name for the source node (default \"src\").     target_col: The column name for the target node (default \"dst\").     key_col: The column name for the edge key (default \"key\").</p> <p>Returns:     A list of strings, each representing one edge in the specified column format.</p>"},{"location":"reference/api-full/#graph_to_node_linkgraph-strictmultidigraph-dictstr-any","title":"graph_to_node_link(graph: 'StrictMultiDiGraph') -&gt; 'Dict[str, Any]'","text":"<p>Convert a StrictMultiDiGraph into a node-link dict representation.</p> <p>This representation is suitable for JSON serialization (e.g., for D3.js or Nx formats).</p> <p>The returned dict has the following structure:     {         \"graph\": { ... top-level graph attributes ... },         \"nodes\": [             {\"id\": node_id, \"attr\": { ... node attributes ... }},             ...         ],         \"links\": [             {                 \"source\": ,                 \"target\": ,                 \"key\": ,                 \"attr\": { ... edge attributes ... }             },             ...         ]     } <p>Args:     graph: The StrictMultiDiGraph to convert.</p> <p>Returns:     A dict containing the 'graph' attributes, list of 'nodes', and list of 'links'.</p>"},{"location":"reference/api-full/#node_link_to_graphdata-dictstr-any-strictmultidigraph","title":"node_link_to_graph(data: 'Dict[str, Any]') -&gt; 'StrictMultiDiGraph'","text":"<p>Reconstruct a StrictMultiDiGraph from its node-link dict representation.</p> <p>Expected input format:     {         \"graph\": { ... graph attributes ... },         \"nodes\": [             {\"id\": , \"attr\": { ... node attributes ... }},             ...         ],         \"links\": [             {                 \"source\": ,                 \"target\": ,                 \"key\": ,                 \"attr\": { ... edge attributes ... }             },             ...         ]     } <p>Args:     data: A dict representing the node-link structure.</p> <p>Returns:     A StrictMultiDiGraph reconstructed from the provided data.</p> <p>Raises:     KeyError: If required keys (e.g., \"id\" or \"attr\" on nodes) are missing.</p>"},{"location":"reference/api-full/#ngraphgraphstrict_multidigraph","title":"ngraph.graph.strict_multidigraph","text":"<p>Strict multi-directed graph with validation and convenience APIs.</p> <p><code>StrictMultiDiGraph</code> extends <code>networkx.MultiDiGraph</code> to enforce explicit node management, unique edge identifiers, and predictable error handling. It exposes helpers to access nodes/edges as dictionaries and to serialize in node-link format via <code>to_dict()</code>.</p>"},{"location":"reference/api-full/#strictmultidigraph","title":"StrictMultiDiGraph","text":"<p>A custom multi-directed graph with strict rules and unique edge IDs.</p> <p>This class enforces:</p> <ul> <li>No automatic creation of missing nodes when adding an edge.</li> <li>No duplicate nodes (raises ValueError on duplicates).</li> <li>No duplicate edges by key (raises ValueError on duplicates).</li> <li>Removing non-existent nodes or edges raises ValueError.</li> <li> <p>Each edge key must be unique; by default, a Base64-UUID is generated</p> <p>if none is provided.</p> </li> <li> <p><code>copy()</code> can perform a pickle-based deep copy that may be faster</p> <p>than the NetworkX default.</p> </li> </ul> <p>Inherits from:     networkx.MultiDiGraph</p> <p>Methods:</p> <ul> <li><code>add_edge(self, u_for_edge: 'NodeID', v_for_edge: 'NodeID', key: 'Optional[EdgeID]' = None, **attr: 'Any') -&gt; 'EdgeID'</code> - Add a directed edge from u_for_edge to v_for_edge.</li> <li><code>add_edges_from(self, ebunch_to_add, **attr)</code> - Add all the edges in ebunch_to_add.</li> <li><code>add_node(self, node_for_adding: 'NodeID', **attr: 'Any') -&gt; 'None'</code> - Add a single node, disallowing duplicates.</li> <li><code>add_nodes_from(self, nodes_for_adding, **attr)</code> - Add multiple nodes.</li> <li><code>add_weighted_edges_from(self, ebunch_to_add, weight='weight', **attr)</code> - Add weighted edges in <code>ebunch_to_add</code> with specified weight attr</li> <li><code>adjacency(self)</code> - Returns an iterator over (node, adjacency dict) tuples for all nodes.</li> <li><code>clear(self)</code> - Remove all nodes and edges from the graph.</li> <li><code>clear_edges(self)</code> - Remove all edges from the graph without altering nodes.</li> <li><code>copy(self, as_view: 'bool' = False, pickle: 'bool' = True) -&gt; 'StrictMultiDiGraph'</code> - Create a copy of this graph.</li> <li><code>edge_subgraph(self, edges)</code> - Returns the subgraph induced by the specified edges.</li> <li><code>edges_between(self, u: 'NodeID', v: 'NodeID') -&gt; 'List[EdgeID]'</code> - List all edge keys from node u to node v.</li> <li><code>get_edge_attr(self, key: 'EdgeID') -&gt; 'AttrDict'</code> - Retrieve the attribute dictionary of a specific edge.</li> <li><code>get_edge_data(self, u, v, key=None, default=None)</code> - Returns the attribute dictionary associated with edge (u, v,</li> <li><code>get_edges(self) -&gt; 'Dict[EdgeID, EdgeTuple]'</code> - Retrieve a dictionary of all edges by their keys.</li> <li><code>get_nodes(self) -&gt; 'Dict[NodeID, AttrDict]'</code> - Retrieve all nodes and their attributes as a dictionary.</li> <li><code>has_edge(self, u, v, key=None)</code> - Returns True if the graph has an edge between nodes u and v.</li> <li><code>has_edge_by_id(self, key: 'EdgeID') -&gt; 'bool'</code> - Check whether an edge with the given key exists.</li> <li><code>has_node(self, n)</code> - Returns True if the graph contains the node n.</li> <li><code>has_predecessor(self, u, v)</code> - Returns True if node u has predecessor v.</li> <li><code>has_successor(self, u, v)</code> - Returns True if node u has successor v.</li> <li><code>is_directed(self)</code> - Returns True if graph is directed, False otherwise.</li> <li><code>is_multigraph(self)</code> - Returns True if graph is a multigraph, False otherwise.</li> <li><code>nbunch_iter(self, nbunch=None)</code> - Returns an iterator over nodes contained in nbunch that are</li> <li><code>neighbors(self, n)</code> - Returns an iterator over successor nodes of n.</li> <li><code>new_edge_key(self, u: 'NodeID', v: 'NodeID', key: 'Optional[int]' = None) -&gt; 'int'</code> - Return a new unique integer edge ID.</li> <li><code>number_of_edges(self, u=None, v=None)</code> - Returns the number of edges between two nodes.</li> <li><code>number_of_nodes(self)</code> - Returns the number of nodes in the graph.</li> <li><code>order(self)</code> - Returns the number of nodes in the graph.</li> <li><code>predecessors(self, n)</code> - Returns an iterator over predecessor nodes of n.</li> <li><code>remove_edge(self, u: 'NodeID', v: 'NodeID', key: 'Optional[EdgeID]' = None) -&gt; 'None'</code> - Remove an edge (or edges) between nodes u and v.</li> <li><code>remove_edge_by_id(self, key: 'EdgeID') -&gt; 'None'</code> - Remove a directed edge by its unique key.</li> <li><code>remove_edges_from(self, ebunch)</code> - Remove all edges specified in ebunch.</li> <li><code>remove_node(self, n: 'NodeID') -&gt; 'None'</code> - Remove a single node and all incident edges.</li> <li><code>remove_nodes_from(self, nodes)</code> - Remove multiple nodes.</li> <li><code>reverse(self, copy=True)</code> - Returns the reverse of the graph.</li> <li><code>size(self, weight=None)</code> - Returns the number of edges or total of all edge weights.</li> <li><code>subgraph(self, nodes)</code> - Returns a SubGraph view of the subgraph induced on <code>nodes</code>.</li> <li><code>successors(self, n)</code> - Returns an iterator over successor nodes of n.</li> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code> - Convert the graph to a dictionary representation suitable for JSON serialization.</li> <li><code>to_directed(self, as_view=False)</code> - Returns a directed representation of the graph.</li> <li><code>to_directed_class(self)</code> - Returns the class to use for empty directed copies.</li> <li><code>to_undirected(self, reciprocal=False, as_view=False)</code> - Returns an undirected representation of the digraph.</li> <li><code>to_undirected_class(self)</code> - Returns the class to use for empty undirected copies.</li> <li><code>update(self, edges=None, nodes=None)</code> - Update the graph using nodes/edges/graphs as input.</li> <li><code>update_edge_attr(self, key: 'EdgeID', **attr: 'Any') -&gt; 'None'</code> - Update attributes on an existing edge by key.</li> </ul>"},{"location":"reference/api-full/#ngraphmodelnetwork","title":"ngraph.model.network","text":"<p>Network topology modeling with Node, Link, RiskGroup, and Network classes.</p>"},{"location":"reference/api-full/#link","title":"Link","text":"<p>Represents one directed link between two nodes.</p> <p>The model stores a single direction (<code>source</code> -&gt; <code>target</code>). When building the working graph for analysis, a reverse edge is added by default to provide bidirectional connectivity. Disable with <code>add_reverse=False</code> in <code>Network.to_strict_multidigraph</code>.</p> <p>Attributes:     source (str): Name of the source node.     target (str): Name of the target node.     capacity (float): Link capacity (default 1.0).     cost (float): Link cost (default 1.0).     disabled (bool): Whether the link is disabled.     risk_groups (Set[str]): Set of risk group names this link belongs to.     attrs (Dict[str, Any]): Additional metadata (e.g., distance).     id (str): Auto-generated unique identifier: \"{source}|{target}|\". <p>Attributes:</p> <ul> <li><code>source</code> (str)</li> <li><code>target</code> (str)</li> <li><code>capacity</code> (float) = 1.0</li> <li><code>cost</code> (float) = 1.0</li> <li><code>disabled</code> (bool) = False</li> <li><code>risk_groups</code> (Set[str]) = set()</li> <li><code>attrs</code> (Dict[str, Any]) = {}</li> <li><code>id</code> (str)</li> </ul>"},{"location":"reference/api-full/#network","title":"Network","text":"<p>A container for network nodes and links.</p> <p>Network represents the scenario-level topology with persistent state (nodes/links that are disabled in the scenario configuration). For temporary exclusion of nodes/links during analysis (e.g., failure simulation), use NetworkView instead of modifying the Network's disabled states.</p> <p>Attributes:     nodes (Dict[str, Node]): Mapping from node name -&gt; Node object.     links (Dict[str, Link]): Mapping from link ID -&gt; Link object.     risk_groups (Dict[str, RiskGroup]): Top-level risk groups by name.     attrs (Dict[str, Any]): Optional metadata about the network.</p> <p>Attributes:</p> <ul> <li><code>nodes</code> (Dict[str, Node]) = {}</li> <li><code>links</code> (Dict[str, Link]) = {}</li> <li><code>risk_groups</code> (Dict[str, RiskGroup]) = {}</li> <li><code>attrs</code> (Dict[str, Any]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>add_link(self, link: 'Link') -&gt; 'None'</code> - Add a link to the network (keyed by the link's auto-generated ID).</li> <li><code>add_node(self, node: 'Node') -&gt; 'None'</code> - Add a node to the network (keyed by node.name).</li> <li><code>disable_all(self) -&gt; 'None'</code> - Mark all nodes and links as disabled.</li> <li><code>disable_link(self, link_id: 'str') -&gt; 'None'</code> - Mark a link as disabled.</li> <li><code>disable_node(self, node_name: 'str') -&gt; 'None'</code> - Mark a node as disabled.</li> <li><code>disable_risk_group(self, name: 'str', recursive: 'bool' = True) -&gt; 'None'</code> - Disable all nodes/links that have 'name' in their risk_groups.</li> <li><code>enable_all(self) -&gt; 'None'</code> - Mark all nodes and links as enabled.</li> <li><code>enable_link(self, link_id: 'str') -&gt; 'None'</code> - Mark a link as enabled.</li> <li><code>enable_node(self, node_name: 'str') -&gt; 'None'</code> - Mark a node as enabled.</li> <li><code>enable_risk_group(self, name: 'str', recursive: 'bool' = True) -&gt; 'None'</code> - Enable all nodes/links that have 'name' in their risk_groups.</li> <li><code>find_links(self, source_regex: 'Optional[str]' = None, target_regex: 'Optional[str]' = None, any_direction: 'bool' = False) -&gt; 'List[Link]'</code> - Search for links using optional regex patterns for source or target node names.</li> <li><code>get_links_between(self, source: 'str', target: 'str') -&gt; 'List[str]'</code> - Retrieve all link IDs that connect the specified source node</li> <li><code>k_shortest_paths(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'pairwise', *, max_k: 'int' = 3, max_path_cost: 'float' = inf, max_path_cost_factor: 'Optional[float]' = None, split_parallel_edges: 'bool' = False) -&gt; 'Dict[Tuple[str, str], List[_NGPath]]'</code> - Return up to K shortest paths per group pair.</li> <li><code>max_flow(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;) -&gt; 'Dict[Tuple[str, str], float]'</code> - Compute maximum flow between node groups in this network.</li> <li><code>max_flow_detailed(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;) -&gt; 'Dict[Tuple[str, str], Tuple[float, FlowSummary, StrictMultiDiGraph]]'</code> - Compute maximum flow with both analytics summary and graph.</li> <li><code>max_flow_with_graph(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;) -&gt; 'Dict[Tuple[str, str], Tuple[float, StrictMultiDiGraph]]'</code> - Compute maximum flow and return flow-assigned graphs.</li> <li><code>max_flow_with_summary(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;) -&gt; 'Dict[Tuple[str, str], Tuple[float, FlowSummary]]'</code> - Compute maximum flow and return per-pair analytics summary.</li> <li><code>saturated_edges(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', tolerance: 'float' = 1e-10, shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;) -&gt; 'Dict[Tuple[str, str], List[Tuple[str, str, str]]]'</code> - Identify saturated edges in max flow solutions.</li> <li><code>select_node_groups_by_path(self, path: 'str') -&gt; 'Dict[str, List[Node]]'</code> - Select and group nodes by regex on name or by attribute directive.</li> <li><code>sensitivity_analysis(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', change_amount: 'float' = 1.0, shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;) -&gt; 'Dict[Tuple[str, str], Dict[Tuple[str, str, str], float]]'</code> - Perform sensitivity analysis for capacity changes.</li> <li><code>shortest_path_costs(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine') -&gt; 'Dict[Tuple[str, str], float]'</code> - Return minimal path costs between node groups in this network.</li> <li><code>shortest_paths(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', *, split_parallel_edges: 'bool' = False) -&gt; 'Dict[Tuple[str, str], List[_NGPath]]'</code> - Return concrete shortest path(s) between selected node groups.</li> <li><code>to_strict_multidigraph(self, add_reverse: 'bool' = True, *, compact: 'bool' = False) -&gt; 'StrictMultiDiGraph'</code> - Create a StrictMultiDiGraph representation of this Network.</li> </ul>"},{"location":"reference/api-full/#node","title":"Node","text":"<p>Represents a node in the network.</p> <p>Each node is uniquely identified by its name, which is used as the key in the Network's node dictionary.</p> <p>Attributes:     name (str): Unique identifier for the node.     disabled (bool): Whether the node is disabled in the scenario configuration.     risk_groups (Set[str]): Set of risk group names this node belongs to.     attrs (Dict[str, Any]): Additional metadata (e.g., coordinates, region).</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>disabled</code> (bool) = False</li> <li><code>risk_groups</code> (Set[str]) = set()</li> <li><code>attrs</code> (Dict[str, Any]) = {}</li> </ul>"},{"location":"reference/api-full/#riskgroup","title":"RiskGroup","text":"<p>Represents a shared-risk or failure domain, which may have nested children.</p> <p>Attributes:     name (str): Unique name of this risk group.     children (List[RiskGroup]): Subdomains in a nested structure.     disabled (bool): Whether this group was declared disabled on load.     attrs (Dict[str, Any]): Additional metadata for the risk group.</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>children</code> (List[RiskGroup]) = []</li> <li><code>disabled</code> (bool) = False</li> <li><code>attrs</code> (Dict[str, Any]) = {}</li> </ul>"},{"location":"reference/api-full/#ngraphmodelview","title":"ngraph.model.view","text":"<p>Read-only view of a <code>Network</code> with temporary exclusions.</p> <p>This module defines a view over <code>Network</code> objects that can exclude nodes and links for analysis without mutating the base network. It supports what-if analysis, including failure simulations.</p>"},{"location":"reference/api-full/#networkview","title":"NetworkView","text":"<p>Read-only overlay that hides selected nodes/links from a base Network.</p> <p>NetworkView provides filtered access to a Network where both scenario-disabled elements (Node.disabled, Link.disabled) and analysis-excluded elements are hidden from algorithms. This enables failure simulation and what-if analysis without mutating the base Network.</p> <p>Multiple NetworkView instances can safely operate on the same base Network concurrently, each with different exclusion sets.</p> <p>Example:     <pre><code># Create view excluding specific nodes for failure analysis\nview = NetworkView.from_excluded_sets(\n    base_network,\n    excluded_nodes=[\"node1\", \"node2\"],\n    excluded_links=[\"link1\"]\n)\n\n# Run analysis on filtered topology\nflows = view.max_flow(\"source.*\", \"sink.*\")\n</code></pre></p> <p>Attributes:     _base: The underlying Network object.     _excluded_nodes: Frozen set of node names to exclude from analysis.     _excluded_links: Frozen set of link IDs to exclude from analysis.</p> <p>Attributes:</p> <ul> <li><code>_base</code> ('Network')</li> <li><code>_excluded_nodes</code> (frozenset[str]) = frozenset()</li> <li><code>_excluded_links</code> (frozenset[str]) = frozenset()</li> </ul> <p>Methods:</p> <ul> <li><code>from_excluded_sets(base: \"'Network'\", excluded_nodes: 'Iterable[str]' = (), excluded_links: 'Iterable[str]' = ()) -&gt; \"'NetworkView'\"</code> - Create a NetworkView with specified exclusions.</li> <li><code>is_link_hidden(self, link_id: 'str') -&gt; 'bool'</code> - Check if a link is hidden in this view.</li> <li><code>is_node_hidden(self, name: 'str') -&gt; 'bool'</code> - Check if a node is hidden in this view.</li> <li><code>k_shortest_paths(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'pairwise', *, max_k: 'int' = 3, max_path_cost: 'float' = inf, max_path_cost_factor: 'Optional[float]' = None, split_parallel_edges: 'bool' = False) -&gt; 'Dict[Tuple[str, str], List[_NGPath]]'</code> - Return up to K shortest paths per group pair.</li> <li><code>max_flow(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: \"Optional['FlowPlacement']\" = None) -&gt; 'Dict[Tuple[str, str], float]'</code> - Compute maximum flow between node groups in this view.</li> <li><code>max_flow_detailed(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: \"Optional['FlowPlacement']\" = None) -&gt; \"Dict[Tuple[str, str], Tuple[float, 'FlowSummary', 'StrictMultiDiGraph']]\"</code> - Compute maximum flow with complete analytics and graph.</li> <li><code>max_flow_with_graph(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: \"Optional['FlowPlacement']\" = None) -&gt; \"Dict[Tuple[str, str], Tuple[float, 'StrictMultiDiGraph']]\"</code> - Compute maximum flow and return flow-assigned graph.</li> <li><code>max_flow_with_summary(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: \"Optional['FlowPlacement']\" = None) -&gt; \"Dict[Tuple[str, str], Tuple[float, 'FlowSummary']]\"</code> - Compute maximum flow with detailed analytics summary.</li> <li><code>saturated_edges(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', tolerance: 'float' = 1e-10, shortest_path: 'bool' = False, flow_placement: \"Optional['FlowPlacement']\" = None) -&gt; 'Dict[Tuple[str, str], List[Tuple[str, str, str]]]'</code> - Identify saturated edges in max flow solutions.</li> <li><code>select_node_groups_by_path(self, path: 'str') -&gt; \"Dict[str, List['Node']]\"</code> - Select and group visible nodes by regex or attribute directive.</li> <li><code>sensitivity_analysis(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', change_amount: 'float' = 1.0, shortest_path: 'bool' = False, flow_placement: \"Optional['FlowPlacement']\" = None) -&gt; 'Dict[Tuple[str, str], Dict[Tuple[str, str, str], float]]'</code> - Perform sensitivity analysis on capacity changes.</li> <li><code>shortest_path_costs(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine') -&gt; 'Dict[Tuple[str, str], float]'</code> - Return minimal path costs between node groups in this view.</li> <li><code>shortest_paths(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', *, split_parallel_edges: 'bool' = False) -&gt; 'Dict[Tuple[str, str], List[_NGPath]]'</code> - Return concrete shortest path(s) between selected node groups.</li> <li><code>to_strict_multidigraph(self, add_reverse: 'bool' = True, *, compact: 'bool' = False) -&gt; \"'StrictMultiDiGraph'\"</code> - Create a StrictMultiDiGraph representation of this view.</li> </ul>"},{"location":"reference/api-full/#ngraphalgorithmsbase","title":"ngraph.algorithms.base","text":"<p>Base classes and enums for network analysis algorithms.</p>"},{"location":"reference/api-full/#edgeselect","title":"EdgeSelect","text":"<p>Edge selection criteria.</p> <p>Determines which edges are considered for path-finding between a node and its neighbor(s).</p>"},{"location":"reference/api-full/#flowplacement","title":"FlowPlacement","text":"<p>Strategies to distribute flow across parallel equal-cost paths.</p>"},{"location":"reference/api-full/#pathalg","title":"PathAlg","text":"<p>Path-finding algorithm types.</p>"},{"location":"reference/api-full/#ngraphalgorithmscapacity","title":"ngraph.algorithms.capacity","text":"<p>Capacity calculation algorithms for network analysis.</p> <p>This module computes feasible flow given a predecessor DAG from a shortest-path routine and supports two placement strategies: proportional and equal-balanced in reversed orientation. Functions follow a Dinic-like blocking-flow approach for proportional placement.</p>"},{"location":"reference/api-full/#calc_graph_capacityflow_graph-strictmultidigraph-src_node-nodeid-dst_node-nodeid-pred-dictnodeid-dictnodeid-listedgeid-flow_placement-flowplacement-capacity_attr-str-capacity-flow_attr-str-flow-tuplefloat-dictnodeid-dictnodeid-float","title":"calc_graph_capacity(flow_graph: 'StrictMultiDiGraph', src_node: 'NodeID', dst_node: 'NodeID', pred: 'Dict[NodeID, Dict[NodeID, List[EdgeID]]]', flow_placement: 'FlowPlacement' = , capacity_attr: 'str' = 'capacity', flow_attr: 'str' = 'flow') -&gt; 'Tuple[float, Dict[NodeID, Dict[NodeID, float]]]' <p>Calculate feasible flow and flow fractions between two nodes.</p> <p>In PROPORTIONAL mode (similar to Dinic in reversed orientation):</p> <ol> <li>Build the reversed residual graph from dst_node (via <code>_init_graph_data</code>).</li> <li> <p>Use BFS (in <code>_set_levels_bfs</code>) to build a level graph and DFS (<code>_push_flow_dfs</code>)</p> <p>to push blocking flows, repeating until no more flow can be pushed.</p> </li> <li> <p>The net flow found is stored in reversed orientation. Convert final flows</p> <p>to forward orientation by negating and normalizing by the total.</p> </li> </ol> <p>In EQUAL_BALANCED mode:</p> <ol> <li> <p>Build reversed adjacency from dst_node (also via <code>_init_graph_data</code>),</p> <p>ignoring capacity checks in that BFS.</p> </li> <li> <p>Perform a BFS pass from src_node (<code>_equal_balance_bfs</code>) to distribute a</p> <p>nominal flow of 1.0 equally among parallel edges.</p> </li> <li> <p>Determine the scaling ratio so that no edge capacity is exceeded.</p> <p>Scale the flow assignments accordingly, then normalize to the forward sense.</p> </li> </ol> <p>Args:     flow_graph: The multigraph with capacity and flow attributes.     src_node: The source node in the forward graph.     dst_node: The destination node in the forward graph.     pred: Forward adjacency mapping (node -&gt; (adjacent node -&gt; list of EdgeIDs)),           typically produced by <code>spf(..., multipath=True)</code>. Must be a DAG.     flow_placement: The flow distribution strategy (PROPORTIONAL or EQUAL_BALANCED).     capacity_attr: Name of the capacity attribute on edges.     flow_attr: Name of the flow attribute on edges.</p> <p>Returns:     tuple[float, dict[NodeID, dict[NodeID, float]]]:</p> <ul> <li>Total feasible flow from <code>src_node</code> to <code>dst_node</code>.</li> <li>Normalized flow fractions in forward orientation (<code>[u][v]</code> &gt;= 0).</li> </ul> <p>Raises:     ValueError: If src_node or dst_node is not in the graph, or the flow_placement                 is unsupported.</p>","text":""},{"location":"reference/api-full/#ngraphalgorithmsedge_select","title":"ngraph.algorithms.edge_select","text":"<p>Edge selection algorithms for routing.</p> <p>Provides selection routines used by SPF to choose candidate edges between neighbors according to cost and capacity constraints.</p>"},{"location":"reference/api-full/#edge_select_fabricedge_select-ngraphalgorithmsbaseedgeselect-select_value-optionalany-none-edge_select_func-optionalcallablengraphgraphstrict_multidigraphstrictmultidigraph-hashable-hashable-dicthashable-dictstr-any-optionalsethashable-optionalsethashable-tupleunionint-float-listhashable-none-excluded_edges-optionalsethashable-none-excluded_nodes-optionalsethashable-none-cost_attr-str-cost-capacity_attr-str-capacity-flow_attr-str-flow-callablengraphgraphstrict_multidigraphstrictmultidigraph-hashable-hashable-dicthashable-dictstr-any-optionalsethashable-optionalsethashable-tupleunionint-float-listhashable","title":"edge_select_fabric(edge_select: ngraph.algorithms.base.EdgeSelect, select_value: Optional[Any] = None, edge_select_func: Optional[Callable[[ngraph.graph.strict_multidigraph.StrictMultiDiGraph, Hashable, Hashable, Dict[Hashable, Dict[str, Any]], Optional[Set[Hashable]], Optional[Set[Hashable]]], Tuple[Union[int, float], List[Hashable]]]] = None, excluded_edges: Optional[Set[Hashable]] = None, excluded_nodes: Optional[Set[Hashable]] = None, cost_attr: str = 'cost', capacity_attr: str = 'capacity', flow_attr: str = 'flow') -&gt; Callable[[ngraph.graph.strict_multidigraph.StrictMultiDiGraph, Hashable, Hashable, Dict[Hashable, Dict[str, Any]], Optional[Set[Hashable]], Optional[Set[Hashable]]], Tuple[Union[int, float], List[Hashable]]] <p>Create an edge-selection callable for SPF.</p> <p>Args:     edge_select: An EdgeSelect enum specifying the selection strategy.     select_value: An optional numeric threshold or scaling factor for capacity checks.     edge_select_func: A user-supplied function if edge_select=USER_DEFINED.     excluded_edges: A set of edges to ignore entirely.     excluded_nodes: A set of nodes to skip (if the destination node is in this set).     cost_attr: The edge attribute name representing cost.     capacity_attr: The edge attribute name representing capacity.     flow_attr: The edge attribute name representing current flow.</p> <p>Returns:     Callable: Function with signature         <code>(graph, src, dst, edges_dict, excluded_edges, excluded_nodes) -&gt;         (selected_cost, [edge_ids])</code>.</p>","text":""},{"location":"reference/api-full/#ngraphalgorithmsflow_init","title":"ngraph.algorithms.flow_init","text":"<p>Flow graph initialization utilities.</p> <p>Ensures nodes and edges carry aggregate (<code>flow_attr</code>) and per-flow (<code>flows_attr</code>) attributes, optionally resetting existing values.</p>"},{"location":"reference/api-full/#init_flow_graphflow_graph-strictmultidigraph-flow_attr-str-flow-flows_attr-str-flows-reset_flow_graph-bool-true-strictmultidigraph","title":"init_flow_graph(flow_graph: 'StrictMultiDiGraph', flow_attr: 'str' = 'flow', flows_attr: 'str' = 'flows', reset_flow_graph: 'bool' = True) -&gt; 'StrictMultiDiGraph' <p>Ensure that nodes and edges expose flow-related attributes.</p> <p>For each node and edge:</p> <ul> <li>The attribute named <code>flow_attr</code> (default: \"flow\") is set to 0.</li> <li>The attribute named <code>flows_attr</code> (default: \"flows\") is set to an empty dict.</li> </ul> <p>If <code>reset_flow_graph</code> is True, any existing flow values in these attributes are overwritten; otherwise they are only created if missing.</p> <p>Args:     flow_graph: The StrictMultiDiGraph whose nodes and edges should be         prepared for flow assignment.     flow_attr: The attribute name to track a numeric flow value per node/edge.     flows_attr: The attribute name to track multiple flow identifiers (and flows).     reset_flow_graph: If True, reset existing flows (set to 0). If False, do not overwrite.</p> <p>Returns:     StrictMultiDiGraph: The same graph instance after attribute checks.</p>","text":""},{"location":"reference/api-full/#ngraphalgorithmsmax_flow","title":"ngraph.algorithms.max_flow","text":"<p>Maximum-flow computation via iterative shortest-path augmentation.</p> <p>Implements a practical Edmonds-Karp-like procedure using SPF with capacity constraints and configurable flow-splitting across equal-cost parallel edges. Provides helpers for saturated-edge detection and simple sensitivity analysis.</p>"},{"location":"reference/api-full/#calc_max_flowgraph-ngraphgraphstrict_multidigraphstrictmultidigraph-src_node-hashable-dst_node-hashable-return_summary-bool-false-return_graph-bool-false-flow_placement-ngraphalgorithmsbaseflowplacement-shortest_path-bool-false-reset_flow_graph-bool-false-capacity_attr-str-capacity-flow_attr-str-flow-flows_attr-str-flows-copy_graph-bool-true-tolerance-float-1e-10-unionfloat-tuple","title":"calc_max_flow(graph: ngraph.graph.strict_multidigraph.StrictMultiDiGraph, src_node: Hashable, dst_node: Hashable, *, return_summary: bool = False, return_graph: bool = False, flow_placement: ngraph.algorithms.base.FlowPlacement = , shortest_path: bool = False, reset_flow_graph: bool = False, capacity_attr: str = 'capacity', flow_attr: str = 'flow', flows_attr: str = 'flows', copy_graph: bool = True, tolerance: float = 1e-10) -&gt; Union[float, tuple] <p>Compute max flow between two nodes in a directed multi-graph.</p> <p>Uses iterative shortest-path augmentation with capacity-aware SPF and configurable flow placement.</p> <p>By default, this function:</p> <ol> <li>Creates or re-initializes a flow-aware copy of the graph (via <code>init_flow_graph</code>).</li> <li> <p>Repeatedly finds a path from <code>src_node</code> to <code>dst_node</code> using <code>spf</code> with</p> <p>capacity constraints (<code>EdgeSelect.ALL_MIN_COST_WITH_CAP_REMAINING</code>).</p> </li> <li> <p>Places flow along that path (via <code>place_flow_on_graph</code>) until no augmenting path</p> <p>remains or the capacities are exhausted.</p> </li> </ol> <p>If <code>shortest_path=True</code>, the function performs only one iteration (single augmentation) and returns the flow placed along that single path (not the true max flow).</p> <p>Args:     graph (StrictMultiDiGraph):         The original graph containing capacity/flow attributes on each edge.     src_node (NodeID):         The source node for flow.     dst_node (NodeID):         The destination node for flow.     return_summary (bool):         If True, return a FlowSummary with detailed flow analytics.         Defaults to False.     return_graph (bool):         If True, return the mutated flow graph along with other results.         Defaults to False.     flow_placement (FlowPlacement):         Determines how flow is split among parallel edges of equal cost.         Defaults to <code>FlowPlacement.PROPORTIONAL</code>.     shortest_path (bool):         If True, place flow only once along the first shortest path found and return         immediately, rather than iterating for the true max flow.     reset_flow_graph (bool):         If True, reset any existing flow data (e.g., <code>flow_attr</code>, <code>flows_attr</code>).         Defaults to False.     capacity_attr (str):         The name of the capacity attribute on edges. Defaults to \"capacity\".     flow_attr (str):         The name of the aggregated flow attribute on edges. Defaults to \"flow\".     flows_attr (str):         The name of the per-flow dictionary attribute on edges. Defaults to \"flows\".     copy_graph (bool):         If True, work on a copy of the original graph so it remains unmodified.         Defaults to True.     tolerance (float):         Tolerance for floating-point comparisons when determining saturated edges         and residual capacity. Defaults to 1e-10.</p> <p>Returns:     Union[float, tuple]:</p> <ul> <li>If neither flag: <code>float</code> total flow.</li> <li>If return_summary only: <code>tuple[float, FlowSummary]</code>.</li> <li>If both flags: <code>tuple[float, FlowSummary, StrictMultiDiGraph]</code>.</li> </ul> <p>Notes:</p> <ul> <li>When using return_summary or return_graph, the return value is a tuple.</li> </ul> <p>Examples:     &gt;&gt;&gt; g = StrictMultiDiGraph()     &gt;&gt;&gt; g.add_node('A')     &gt;&gt;&gt; g.add_node('B')     &gt;&gt;&gt; g.add_node('C')     &gt;&gt;&gt; g.add_edge('A', 'B', capacity=10.0, flow=0.0, flows={}, cost=1)     &gt;&gt;&gt; g.add_edge('B', 'C', capacity=5.0, flow=0.0, flows={}, cost=1)     &gt;&gt;&gt;     &gt;&gt;&gt; # Basic usage (scalar return)     &gt;&gt;&gt; max_flow_value = calc_max_flow(g, 'A', 'C')     &gt;&gt;&gt; print(max_flow_value)     5.0     &gt;&gt;&gt;     &gt;&gt;&gt; # With flow summary analytics     &gt;&gt;&gt; flow, summary = calc_max_flow(g, 'A', 'C', return_summary=True)     &gt;&gt;&gt; print(f\"Min-cut edges: {summary.min_cut}\")     &gt;&gt;&gt;     &gt;&gt;&gt; # With both summary and mutated graph     &gt;&gt;&gt; flow, summary, flow_graph = calc_max_flow(     ...     g, 'A', 'C', return_summary=True, return_graph=True     ... )     &gt;&gt;&gt; # flow_graph contains the flow assignments</p>","text":""},{"location":"reference/api-full/#run_sensitivitygraph-ngraphgraphstrict_multidigraphstrictmultidigraph-src_node-hashable-dst_node-hashable-capacity_attr-str-capacity-flow_attr-str-flow-change_amount-float-10-kwargs-dicttuple-float","title":"run_sensitivity(graph: ngraph.graph.strict_multidigraph.StrictMultiDiGraph, src_node: Hashable, dst_node: Hashable, , capacity_attr: str = 'capacity', flow_attr: str = 'flow', change_amount: float = 1.0, *kwargs) -&gt; dict[tuple, float] <p>Simple sensitivity analysis for per-edge capacity changes.</p> <p>Tests changing each saturated edge capacity by change_amount and measures the resulting change in total flow. Positive values increase capacity, negative values decrease capacity (with validation to prevent negative capacities).</p> <p>Args:     graph: The graph to analyze     src_node: Source node     dst_node: Destination node     capacity_attr: Name of capacity attribute     flow_attr: Name of flow attribute     change_amount: Amount to change capacity for testing (positive=increase, negative=decrease)     **kwargs: Additional arguments passed to calc_max_flow</p> <p>Returns:     dict[tuple, float]: Flow delta per modified edge.</p>","text":""},{"location":"reference/api-full/#saturated_edgesgraph-ngraphgraphstrict_multidigraphstrictmultidigraph-src_node-hashable-dst_node-hashable-capacity_attr-str-capacity-flow_attr-str-flow-tolerance-float-1e-10-kwargs-listtuple","title":"saturated_edges(graph: ngraph.graph.strict_multidigraph.StrictMultiDiGraph, src_node: Hashable, dst_node: Hashable, , capacity_attr: str = 'capacity', flow_attr: str = 'flow', tolerance: float = 1e-10, *kwargs) -&gt; list[tuple] <p>Identify saturated edges in the max-flow solution.</p> <p>Args:     graph: The graph to analyze     src_node: Source node     dst_node: Destination node     capacity_attr: Name of capacity attribute     flow_attr: Name of flow attribute     tolerance: Tolerance for considering an edge saturated     **kwargs: Additional arguments passed to calc_max_flow</p> <p>Returns:     list[tuple]: Edges <code>(u, v, k)</code> with residual capacity &lt;= <code>tolerance</code>.</p>","text":""},{"location":"reference/api-full/#ngraphalgorithmspaths","title":"ngraph.algorithms.paths","text":"<p>Path manipulation utilities.</p> <p>Provides helpers to enumerate realized paths from a predecessor map produced by SPF/KSP, with optional expansion of parallel edges into distinct paths.</p>"},{"location":"reference/api-full/#resolve_to_pathssrc_node-nodeid-dst_node-nodeid-pred-dictnodeid-dictnodeid-listedgeid-split_parallel_edges-bool-false-iteratorpathtuple","title":"resolve_to_paths(src_node: 'NodeID', dst_node: 'NodeID', pred: 'Dict[NodeID, Dict[NodeID, List[EdgeID]]]', split_parallel_edges: 'bool' = False) -&gt; 'Iterator[PathTuple]' <p>Enumerate all paths from a predecessor map.</p> <p>Args:     src_node: Source node ID.     dst_node: Destination node ID.     pred: Predecessor map from SPF or KSP.     split_parallel_edges: If True, expand parallel edges into distinct paths.</p> <p>Yields:     PathTuple: Sequence of <code>(node_id, (edge_ids,))</code> pairs from source to dest.</p>","text":""},{"location":"reference/api-full/#ngraphalgorithmsplacement","title":"ngraph.algorithms.placement","text":"<p>Flow placement for routing over equal-cost predecessor DAGs.</p> <p>Places feasible flow on a graph given predecessor relations and a placement strategy, updating aggregate and per-flow attributes.</p>"},{"location":"reference/api-full/#flowplacementmeta","title":"FlowPlacementMeta <p>Metadata describing how flow was placed on the graph.</p> <p>Attributes:     placed_flow: The amount of flow actually placed.     remaining_flow: The portion of flow that could not be placed due to capacity limits.     nodes: Set of node IDs that participated in the flow.     edges: Set of edge IDs that carried some portion of this flow.</p> <p>Attributes:</p> <ul> <li><code>placed_flow</code> (float)</li> <li><code>remaining_flow</code> (float)</li> <li><code>nodes</code> (Set[NodeID]) = set()</li> <li><code>edges</code> (Set[EdgeID]) = set()</li> </ul>","text":""},{"location":"reference/api-full/#place_flow_on_graphflow_graph-strictmultidigraph-src_node-nodeid-dst_node-nodeid-pred-dictnodeid-dictnodeid-listedgeid-flow-float-inf-flow_index-optionalhashable-none-flow_placement-flowplacement-capacity_attr-str-capacity-flow_attr-str-flow-flows_attr-str-flows-flowplacementmeta","title":"place_flow_on_graph(flow_graph: 'StrictMultiDiGraph', src_node: 'NodeID', dst_node: 'NodeID', pred: 'Dict[NodeID, Dict[NodeID, List[EdgeID]]]', flow: 'float' = inf, flow_index: 'Optional[Hashable]' = None, flow_placement: 'FlowPlacement' = , capacity_attr: 'str' = 'capacity', flow_attr: 'str' = 'flow', flows_attr: 'str' = 'flows') -&gt; 'FlowPlacementMeta' <p>Place flow from <code>src_node</code> to <code>dst_node</code> on <code>flow_graph</code>.</p> <p>Uses a precomputed <code>flow_dict</code> from <code>calc_graph_capacity</code> to figure out how much flow can be placed. Updates the graph's edges and nodes with the placed flow.</p> <p>Args:     flow_graph: The graph on which flow will be placed.     src_node: The source node.     dst_node: The destination node.     pred: A dictionary of node-&gt;(adj_node-&gt;list_of_edge_IDs) giving path adjacency.     flow: Requested flow amount; can be infinite.     flow_index: Identifier for this flow (used to track multiple flows).     flow_placement: Strategy for distributing flow among parallel equal cost paths.     capacity_attr: Attribute name on edges for capacity.     flow_attr: Attribute name on edges/nodes for aggregated flow.     flows_attr: Attribute name on edges/nodes for per-flow tracking.</p> <p>Returns:     FlowPlacementMeta: Amount placed, remaining amount, and touched nodes/edges.</p>","text":""},{"location":"reference/api-full/#remove_flow_from_graphflow_graph-strictmultidigraph-flow_index-optionalhashable-none-flow_attr-str-flow-flows_attr-str-flows-none","title":"remove_flow_from_graph(flow_graph: 'StrictMultiDiGraph', flow_index: 'Optional[Hashable]' = None, flow_attr: 'str' = 'flow', flows_attr: 'str' = 'flows') -&gt; 'None' <p>Remove one or all flows from the graph.</p> <p>Args:     flow_graph: Graph whose edge flow attributes will be modified.     flow_index: If provided, remove only the specified flow; otherwise remove all.     flow_attr: Aggregate flow attribute name on edges.     flows_attr: Per-flow attribute name on edges.</p>","text":""},{"location":"reference/api-full/#ngraphalgorithmsspf","title":"ngraph.algorithms.spf","text":"<p>Shortest-path-first (SPF) algorithms.</p> <p>Implements Dijkstra-like SPF with pluggable edge-selection policies and a Yen-like KSP generator. Specialized fast paths exist for common selection strategies without exclusions.</p> <p>Notes:     When a destination node is known, SPF supports an optimized mode that     terminates once the destination's minimal distance is settled. In this mode:</p> <ul> <li>The destination node is not expanded (no neighbor relaxation from <code>dst</code>).</li> <li> <p>The algorithm continues processing any nodes with equal distance to capture</p> <p>equal-cost predecessors (needed by proportional flow placement).</p> </li> </ul>"},{"location":"reference/api-full/#kspgraph-ngraphgraphstrict_multidigraphstrictmultidigraph-src_node-hashable-dst_node-hashable-edge_select-ngraphalgorithmsbaseedgeselect-edge_select_func-optionalcallablengraphgraphstrict_multidigraphstrictmultidigraph-hashable-hashable-dicthashable-dictstr-any-sethashable-sethashable-tupleunionint-float-listhashable-none-max_k-optionalint-none-max_path_cost-unionint-float-inf-max_path_cost_factor-optionalfloat-none-multipath-bool-true-excluded_edges-optionalsethashable-none-excluded_nodes-optionalsethashable-none-iteratortupledicthashable-unionint-float-dicthashable-dicthashable-listhashable","title":"ksp(graph: ngraph.graph.strict_multidigraph.StrictMultiDiGraph, src_node: Hashable, dst_node: Hashable, edge_select: ngraph.algorithms.base.EdgeSelect = , edge_select_func: Optional[Callable[[ngraph.graph.strict_multidigraph.StrictMultiDiGraph, Hashable, Hashable, Dict[Hashable, Dict[str, Any]], Set[Hashable], Set[Hashable]], Tuple[Union[int, float], List[Hashable]]]] = None, max_k: Optional[int] = None, max_path_cost: Union[int, float] = inf, max_path_cost_factor: Optional[float] = None, multipath: bool = True, excluded_edges: Optional[Set[Hashable]] = None, excluded_nodes: Optional[Set[Hashable]] = None) -&gt; Iterator[Tuple[Dict[Hashable, Union[int, float]], Dict[Hashable, Dict[Hashable, List[Hashable]]]]] <p>Yield up to k shortest paths using a Yen-like algorithm.</p> <p>The initial SPF (shortest path) is computed; subsequent paths are found by systematically excluding edges/nodes used by previously generated paths. Each iteration yields a (costs, pred) describing one path. Stops if there are no more valid paths or if max_k is reached.</p> <p>Args:     graph: The directed graph (StrictMultiDiGraph).     src_node: The source node.     dst_node: The destination node.     edge_select: The edge selection strategy. Defaults to ALL_MIN_COST.     edge_select_func: Optional override of the default edge selection function.     max_k: If set, yields at most k distinct paths.     max_path_cost: If set, do not yield any path whose total cost &gt; max_path_cost.     max_path_cost_factor: If set, updates max_path_cost to:         min(max_path_cost, best_path_cost * max_path_cost_factor).     multipath: Whether to consider multiple same-cost expansions in SPF.     excluded_edges: Set of edge IDs to exclude globally.     excluded_nodes: Set of node IDs to exclude globally.</p> <p>Yields:     Tuple of <code>(costs, pred)</code> per discovered path in ascending cost order.</p>","text":""},{"location":"reference/api-full/#spfgraph-ngraphgraphstrict_multidigraphstrictmultidigraph-src_node-hashable-edge_select-ngraphalgorithmsbaseedgeselect-edge_select_func-optionalcallablengraphgraphstrict_multidigraphstrictmultidigraph-hashable-hashable-dicthashable-dictstr-any-sethashable-sethashable-tupleunionint-float-listhashable-none-multipath-bool-true-excluded_edges-optionalsethashable-none-excluded_nodes-optionalsethashable-none-dst_node-optionalhashable-none-tupledicthashable-unionint-float-dicthashable-dicthashable-listhashable","title":"spf(graph: ngraph.graph.strict_multidigraph.StrictMultiDiGraph, src_node: Hashable, edge_select: ngraph.algorithms.base.EdgeSelect = , edge_select_func: Optional[Callable[[ngraph.graph.strict_multidigraph.StrictMultiDiGraph, Hashable, Hashable, Dict[Hashable, Dict[str, Any]], Set[Hashable], Set[Hashable]], Tuple[Union[int, float], List[Hashable]]]] = None, multipath: bool = True, excluded_edges: Optional[Set[Hashable]] = None, excluded_nodes: Optional[Set[Hashable]] = None, dst_node: Optional[Hashable] = None) -&gt; Tuple[Dict[Hashable, Union[int, float]], Dict[Hashable, Dict[Hashable, List[Hashable]]]] <p>Compute shortest paths from a source node.</p> <p>By default, uses EdgeSelect.ALL_MIN_COST. If multipath=True, multiple equal-cost paths to the same node will be recorded in the predecessor structure. If no excluded edges/nodes are given and edge_select is one of the specialized (ALL_MIN_COST or ALL_MIN_COST_WITH_CAP_REMAINING), it uses a fast specialized routine.</p> <p>Args:     graph: The directed graph (StrictMultiDiGraph).     src_node: The source node from which to compute shortest paths.     edge_select: The edge selection strategy. Defaults to ALL_MIN_COST.     edge_select_func: If provided, overrides the default edge selection function.         Must return (cost, list_of_edges) for the given node-&gt;neighbor adjacency.     multipath: Whether to record multiple same-cost paths.     excluded_edges: A set of edge IDs to ignore in the graph.     excluded_nodes: A set of node IDs to ignore in the graph.     dst_node: Optional destination node. If provided, SPF avoids expanding         from the destination and performs early termination once the next         candidate in the heap would exceed the settled distance for         <code>dst_node</code>. This preserves equal-cost predecessors while avoiding         unnecessary relaxations beyond the destination.</p> <p>Returns:     tuple[dict[NodeID, Cost], dict[NodeID, dict[NodeID, list[EdgeID]]]]:         Costs and predecessor mapping.</p> <p>Raises:     KeyError: If src_node does not exist in graph.</p>","text":""},{"location":"reference/api-full/#ngraphalgorithmstypes","title":"ngraph.algorithms.types","text":"<p>Types and data structures for algorithm analytics.</p> <p>Defines immutable summary containers and aliases for algorithm outputs.</p>"},{"location":"reference/api-full/#flowsummary","title":"FlowSummary <p>Summary of max-flow computation results.</p> <p>Captures edge flows, residual capacities, reachable set, and min-cut.</p> <p>Attributes:     total_flow: Maximum flow value achieved.     edge_flow: Flow amount per edge, indexed by <code>(src, dst, key)</code>.     residual_cap: Remaining capacity per edge after placement.     reachable: Nodes reachable from source in residual graph.     min_cut: Saturated edges crossing the s-t cut.     cost_distribution: Mapping of path cost to flow volume placed at that cost.</p> <p>Attributes:</p> <ul> <li><code>total_flow</code> (float)</li> <li><code>edge_flow</code> (Dict[Edge, float])</li> <li><code>residual_cap</code> (Dict[Edge, float])</li> <li><code>reachable</code> (Set[str])</li> <li><code>min_cut</code> (List[Edge])</li> <li><code>cost_distribution</code> (Dict[Cost, float])</li> </ul>","text":""},{"location":"reference/api-full/#ngraphpathsbundle","title":"ngraph.paths.bundle","text":"<p>Utilities for compact representation of equal-cost path sets.</p> <p>This module defines <code>PathBundle</code>, a structure that represents one or more equal-cost paths between two nodes using a predecessor map. It supports concatenation, containment checks, sub-bundle extraction with cost recalculation, and enumeration into concrete <code>Path</code> instances.</p>"},{"location":"reference/api-full/#pathbundle","title":"PathBundle <p>A collection of equal-cost paths between two nodes.</p> <p>This class encapsulates one or more parallel paths (all of the same cost) between <code>src_node</code> and <code>dst_node</code>. The predecessor map <code>pred</code> associates each node with the node(s) from which it can be reached, along with a list of edge IDs used in that step. The constructor performs a reverse traversal from <code>dst_node</code> to <code>src_node</code> to collect all edges, nodes, and store them in this bundle.</p> <p>The constructor assumes the predecessor relation forms a DAG between <code>src_node</code> and <code>dst_node</code>. No cycle detection is performed. If cycles are present, traversal may not terminate.</p> <p>Methods:</p> <ul> <li><code>add(self, other: 'PathBundle') -&gt; 'PathBundle'</code> - Concatenate this bundle with another bundle (end-to-start).</li> <li><code>contains(self, other: 'PathBundle') -&gt; 'bool'</code> - Check if this bundle's edge set contains all edges of <code>other</code>.</li> <li><code>from_path(path: 'Path', resolve_edges: 'bool' = False, graph: 'Optional[StrictMultiDiGraph]' = None, edge_select: 'Optional[EdgeSelect]' = None, cost_attr: 'str' = 'cost', capacity_attr: 'str' = 'capacity') -&gt; 'PathBundle'</code> - Construct a PathBundle from a single <code>Path</code> object.</li> <li><code>get_sub_path_bundle(self, new_dst_node: 'NodeID', graph: 'StrictMultiDiGraph', cost_attr: 'str' = 'cost') -&gt; 'PathBundle'</code> - Create a sub-bundle ending at <code>new_dst_node</code> with correct minimal cost.</li> <li><code>is_disjoint_from(self, other: 'PathBundle') -&gt; 'bool'</code> - Check if this bundle shares no edges with <code>other</code>.</li> <li><code>is_subset_of(self, other: 'PathBundle') -&gt; 'bool'</code> - Check if this bundle's edge set is contained in <code>other</code>'s edge set.</li> <li><code>resolve_to_paths(self, split_parallel_edges: 'bool' = False) -&gt; 'Iterator[Path]'</code> - Generate all concrete <code>Path</code> objects contained in this PathBundle.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphpathspath","title":"ngraph.paths.path","text":"<p>Lightweight representation of a single routing path.</p> <p>The <code>Path</code> dataclass stores a node-and-parallel-edges sequence and a numeric cost. Cached properties expose derived sequences for nodes and edges, and helpers provide equality, ordering by cost, and sub-path extraction with cost recalculation.</p>"},{"location":"reference/api-full/#path","title":"Path <p>Represents a single path in the network.</p> <p>Attributes:     path_tuple (PathTuple):         A sequence of path elements. Each element is a tuple of the form         (node_id, (edge_id_1, edge_id_2, ...)), where the final element typically has an empty tuple.     cost (Cost):         The total numeric cost (e.g., distance or metric) of the path.     edges (Set[EdgeID]):         A set of all edge IDs encountered in the path.     nodes (Set[NodeID]):         A set of all node IDs encountered in the path.     edge_tuples (Set[Tuple[EdgeID, ...]]):         A set of all tuples of parallel edges from each path element (including the final empty tuple).</p> <p>Attributes:</p> <ul> <li><code>path_tuple</code> (PathTuple)</li> <li><code>cost</code> (Cost)</li> <li><code>edges</code> (Set[EdgeID]) = set()</li> <li><code>nodes</code> (Set[NodeID]) = set()</li> <li><code>edge_tuples</code> (Set[Tuple[EdgeID, ...]]) = set()</li> </ul> <p>Methods:</p> <ul> <li><code>get_sub_path(self, dst_node: 'NodeID', graph: 'StrictMultiDiGraph', cost_attr: 'str' = 'cost') -&gt; 'Path'</code> - Create a sub-path ending at the specified destination node, recalculating the cost.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphflowsflow","title":"ngraph.flows.flow","text":"<p>Flow and FlowIndex classes for traffic flow representation.</p>"},{"location":"reference/api-full/#flow","title":"Flow <p>Represents a fraction of demand routed along a given PathBundle.</p> <p>In traffic-engineering scenarios, a <code>Flow</code> object can model:</p> <ul> <li>MPLS LSPs/tunnels with explicit paths,</li> <li>IP forwarding behavior (with ECMP or WCMP),</li> <li>Or anything that follows a specific set of paths.</li> </ul> <p>Methods:</p> <ul> <li><code>place_flow(self, flow_graph: 'StrictMultiDiGraph', to_place: 'float', flow_placement: 'FlowPlacement') -&gt; 'Tuple[float, float]'</code> - Place or update this flow on the graph.</li> <li><code>remove_flow(self, flow_graph: 'StrictMultiDiGraph') -&gt; 'None'</code> - Remove this flow from the graph.</li> </ul>","text":""},{"location":"reference/api-full/#flowindex","title":"FlowIndex <p>Unique identifier for a flow.</p> <p>Attributes:     src_node: Source node.     dst_node: Destination node.     flow_class: Flow class label (hashable).     flow_id: Monotonic integer id for this flow.</p>","text":""},{"location":"reference/api-full/#ngraphflowspolicy","title":"ngraph.flows.policy","text":"<p>FlowPolicy and FlowPolicyConfig classes for traffic routing algorithms.</p>"},{"location":"reference/api-full/#flowpolicy","title":"FlowPolicy <p>Create, place, rebalance, and remove flows on a network graph.</p> <p>Converts a demand into one or more <code>Flow</code> objects subject to capacity constraints and configuration: path selection, edge selection, and flow placement method.</p> <p>Methods:</p> <ul> <li><code>deep_copy(self) -&gt; 'FlowPolicy'</code> - Return a deep copy of this policy including flows.</li> <li><code>get_metrics(self) -&gt; 'Dict[str, float]'</code> - Return cumulative placement metrics for this policy instance.</li> <li><code>place_demand(self, flow_graph: 'StrictMultiDiGraph', src_node: 'NodeID', dst_node: 'NodeID', flow_class: 'Hashable', volume: 'float', target_flow_volume: 'Optional[float]' = None, min_flow: 'Optional[float]' = None) -&gt; 'Tuple[float, float]'</code> - Place demand volume on the graph by splitting or creating flows as needed.</li> <li><code>rebalance_demand(self, flow_graph: 'StrictMultiDiGraph', src_node: 'NodeID', dst_node: 'NodeID', flow_class: 'Hashable', target_flow_volume: 'float') -&gt; 'Tuple[float, float]'</code> - Rebalance demand across existing flows towards the target volume per flow.</li> <li><code>remove_demand(self, flow_graph: 'StrictMultiDiGraph') -&gt; 'None'</code> - Removes all flows from the network graph without clearing internal state.</li> </ul>","text":""},{"location":"reference/api-full/#flowpolicyconfig","title":"FlowPolicyConfig <p>Enumerates supported flow policy configurations.</p>","text":""},{"location":"reference/api-full/#get_flow_policyflow_policy_config-flowpolicyconfig-flowpolicy","title":"get_flow_policy(flow_policy_config: 'FlowPolicyConfig') -&gt; 'FlowPolicy' <p>Create a policy instance from a configuration preset.</p> <p>Args:     flow_policy_config: A FlowPolicyConfig enum value specifying the desired policy.</p> <p>Returns:     FlowPolicy: Pre-configured policy instance.</p> <p>Raises:     ValueError: If an unknown FlowPolicyConfig value is provided.</p>","text":""},{"location":"reference/api-full/#ngraphsolverhelpers","title":"ngraph.solver.helpers","text":""},{"location":"reference/api-full/#ngraphsolvermaxflow","title":"ngraph.solver.maxflow","text":"<p>Problem-level max-flow API bound to the model layer.</p> <p>Functions here operate on a model context that provides:</p> <ul> <li>to_strict_multidigraph(add_reverse: bool = True) -&gt; StrictMultiDiGraph</li> <li>select_node_groups_by_path(path: str) -&gt; dict[str, list[Node]]</li> </ul> <p>They accept either a <code>Network</code> or a <code>NetworkView</code>. The input context is not mutated. Pseudo source and sink nodes are attached on a working graph when computing flows between groups.</p>"},{"location":"reference/api-full/#max_flowcontext-any-source_path-str-sink_path-str-mode-str-combine-shortest_path-bool-false-flow_placement-flowplacement-dicttuplestr-str-float","title":"max_flow(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = ) -&gt; 'Dict[Tuple[str, str], float]' <p>Compute max flow between groups selected from the context.</p> <p>Creates a working graph from the context, adds a pseudo source attached to the selected source nodes and a pseudo sink attached to the selected sink nodes, then runs the max-flow routine.</p> <p>Args:     context: <code>Network</code> or <code>NetworkView</code> providing selection and graph APIs.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: Aggregation strategy. \"combine\" considers all sources as one         group and all sinks as one group. \"pairwise\" evaluates each         source-label and sink-label pair separately.     shortest_path: If True, perform a single augmentation along the first         shortest path instead of the full max-flow.     flow_placement: Strategy for splitting flow among equal-cost parallel         edges.</p> <p>Returns:     Dict[Tuple[str, str], float]: Total flow per (source_label, sink_label).</p> <p>Raises:     ValueError: If no matching sources or sinks are found, or if <code>mode</code>         is not one of {\"combine\", \"pairwise\"}.</p>","text":""},{"location":"reference/api-full/#max_flow_detailedcontext-any-source_path-str-sink_path-str-mode-str-combine-shortest_path-bool-false-flow_placement-flowplacement-dicttuplestr-str-tuplefloat-flowsummary-strictmultidigraph","title":"max_flow_detailed(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = ) -&gt; \"Dict[Tuple[str, str], Tuple[float, FlowSummary, 'StrictMultiDiGraph']]\" <p>Compute max flow, return summary and flow graph for each pair.</p> <p>Args:     context: <code>Network</code> or <code>NetworkView</code> providing selection and graph APIs.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"combine\" or \"pairwise\". See <code>max_flow</code>.     shortest_path: If True, perform only one augmentation step.     flow_placement: Strategy for splitting among equal-cost parallel edges.</p> <p>Returns:     Dict[Tuple[str, str], Tuple[float, FlowSummary, StrictMultiDiGraph]]:     For each (source_label, sink_label), the total flow, a summary, and the     flow-assigned graph.</p> <p>Raises:     ValueError: If no matching sources or sinks are found, or if <code>mode</code>         is invalid.</p>","text":""},{"location":"reference/api-full/#max_flow_with_graphcontext-any-source_path-str-sink_path-str-mode-str-combine-shortest_path-bool-false-flow_placement-flowplacement-dicttuplestr-str-tuplefloat-strictmultidigraph","title":"max_flow_with_graph(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = ) -&gt; \"Dict[Tuple[str, str], Tuple[float, 'StrictMultiDiGraph']]\" <p>Compute max flow and return the mutated flow graph for each pair.</p> <p>Args:     context: <code>Network</code> or <code>NetworkView</code> providing selection and graph APIs.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"combine\" or \"pairwise\". See <code>max_flow</code>.     shortest_path: If True, perform only one augmentation step.     flow_placement: Strategy for splitting among equal-cost parallel edges.</p> <p>Returns:     Dict[Tuple[str, str], Tuple[float, StrictMultiDiGraph]]: For each     (source_label, sink_label), the total flow and the flow-assigned graph.</p> <p>Raises:     ValueError: If no matching sources or sinks are found, or if <code>mode</code>         is invalid.</p>","text":""},{"location":"reference/api-full/#max_flow_with_summarycontext-any-source_path-str-sink_path-str-mode-str-combine-shortest_path-bool-false-flow_placement-flowplacement-dicttuplestr-str-tuplefloat-flowsummary","title":"max_flow_with_summary(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = ) -&gt; 'Dict[Tuple[str, str], Tuple[float, FlowSummary]]' <p>Compute max flow and return a summary for each group pair.</p> <p>The summary includes total flow, per-edge flow, residual capacity, reachable set from the source in the residual graph, min-cut edges, and a cost distribution over augmentation steps.</p> <p>Args:     context: <code>Network</code> or <code>NetworkView</code> providing selection and graph APIs.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"combine\" or \"pairwise\". See <code>max_flow</code>.     shortest_path: If True, perform only one augmentation step.     flow_placement: Strategy for splitting among equal-cost parallel edges.</p> <p>Returns:     Dict[Tuple[str, str], Tuple[float, FlowSummary]]: For each     (source_label, sink_label), the total flow and the associated summary.</p> <p>Raises:     ValueError: If no matching sources or sinks are found, or if <code>mode</code>         is invalid.</p>","text":""},{"location":"reference/api-full/#saturated_edgescontext-any-source_path-str-sink_path-str-mode-str-combine-tolerance-float-1e-10-shortest_path-bool-false-flow_placement-flowplacement-dicttuplestr-str-listtuplestr-str-str","title":"saturated_edges(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', tolerance: 'float' = 1e-10, shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = ) -&gt; 'Dict[Tuple[str, str], List[Tuple[str, str, str]]]' <p>Identify saturated edges for each selected group pair.</p> <p>Args:     context: <code>Network</code> or <code>NetworkView</code> providing selection and graph APIs.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"combine\" or \"pairwise\". See <code>max_flow</code>.     tolerance: Residual capacity threshold to consider an edge saturated.     shortest_path: If True, perform only one augmentation step.     flow_placement: Strategy for splitting among equal-cost parallel edges.</p> <p>Returns:     Dict[Tuple[str, str], list[tuple[str, str, str]]]: For each     (source_label, sink_label), a list of saturated edges <code>(u, v, k)</code>.</p> <p>Raises:     ValueError: If no matching sources or sinks are found, or if <code>mode</code>         is invalid.</p>","text":""},{"location":"reference/api-full/#sensitivity_analysiscontext-any-source_path-str-sink_path-str-mode-str-combine-change_amount-float-10-shortest_path-bool-false-flow_placement-flowplacement-dicttuplestr-str-dicttuplestr-str-str-float","title":"sensitivity_analysis(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', change_amount: 'float' = 1.0, shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = ) -&gt; 'Dict[Tuple[str, str], Dict[Tuple[str, str, str], float]]' <p>Perform a simple sensitivity analysis per saturated edge.</p> <p>For each saturated edge, test a capacity change of <code>change_amount</code> and report the change in total flow. Positive amounts increase capacity; negative amounts decrease capacity (with lower bound at zero).</p> <p>Args:     context: <code>Network</code> or <code>NetworkView</code> providing selection and graph APIs.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"combine\" or \"pairwise\". See <code>max_flow</code>.     change_amount: Capacity delta to apply when testing each saturated edge.     shortest_path: If True, perform only one augmentation step.     flow_placement: Strategy for splitting among equal-cost parallel edges.</p> <p>Returns:     Dict[Tuple[str, str], Dict[Tuple[str, str, str], float]]: For each     (source_label, sink_label), a mapping from saturated edge <code>(u, v, k)</code>     to the change in total flow after applying the capacity delta.</p> <p>Raises:     ValueError: If no matching sources or sinks are found, or if <code>mode</code>         is invalid.</p>","text":""},{"location":"reference/api-full/#ngraphsolverpaths","title":"ngraph.solver.paths","text":"<p>Shortest-path solver wrappers bound to the model layer.</p> <p>Expose convenience functions for computing shortest paths between node groups selected from a <code>Network</code> or <code>NetworkView</code> context. Selection semantics mirror the max-flow wrappers with <code>mode</code> in {\"combine\", \"pairwise\"}.</p> <p>Functions return minimal costs or concrete <code>Path</code> objects built from SPF predecessor maps. Parallel equal-cost edges can be expanded into distinct paths.</p> <p>All functions fail fast on invalid selection inputs and do not mutate the input context.</p> <p>Note:     For path queries, overlapping source/sink membership is treated as     unreachable.</p>"},{"location":"reference/api-full/#k_shortest_pathscontext-any-source_path-str-sink_path-str-mode-str-pairwise-max_k-int-3-edge_select-edgeselect-max_path_cost-float-inf-max_path_cost_factor-optionalfloat-none-split_parallel_edges-bool-false-dicttuplestr-str-listpath","title":"k_shortest_paths(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'pairwise', max_k: 'int' = 3, edge_select: 'EdgeSelect' = , max_path_cost: 'float' = inf, max_path_cost_factor: 'Optional[float]' = None, split_parallel_edges: 'bool' = False) -&gt; 'Dict[Tuple[str, str], List[Path]]' <p>Return up to K shortest paths per group pair.</p> <p>Args:     context: Network or NetworkView.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"pairwise\" (default) or \"combine\".     max_k: Max paths per pair.     edge_select: SPF/KSP edge selection strategy.     max_path_cost: Absolute cost threshold.     max_path_cost_factor: Relative threshold versus best path.     split_parallel_edges: Expand parallel edges into distinct paths when True.</p> <p>Returns:     Mapping from (source_label, sink_label) to list of Path (&lt;= max_k).</p> <p>Raises:     ValueError: If no source nodes match <code>source_path</code>.     ValueError: If no sink nodes match <code>sink_path</code>.     ValueError: If <code>mode</code> is not \"combine\" or \"pairwise\".</p>","text":""},{"location":"reference/api-full/#shortest_path_costscontext-any-source_path-str-sink_path-str-mode-str-combine-edge_select-edgeselect-dicttuplestr-str-float","title":"shortest_path_costs(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', edge_select: 'EdgeSelect' = ) -&gt; 'Dict[Tuple[str, str], float]' <p>Return minimal path cost(s) between selected node groups.</p> <p>Args:     context: Network or NetworkView.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"combine\" or \"pairwise\".     edge_select: SPF edge selection strategy.</p> <p>Returns:     Mapping from (source_label, sink_label) to minimal cost; <code>inf</code> if no     path.</p> <p>Raises:     ValueError: If no source nodes match <code>source_path</code>.     ValueError: If no sink nodes match <code>sink_path</code>.     ValueError: If <code>mode</code> is not \"combine\" or \"pairwise\".</p>","text":""},{"location":"reference/api-full/#shortest_pathscontext-any-source_path-str-sink_path-str-mode-str-combine-edge_select-edgeselect-split_parallel_edges-bool-false-dicttuplestr-str-listpath","title":"shortest_paths(context: 'Any', source_path: 'str', sink_path: 'str', *, mode: 'str' = 'combine', edge_select: 'EdgeSelect' = , split_parallel_edges: 'bool' = False) -&gt; 'Dict[Tuple[str, str], List[Path]]' <p>Return concrete shortest path(s) between selected node groups.</p> <p>Args:     context: Network or NetworkView.     source_path: Selection expression for source groups.     sink_path: Selection expression for sink groups.     mode: \"combine\" or \"pairwise\".     edge_select: SPF edge selection strategy.     split_parallel_edges: Expand parallel edges into distinct paths when True.</p> <p>Returns:     Mapping from (source_label, sink_label) to list of Path. Empty if     unreachable.</p> <p>Raises:     ValueError: If no source nodes match <code>source_path</code>.     ValueError: If no sink nodes match <code>sink_path</code>.     ValueError: If <code>mode</code> is not \"combine\" or \"pairwise\".</p>","text":""},{"location":"reference/api-full/#ngraphdemandmanagerbuilder","title":"ngraph.demand.manager.builder","text":"<p>Builders for traffic matrices.</p> <p>Construct <code>TrafficMatrixSet</code> from raw dictionaries (e.g. parsed YAML). This logic was previously embedded in <code>Scenario.from_yaml</code>.</p>"},{"location":"reference/api-full/#build_traffic_matrix_setraw-dictstr-listdict-trafficmatrixset","title":"build_traffic_matrix_set(raw: 'Dict[str, List[dict]]') -&gt; 'TrafficMatrixSet' <p>Build a <code>TrafficMatrixSet</code> from a mapping of name -&gt; list of dicts.</p> <p>Args:     raw: Mapping where each key is a matrix name and each value is a list of         dictionaries with <code>TrafficDemand</code> constructor fields.</p> <p>Returns:     Initialized <code>TrafficMatrixSet</code> with constructed <code>TrafficDemand</code> objects.</p> <p>Raises:     ValueError: If <code>raw</code> is not a mapping of name -&gt; list[dict].</p>","text":""},{"location":"reference/api-full/#ngraphdemandmanagerexpand","title":"ngraph.demand.manager.expand","text":"<p>Expansion helpers for traffic demand specifications.</p> <p>Public functions here convert user-facing <code>TrafficDemand</code> specifications into concrete <code>Demand</code> objects that can be placed on a <code>StrictMultiDiGraph</code>.</p> <p>This module provides the pure expansion logic that was previously embedded in <code>TrafficManager</code>.</p>"},{"location":"reference/api-full/#expand_demandsnetwork-unionnetwork-networkview-graph-strictmultidigraph-none-traffic_demands-listtrafficdemand-default_flow_policy_config-flowpolicyconfig-tuplelistdemand-dictstr-listdemand","title":"expand_demands(network: \"Union[Network, 'NetworkView']\", graph: 'StrictMultiDiGraph | None', traffic_demands: 'List[TrafficDemand]', default_flow_policy_config: 'FlowPolicyConfig') -&gt; 'Tuple[List[Demand], Dict[str, List[Demand]]]' <p>Expand traffic demands into concrete <code>Demand</code> objects.</p> <p>The result is a flat list of <code>Demand</code> plus a mapping from <code>TrafficDemand.id</code> to the list of expanded demands for that entry.</p> <p>Args:     network: Network or NetworkView used for node group selection.     graph: Flow graph to operate on. If <code>None</code>, expansion that requires         graph mutation (pseudo nodes/edges) is skipped.     traffic_demands: List of high-level traffic demand specifications.     default_flow_policy_config: Default policy to apply when a demand does         not specify an explicit <code>flow_policy</code>.</p> <p>Returns:     A tuple <code>(expanded, td_map)</code> where:</p> <ul> <li> <p><code>expanded</code> is the flattened, sorted list of all expanded demands</p> <p>(sorted by ascending <code>demand_class</code>).</p> </li> <li> <p><code>td_map</code> maps <code>TrafficDemand.id</code> to its expanded demands.</p> </li> </ul>","text":""},{"location":"reference/api-full/#ngraphdemandmanagermanager","title":"ngraph.demand.manager.manager","text":"<p>Traffic demand management and placement.</p> <p><code>TrafficManager</code> expands <code>TrafficDemand</code> specs into concrete <code>Demand</code> objects, builds a working <code>StrictMultiDiGraph</code> from a <code>Network</code>, and places flows via per-demand <code>FlowPolicy</code> instances.</p>"},{"location":"reference/api-full/#trafficmanager","title":"TrafficManager <p>Manage expansion and placement of traffic demands on a <code>Network</code>.</p> <p>This class:</p> <p>1) Builds (or rebuilds) a StrictMultiDiGraph from the given Network.    2) Expands each TrafficDemand into one or more Demand objects based       on a configurable 'mode' (\"combine\" or \"pairwise\").   3) Each Demand is associated with a FlowPolicy, which handles how flows      are placed (split across paths, balancing, etc.).      4) Provides methods to place all demands incrementally with optional       re-optimization, reset usage, and retrieve flow/usage summaries.</p> <p>Auto rounds semantics:</p> <ul> <li> <p>placement_rounds=\"auto\" performs up to a small number of fairness passes</p> <p>(at most 3), with early stop when diminishing returns are detected. Each  pass asks the scheduler to place full leftovers without step splitting.</p> </li> </ul> <p>In particular:</p> <ul> <li>'combine' mode:</li> <li> <p>Combine all matched sources into a single pseudo-source node, and all</p> <p>matched sinks into a single pseudo-sink node (named using the traffic   demand's <code>source_path</code> and <code>sink_path</code>). A single Demand is created   from the pseudo-source to the pseudo-sink, with the full volume.</p> </li> <li> <p>'pairwise' mode:</p> </li> <li> <p>All matched sources form one group, all matched sinks form another group.</p> <p>A separate Demand is created for each (src_node, dst_node) pair,   skipping self-pairs. The total volume is split evenly across the pairs.</p> </li> </ul> <p>The sum of volumes of all expanded Demands for a given TrafficDemand matches that TrafficDemand's <code>demand</code> value (unless no valid node pairs exist, in which case no demands are created).</p> <p>Attributes:     network (Union[Network, NetworkView]): The underlying network or view object.     traffic_matrix_set (TrafficMatrixSet): Traffic matrices containing demands.     matrix_name (Optional[str]): Name of specific matrix to use, or None for default.     default_flow_policy_config (FlowPolicyConfig): Default FlowPolicy if         a TrafficDemand does not specify one.     graph (StrictMultiDiGraph): Active graph built from the network.     demands (List[Demand]): All expanded demands from the active matrix.     _td_to_demands (Dict[str, List[Demand]]): Internal mapping from         TrafficDemand.id to its expanded Demand objects.</p> <p>Attributes:</p> <ul> <li><code>network</code> (Union[Network, 'NetworkView'])</li> <li><code>traffic_matrix_set</code> ('TrafficMatrixSet')</li> <li><code>matrix_name</code> (Optional[str])</li> <li><code>default_flow_policy_config</code> (FlowPolicyConfig) = 1</li> <li><code>graph</code> (Optional[StrictMultiDiGraph])</li> <li><code>demands</code> (List[Demand]) = []</li> <li><code>_td_to_demands</code> (Dict[str, List[Demand]]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>build_graph(self, add_reverse: 'bool' = True) -&gt; 'None'</code> - Build or rebuild the internal <code>StrictMultiDiGraph</code> from <code>network</code>.</li> <li><code>expand_demands(self) -&gt; 'None'</code> - Expand each <code>TrafficDemand</code> into one or more <code>Demand</code> objects.</li> <li><code>get_flow_details(self) -&gt; 'Dict[Tuple[int, int], Dict[str, object]]'</code> - Summarize flows from each demand's policy.</li> <li><code>get_traffic_results(self, detailed: 'bool' = False) -&gt; 'List[TrafficResult]'</code> - Return traffic demand summaries.</li> <li><code>place_all_demands(self, placement_rounds: 'Union[int, str]' = 'auto', reoptimize_after_each_round: 'bool' = False) -&gt; 'float'</code> - Place all expanded demands in ascending priority order.</li> <li><code>reset_all_flow_usages(self) -&gt; 'None'</code> - Remove flow usage for each demand and reset placements to 0.</li> <li><code>summarize_link_usage(self) -&gt; 'Dict[str, float]'</code> - Return total flow usage per edge in the graph.</li> </ul>","text":""},{"location":"reference/api-full/#trafficresult","title":"TrafficResult <p>Traffic demand result entry.</p> <p>Attributes:     priority: Demand priority class (lower value is more critical).     total_volume: Total traffic volume for this entry.     placed_volume: Volume actually placed in the flow graph.     unplaced_volume: Volume not placed (<code>total_volume - placed_volume</code>).     src: Source node or path.     dst: Destination node or path.</p>","text":""},{"location":"reference/api-full/#ngraphdemandmanagerschedule","title":"ngraph.demand.manager.schedule","text":"<p>Scheduling utilities for demand placement rounds.</p> <p>Provides the simple priority-aware round-robin scheduler that was previously implemented in <code>TrafficManager</code>.</p>"},{"location":"reference/api-full/#place_demands_round_robingraph-strictmultidigraph-demands-listdemand-placement_rounds-int-reoptimize_after_each_round-bool-false-float","title":"place_demands_round_robin(graph: 'StrictMultiDiGraph', demands: 'List[Demand]', placement_rounds: 'int', reoptimize_after_each_round: 'bool' = False) -&gt; 'float' <p>Place demands using priority buckets and round-robin within each bucket.</p> <p>Args:     graph: Active flow graph.     demands: Expanded demands to place.     placement_rounds: Number of passes per priority class.     reoptimize_after_each_round: Whether to re-run placement for each demand         after a round to better share capacity.</p> <p>Returns:     Total volume successfully placed across all demands.</p>","text":""},{"location":"reference/api-full/#ngraphdemandmatrix","title":"ngraph.demand.matrix","text":"<p>Traffic matrix containers.</p> <p>Provides <code>TrafficMatrixSet</code>, a named collection of <code>TrafficDemand</code> lists used as input to demand expansion and placement. This module contains input containers, not analysis results.</p>"},{"location":"reference/api-full/#trafficmatrixset","title":"TrafficMatrixSet <p>Named collection of TrafficDemand lists.</p> <p>This mutable container maps scenario names to lists of TrafficDemand objects, allowing management of multiple traffic matrices for analysis.</p> <p>Attributes:     matrices: Dictionary mapping scenario names to TrafficDemand lists.</p> <p>Attributes:</p> <ul> <li><code>matrices</code> (dict[str, list[TrafficDemand]]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>add(self, name: 'str', demands: 'list[TrafficDemand]') -&gt; 'None'</code> - Add a traffic matrix to the collection.</li> <li><code>get_all_demands(self) -&gt; 'list[TrafficDemand]'</code> - Get all traffic demands from all matrices combined.</li> <li><code>get_default_matrix(self) -&gt; 'list[TrafficDemand]'</code> - Get default traffic matrix.</li> <li><code>get_matrix(self, name: 'str') -&gt; 'list[TrafficDemand]'</code> - Get a specific traffic matrix by name.</li> <li><code>to_dict(self) -&gt; 'dict[str, Any]'</code> - Convert to dictionary for JSON serialization.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphdemandspec","title":"ngraph.demand.spec","text":"<p>Traffic demand specification.</p> <p>Defines <code>TrafficDemand</code>, a user-facing specification used by demand expansion and placement. It can carry either a concrete <code>FlowPolicy</code> instance or a <code>FlowPolicyConfig</code> enum to construct one.</p>"},{"location":"reference/api-full/#trafficdemand","title":"TrafficDemand <p>Single traffic demand input.</p> <p>Attributes:     source_path: Regex string selecting source nodes.     sink_path: Regex string selecting sink nodes.     priority: Priority class for this demand (lower value = higher priority).     demand: Total demand volume.     demand_placed: Portion of this demand placed so far.     flow_policy_config: Policy configuration used to build a <code>FlowPolicy</code> if         <code>flow_policy</code> is not provided.     flow_policy: Concrete policy instance. If set, it overrides         <code>flow_policy_config</code>.     mode: Expansion mode, <code>\"combine\"</code> or <code>\"pairwise\"</code>.     attrs: Arbitrary user metadata.     id: Unique identifier assigned at initialization.</p> <p>Attributes:</p> <ul> <li><code>source_path</code> (str)</li> <li><code>sink_path</code> (str)</li> <li><code>priority</code> (int) = 0</li> <li><code>demand</code> (float) = 0.0</li> <li><code>demand_placed</code> (float) = 0.0</li> <li><code>flow_policy_config</code> (Optional)</li> <li><code>flow_policy</code> (Optional)</li> <li><code>mode</code> (str) = combine</li> <li><code>attrs</code> (Dict) = {}</li> <li><code>id</code> (str)</li> </ul>","text":""},{"location":"reference/api-full/#ngraphfailureconditions","title":"ngraph.failure.conditions","text":"<p>Shared condition primitives and evaluators.</p> <p>This module provides a small, dependency-free condition evaluation utility that can be reused by failure policies and DSL selection filters.</p> <p>Operators supported:</p> <ul> <li>==, !=, &lt;, &lt;=, &gt;, &gt;=</li> <li>contains, not_contains</li> <li>any_value, no_value</li> </ul> <p>The evaluator operates on a flat attribute mapping for an entity. Callers are responsible for constructing that mapping (e.g. merging top-level fields with <code>attrs</code> and ensuring appropriate precedence rules).</p>"},{"location":"reference/api-full/#failurecondition","title":"FailureCondition <p>A single condition for matching an entity attribute.</p> <p>Args:     attr: Attribute name to inspect in the entity mapping.     operator: Comparison operator. See module docstring for the list.     value: Right-hand operand for the comparison (unused for any_value/no_value).</p> <p>Attributes:</p> <ul> <li><code>attr</code> (str)</li> <li><code>operator</code> (str)</li> <li><code>value</code> (Any | None)</li> </ul>","text":""},{"location":"reference/api-full/#evaluate_conditionentity_attrs-dictstr-any-cond-failurecondition-bool","title":"evaluate_condition(entity_attrs: 'dict[str, Any]', cond: 'FailureCondition') -&gt; 'bool' <p>Evaluate a single condition against an entity attribute mapping.</p> <p>Args:     entity_attrs: Flat mapping of attributes for the entity.     cond: Condition to evaluate.</p> <p>Returns:     True if the condition passes, False otherwise.</p>","text":""},{"location":"reference/api-full/#evaluate_conditionsentity_attrs-dictstr-any-conditions-iterablefailurecondition-logic-str-bool","title":"evaluate_conditions(entity_attrs: 'dict[str, Any]', conditions: 'Iterable[FailureCondition]', logic: 'str') -&gt; 'bool' <p>Evaluate multiple conditions with AND/OR logic.</p> <p>Args:     entity_attrs: Flat mapping of attributes for the entity.     conditions: Iterable of conditions to evaluate.     logic: \"and\" or \"or\".</p> <p>Returns:     True if the combined predicate passes, False otherwise.</p>","text":""},{"location":"reference/api-full/#ngraphfailuremanageraggregate","title":"ngraph.failure.manager.aggregate","text":"<p>Aggregation helpers for failure analysis results.</p> <p>Utilities in this module group and summarize outputs produced by <code>FailureManager</code> runs. Functions are factored here to keep <code>manager.py</code> focused on orchestration. This module intentionally avoids importing heavy dependencies to keep import cost low in the common path.</p>"},{"location":"reference/api-full/#ngraphfailuremanagerenumerate","title":"ngraph.failure.manager.enumerate","text":"<p>Failure pattern enumeration helpers.</p> <p>Hosts utilities for generating or iterating over failure patterns for testing and analysis workflows. These helpers are separate from the Monte Carlo engine to keep the main manager small and focused.</p>"},{"location":"reference/api-full/#ngraphfailuremanagermanager","title":"ngraph.failure.manager.manager","text":"<p>FailureManager for Monte Carlo failure analysis.</p> <p>Provides the failure analysis engine for NetGraph. Supports parallel processing, per-worker caching, and failure policy handling for workflow steps and direct programmatic use.</p> <p>Performance characteristics: Time complexity: O(I \u00d7 A / P), where I is iteration count, A is analysis cost, and P is parallelism. Worker-local caching reduces repeated work when exclusion sets repeat across iterations. Network serialization happens once per worker, not per iteration.</p> <p>Space complexity: O(V + E + I \u00d7 R + C), where V and E are node and link counts, R is result size per iteration, and C is cache size. The per-worker cache is bounded and evicts in FIFO order after 1000 unique patterns.</p> <p>Parallelism: For small iteration counts, serial execution avoids IPC overhead. For larger workloads, parallel execution benefits from worker caching and CPU utilization. Optimal parallelism is the number of CPU cores for analysis-bound workloads.</p>"},{"location":"reference/api-full/#analysisfunction","title":"AnalysisFunction <p>Protocol for analysis functions used with FailureManager.</p> <p>Analysis functions should take a NetworkView and any additional keyword arguments, returning analysis results of any type.</p>","text":""},{"location":"reference/api-full/#failuremanager","title":"FailureManager <p>Failure analysis engine with Monte Carlo capabilities.</p> <p>This is the component for failure analysis in NetGraph. Provides parallel processing, worker caching, and failure policy handling for workflow steps and direct notebook usage.</p> <p>The FailureManager can execute any analysis function that takes a NetworkView and returns results, making it generic for different types of failure analysis (capacity, traffic, connectivity, etc.).</p> <p>Attributes:     network: The underlying network (not modified during analysis).     failure_policy_set: Set of named failure policies.     policy_name: Name of specific failure policy to use.</p> <p>Methods:</p> <ul> <li><code>compute_exclusions(self, policy: \"'FailurePolicy | None'\" = None, seed_offset: 'int | None' = None) -&gt; 'tuple[set[str], set[str]]'</code> - Compute set of nodes and links to exclude for a failure iteration.</li> <li><code>create_network_view(self, excluded_nodes: 'set[str] | None' = None, excluded_links: 'set[str] | None' = None) -&gt; 'NetworkView'</code> - Create NetworkView with specified exclusions.</li> <li><code>get_failure_policy(self) -&gt; \"'FailurePolicy | None'\"</code> - Get failure policy for analysis.</li> <li><code>run_demand_placement_monte_carlo(self, demands_config: 'list[dict[str, Any]] | Any', iterations: 'int' = 100, parallelism: 'int' = 1, placement_rounds: 'int | str' = 'auto', baseline: 'bool' = False, seed: 'int | None' = None, store_failure_patterns: 'bool' = False, include_flow_details: 'bool' = False, include_used_edges: 'bool' = False, **kwargs) -&gt; 'Any'</code> - Analyze traffic demand placement success under failures.</li> <li><code>run_max_flow_monte_carlo(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', iterations: 'int' = 100, parallelism: 'int' = 1, shortest_path: 'bool' = False, flow_placement: 'FlowPlacement | str' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;, baseline: 'bool' = False, seed: 'int | None' = None, store_failure_patterns: 'bool' = False, include_flow_summary: 'bool' = False, **kwargs) -&gt; 'Any'</code> - Analyze maximum flow capacity envelopes between node groups under failures.</li> <li><code>run_monte_carlo_analysis(self, analysis_func: 'AnalysisFunction', iterations: 'int' = 1, parallelism: 'int' = 1, baseline: 'bool' = False, seed: 'int | None' = None, store_failure_patterns: 'bool' = False, **analysis_kwargs) -&gt; 'dict[str, Any]'</code> - Run Monte Carlo failure analysis with any analysis function.</li> <li><code>run_sensitivity_monte_carlo(self, source_path: 'str', sink_path: 'str', mode: 'str' = 'combine', iterations: 'int' = 100, parallelism: 'int' = 1, shortest_path: 'bool' = False, flow_placement: 'FlowPlacement | str' = &lt;FlowPlacement.PROPORTIONAL: 1&gt;, baseline: 'bool' = False, seed: 'int | None' = None, store_failure_patterns: 'bool' = False, **kwargs) -&gt; 'Any'</code> - Analyze component criticality for flow capacity under failures.</li> <li><code>run_single_failure_scenario(self, analysis_func: 'AnalysisFunction', **kwargs) -&gt; 'Any'</code> - Run a single failure scenario for convenience.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphfailuremanagersimulate","title":"ngraph.failure.manager.simulate","text":"<p>Simulation helpers for failure analyses.</p> <p>Contains small helpers used to drive simulations in tests and examples. The main orchestration lives in <code>manager.py</code>.</p>"},{"location":"reference/api-full/#ngraphfailurepolicy","title":"ngraph.failure.policy","text":"<p>Failure policy primitives.</p> <p>Defines <code>FailureCondition</code>, <code>FailureRule</code>, and <code>FailurePolicy</code> for expressing how nodes, links, and risk groups fail in analyses. Conditions match on top-level attributes with simple operators; rules select matches using \"all\", probabilistic \"random\" (with <code>probability</code>), or fixed-size \"choice\" (with <code>count</code>). Policies can optionally expand failures by shared risk groups or by risk-group children.</p>"},{"location":"reference/api-full/#failurecondition_1","title":"FailureCondition <p>Alias to the shared condition dataclass.</p> <p>This maintains a consistent import path within the failure policy module.</p> <p>Attributes:</p> <ul> <li><code>attr</code> (str)</li> <li><code>operator</code> (str)</li> <li><code>value</code> (Any | None)</li> </ul>","text":""},{"location":"reference/api-full/#failuremode","title":"FailureMode <p>A weighted mode that encapsulates a set of rules applied together.</p> <p>Exactly one mode is selected per failure iteration according to the mode weights. Within a mode, all contained rules are applied and their selections are unioned into the failure set.</p> <p>Attributes:     weight: Non-negative weight used for mode selection. All weights are         normalized internally. Modes with zero weight are never selected.     rules: A list of <code>FailureRule</code> applied together when this mode is chosen.     attrs: Optional metadata.</p> <p>Attributes:</p> <ul> <li><code>weight</code> (float)</li> <li><code>rules</code> (List[FailureRule]) = []</li> <li><code>attrs</code> (Dict[str, Any]) = {}</li> </ul>","text":""},{"location":"reference/api-full/#failurepolicy","title":"FailurePolicy <p>A container for multiple FailureRules plus optional metadata in <code>attrs</code>.</p> <p>The main entry point is <code>apply_failures</code>, which:   1) For each rule, gather the relevant entities (node, link, or risk_group).           2) Match them based on rule conditions using 'and' or 'or' logic.   3) Apply the selection strategy (all, random, or choice).   4) Collect the union of all failed entities across all rules.   5) Optionally expand failures by shared-risk groups or sub-risks.</p> <p>Example YAML configuration:     <pre><code>failure_policy:\n  attrs:\n    description: \"Regional power grid failure affecting telecom infrastructure\"\n  fail_risk_groups: true\n  rules:\n    # Fail all nodes in Texas electrical grid\n    - entity_scope: \"node\"\n\n      conditions:\n        - attr: \"electric_grid\"\n\n          operator: \"==\"\n          value: \"texas\"\n      logic: \"and\"\n      rule_type: \"all\"\n\n    # Randomly fail 40% of underground fiber links in affected region\n    - entity_scope: \"link\"\n\n      conditions:\n        - attr: \"region\"\n\n          operator: \"==\"\n          value: \"southwest\"\n        - attr: \"installation\"\n\n          operator: \"==\"\n          value: \"underground\"\n      logic: \"and\"\n      rule_type: \"random\"\n      probability: 0.4\n\n    # Choose exactly 2 risk groups to fail (e.g., data centers)\n    # Note: logic defaults to \"or\" when not specified\n    - entity_scope: \"risk_group\"\n\n      rule_type: \"choice\"\n      count: 2\n</code></pre></p> <p>Attributes:     rules (List[FailureRule]):         A list of FailureRules to apply.     attrs (Dict[str, Any]):         Arbitrary metadata about this policy (e.g. \"name\", \"description\").     fail_risk_groups (bool):         If True, after initial selection, expand failures among any         node/link that shares a risk group with a failed entity.     fail_risk_group_children (bool):         If True, and if a risk_group is marked as failed, expand to         children risk_groups recursively.     seed (Optional[int]):         Seed for reproducible random operations. If None, operations         will be non-deterministic.</p> <p>Attributes:</p> <ul> <li><code>attrs</code> (Dict[str, Any]) = {}</li> <li><code>fail_risk_groups</code> (bool) = False</li> <li><code>fail_risk_group_children</code> (bool) = False</li> <li><code>seed</code> (Optional[int])</li> <li><code>modes</code> (List[FailureMode]) = []</li> </ul> <p>Methods:</p> <ul> <li><code>apply_failures(self, network_nodes: 'Dict[str, Any]', network_links: 'Dict[str, Any]', network_risk_groups: 'Dict[str, Any] | None' = None, *, seed: 'Optional[int]' = None) -&gt; 'List[str]'</code> - Identify which entities fail for this iteration.</li> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code> - Convert to dictionary for JSON serialization.</li> </ul>","text":""},{"location":"reference/api-full/#failurerule","title":"FailureRule <p>Defines how to match and then select entities for failure.</p> <p>Attributes:     entity_scope (EntityScope):         The type of entities this rule applies to: \"node\", \"link\", or \"risk_group\".     conditions (List[FailureCondition]):         A list of conditions to filter matching entities.     logic (Literal[\"and\", \"or\"]):         \"and\": All conditions must be true for a match.         \"or\": At least one condition is true for a match (default).     rule_type (Literal[\"random\", \"choice\", \"all\"]):         The selection strategy among the matched set:</p> <ul> <li>\"random\": each matched entity is chosen with probability = <code>probability</code>.</li> <li>\"choice\": pick exactly <code>count</code> items from the matched set (random sample).</li> <li> <p>\"all\": select every matched entity in the matched set.</p> <p>probability (float):     Probability in [0,1], used if <code>rule_type=\"random\"</code>. count (int):     Number of entities to pick if <code>rule_type=\"choice\"</code>.</p> </li> </ul> <p>Attributes:</p> <ul> <li><code>entity_scope</code> (EntityScope)</li> <li><code>conditions</code> (List[FailureCondition]) = []</li> <li><code>logic</code> (Literal['and', 'or']) = or</li> <li><code>rule_type</code> (Literal['random', 'choice', 'all']) = all</li> <li><code>probability</code> (float) = 1.0</li> <li><code>count</code> (int) = 1</li> <li><code>weight_by</code> (Optional[str])</li> </ul>","text":""},{"location":"reference/api-full/#ngraphfailurepolicy_set","title":"ngraph.failure.policy_set","text":"<p>Failure policy containers.</p> <p>Provides <code>FailurePolicySet</code>, a named collection of <code>FailurePolicy</code> objects used as input to failure analysis workflows. This module contains input containers, not analysis results.</p>"},{"location":"reference/api-full/#failurepolicyset","title":"FailurePolicySet <p>Named collection of FailurePolicy objects.</p> <p>This mutable container maps failure policy names to FailurePolicy objects, allowing management of multiple failure policies for analysis.</p> <p>Attributes:     policies: Dictionary mapping failure policy names to FailurePolicy objects.</p> <p>Attributes:</p> <ul> <li><code>policies</code> (dict[str, FailurePolicy]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>add(self, name: 'str', policy: 'FailurePolicy') -&gt; 'None'</code> - Add a failure policy to the collection.</li> <li><code>get_all_policies(self) -&gt; 'list[FailurePolicy]'</code> - Get all failure policies from the collection.</li> <li><code>get_policy(self, name: 'str') -&gt; 'FailurePolicy'</code> - Get a specific failure policy by name.</li> <li><code>to_dict(self) -&gt; 'dict[str, Any]'</code> - Convert to dictionary for JSON serialization.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphworkflowbase","title":"ngraph.workflow.base","text":"<p>Base classes for workflow automation.</p> <p>Defines the workflow step abstraction, registration decorator, and execution wrapper that adds timing and logging. Steps implement <code>run()</code> and are executed via <code>execute()</code> which records metadata and re-raises failures.</p>"},{"location":"reference/api-full/#workflowstep","title":"WorkflowStep <p>Base class for all workflow steps.</p> <p>All workflow steps are automatically logged with execution timing information. All workflow steps support seeding for reproducible random operations. Workflow metadata is automatically stored in scenario.results for analysis.</p> <p>YAML Configuration:     <pre><code>workflow:\n  - step_type: &lt;StepTypeName&gt;\n\n    name: \"optional_step_name\"  # Optional: Custom name for this step instance\n    seed: 42                    # Optional: Seed for reproducible random operations\n    # ... step-specific parameters ...\n</code></pre></p> <p>Attributes:     name: Optional custom identifier for this workflow step instance,         used for logging and result storage purposes.     seed: Optional seed for reproducible random operations. If None,         random operations will be non-deterministic.</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>seed</code> (Optional[int])</li> <li><code>_seed_source</code> (str)</li> </ul> <p>Methods:</p> <ul> <li><code>execute(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step with logging and metadata storage.</li> <li><code>run(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step logic.</li> </ul>","text":""},{"location":"reference/api-full/#register_workflow_stepstep_type-str","title":"register_workflow_step(step_type: 'str') <p>Return a decorator that registers a <code>WorkflowStep</code> subclass.</p> <p>Args:     step_type: Registry key used to instantiate steps from configuration.</p> <p>Returns:     A class decorator that adds the class to <code>WORKFLOW_STEP_REGISTRY</code>.</p>","text":""},{"location":"reference/api-full/#ngraphworkflowbuild_graph","title":"ngraph.workflow.build_graph","text":"<p>Graph building workflow component.</p> <p>Converts scenario network definitions into StrictMultiDiGraph structures suitable for analysis algorithms. No additional parameters required beyond basic workflow step options.</p> <p>YAML Configuration Example:     <pre><code>workflow:\n  - step_type: BuildGraph\n\n    name: \"build_network_graph\"  # Optional: Custom name for this step\n</code></pre></p> <p>Results stored in <code>scenario.results</code> under the step name as two keys:</p> <ul> <li>metadata: Step-level execution metadata (empty dict)</li> <li>data: { graph: node-link JSON dict, context: { add_reverse: bool } }</li> </ul>"},{"location":"reference/api-full/#buildgraph","title":"BuildGraph <p>A workflow step that builds a StrictMultiDiGraph from scenario.network.</p> <p>This step converts the scenario's network definition into a graph structure suitable for analysis algorithms. No additional parameters are required.</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>seed</code> (Optional[int])</li> <li><code>_seed_source</code> (str)</li> </ul> <p>Methods:</p> <ul> <li><code>execute(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step with logging and metadata storage.</li> <li><code>run(self, scenario: 'Scenario') -&gt; 'None'</code> - Build the network graph and store it in results.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphworkflowcost_power","title":"ngraph.workflow.cost_power","text":"<p>CostPower workflow step: collect capex and power by hierarchy level.</p> <p>This step aggregates capex and power from the network hardware inventory without performing any normalization or reporting. It separates contributions into two categories:</p> <ul> <li>platform_*: node hardware (e.g., chassis, linecards) resolved from node attrs</li> <li>optics_*: per-end link hardware (e.g., optics) resolved from link attrs</li> </ul> <p>Aggregation is computed at hierarchy levels 0..N where level 0 is the global root (path \"\"), and higher levels correspond to prefixes of node names split by \"/\". For example, for node \"dc1/plane1/leaf/leaf-1\":</p> <ul> <li>level 1 path is \"dc1\"</li> <li>level 2 path is \"dc1/plane1\"</li> <li>etc.</li> </ul> <p>Disabled handling:</p> <ul> <li>When include_disabled is False, only enabled nodes and links are considered.</li> <li>Optics are counted only when the endpoint node has platform hardware.</li> </ul> <p>YAML Configuration Example:     <pre><code>workflow:\n  - step_type: CostPower\n\n    name: \"cost_power\"           # Optional custom name\n    include_disabled: false       # Default: only enabled nodes/links\n    aggregation_level: 2          # Produce levels: 0, 1, 2\n</code></pre></p> <p>Results stored in <code>scenario.results</code> under this step namespace:     data:       context:         include_disabled: bool         aggregation_level: int       levels:         \"0\":</p> <ul> <li>path: \"\"<pre><code>    platform_capex: float\n    platform_power_watts: float\n    optics_capex: float\n    optics_power_watts: float\n    capex_total: float\n    power_total_watts: float\n\"1\": [ ... ]\n\"2\": [ ... ]\n</code></pre> </li> </ul>"},{"location":"reference/api-full/#costpower","title":"CostPower <p>Collect platform and optics capex/power by aggregation level.</p> <p>Attributes:     include_disabled: If True, include disabled nodes and links.     aggregation_level: Inclusive depth for aggregation. 0=root only.</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>seed</code> (Optional[int])</li> <li><code>_seed_source</code> (str)</li> <li><code>include_disabled</code> (bool) = False</li> <li><code>aggregation_level</code> (int) = 2</li> </ul> <p>Methods:</p> <ul> <li><code>execute(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step with logging and metadata storage.</li> <li><code>run(self, scenario: 'Any') -&gt; 'None'</code> - Aggregate capex and power by hierarchy levels 0..N.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphworkflowmax_flow_step","title":"ngraph.workflow.max_flow_step","text":"<p>MaxFlow workflow step.</p> <p>Monte Carlo analysis of maximum flow capacity between node groups using FailureManager. Produces unified <code>flow_results</code> per iteration under <code>data.flow_results</code>.</p> <p>YAML Configuration Example:</p> <pre><code>workflow:\n</code></pre> <ul> <li>step_type: MaxFlow<pre><code>name: \"maxflow_dc_to_edge\"\nsource_path: \"^datacenter/.*\"\nsink_path: \"^edge/.*\"\nmode: \"combine\"\nfailure_policy: \"random_failures\"\niterations: 100\nparallelism: auto\nshortest_path: false\nflow_placement: \"PROPORTIONAL\"\nbaseline: false\nseed: 42\nstore_failure_patterns: false\ninclude_flow_details: false      # cost_distribution\ninclude_min_cut: false           # min-cut edges list\n</code></pre> </li> </ul>"},{"location":"reference/api-full/#maxflow","title":"MaxFlow <p>Maximum flow Monte Carlo workflow step.</p> <p>Attributes:     source_path: Regex pattern for source node groups.     sink_path: Regex pattern for sink node groups.     mode: Flow analysis mode (\"combine\" or \"pairwise\").     failure_policy: Name of failure policy in scenario.failure_policy_set.     iterations: Number of Monte Carlo trials.     parallelism: Number of parallel worker processes.     shortest_path: Whether to use shortest paths only.     flow_placement: Flow placement strategy.     baseline: Whether to run first iteration without failures as baseline.     seed: Optional seed for reproducible results.     store_failure_patterns: Whether to store failure patterns in results.     include_flow_details: Whether to collect cost distribution per flow.     include_min_cut: Whether to include min-cut edges per flow.</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>seed</code> (int | None)</li> <li><code>_seed_source</code> (str)</li> <li><code>source_path</code> (str)</li> <li><code>sink_path</code> (str)</li> <li><code>mode</code> (str) = combine</li> <li><code>failure_policy</code> (str | None)</li> <li><code>iterations</code> (int) = 1</li> <li><code>parallelism</code> (int | str) = auto</li> <li><code>shortest_path</code> (bool) = False</li> <li><code>flow_placement</code> (FlowPlacement | str) = 1</li> <li><code>baseline</code> (bool) = False</li> <li><code>store_failure_patterns</code> (bool) = False</li> <li><code>include_flow_details</code> (bool) = False</li> <li><code>include_min_cut</code> (bool) = False</li> </ul> <p>Methods:</p> <ul> <li><code>execute(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step with logging and metadata storage.</li> <li><code>run(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step logic.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphworkflowmaximum_supported_demand_step","title":"ngraph.workflow.maximum_supported_demand_step","text":"<p>Maximum Supported Demand (MSD) workflow step.</p> <p>Searches for the maximum uniform traffic multiplier <code>alpha_star</code> that is fully placeable for a given matrix. Stores results under <code>data</code> as:</p> <ul> <li><code>alpha_star</code>: float</li> <li><code>context</code>: parameters used for the search</li> <li><code>base_demands</code>: serialized base demand specs</li> <li><code>probes</code>: bracket/bisect evaluations with feasibility</li> </ul>"},{"location":"reference/api-full/#maximumsupporteddemand","title":"MaximumSupportedDemand <p>MaximumSupportedDemand(name: 'str' = '', seed: 'Optional[int]' = None, _seed_source: 'str' = '', matrix_name: 'str' = 'default', acceptance_rule: 'str' = 'hard', alpha_start: 'float' = 1.0, growth_factor: 'float' = 2.0, alpha_min: 'float' = 1e-06, alpha_max: 'float' = 1000000000.0, resolution: 'float' = 0.01, max_bracket_iters: 'int' = 32, max_bisect_iters: 'int' = 32, seeds_per_alpha: 'int' = 1, placement_rounds: 'int | str' = 'auto')</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>seed</code> (Optional[int])</li> <li><code>_seed_source</code> (str)</li> <li><code>matrix_name</code> (str) = default</li> <li><code>acceptance_rule</code> (str) = hard</li> <li><code>alpha_start</code> (float) = 1.0</li> <li><code>growth_factor</code> (float) = 2.0</li> <li><code>alpha_min</code> (float) = 1e-06</li> <li><code>alpha_max</code> (float) = 1000000000.0</li> <li><code>resolution</code> (float) = 0.01</li> <li><code>max_bracket_iters</code> (int) = 32</li> <li><code>max_bisect_iters</code> (int) = 32</li> <li><code>seeds_per_alpha</code> (int) = 1</li> <li><code>placement_rounds</code> (int | str) = auto</li> </ul> <p>Methods:</p> <ul> <li><code>execute(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step with logging and metadata storage.</li> <li><code>run(self, scenario: \"'Any'\") -&gt; 'None'</code> - Execute the workflow step logic.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphworkflownetwork_stats","title":"ngraph.workflow.network_stats","text":"<p>Workflow step for basic node and link statistics.</p> <p>Computes and stores network statistics including node/link counts, capacity distributions, cost distributions, and degree distributions. Supports optional exclusion simulation and disabled entity handling.</p> <p>YAML Configuration Example:     <pre><code>workflow:\n  - step_type: NetworkStats\n\n    name: \"network_statistics\"           # Optional: Custom name for this step\n    include_disabled: false              # Include disabled nodes/links in stats\n    excluded_nodes: [\"node1\", \"node2\"]   # Optional: Temporary node exclusions\n    excluded_links: [\"link1\", \"link3\"]   # Optional: Temporary link exclusions\n</code></pre></p> <p>Results stored in <code>scenario.results</code>:</p> <ul> <li>Node statistics: node_count</li> <li> <p>Link statistics: link_count, total_capacity, mean_capacity, median_capacity,</p> <p>min_capacity, max_capacity, mean_cost, median_cost, min_cost, max_cost</p> </li> <li> <p>Degree statistics: mean_degree, median_degree, min_degree, max_degree</p> </li> </ul>"},{"location":"reference/api-full/#networkstats","title":"NetworkStats <p>Compute basic node and link statistics for the network.</p> <p>Supports optional exclusion simulation using NetworkView without modifying the base network.</p> <p>Attributes:     include_disabled: If True, include disabled nodes and links in statistics.         If False, only consider enabled entities.     excluded_nodes: Optional list of node names to exclude (temporary exclusion).     excluded_links: Optional list of link IDs to exclude (temporary exclusion).</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>seed</code> (Optional[int])</li> <li><code>_seed_source</code> (str)</li> <li><code>include_disabled</code> (bool) = False</li> <li><code>excluded_nodes</code> (Iterable[str]) = ()</li> <li><code>excluded_links</code> (Iterable[str]) = ()</li> </ul> <p>Methods:</p> <ul> <li><code>execute(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step with logging and metadata storage.</li> <li><code>run(self, scenario: 'Scenario') -&gt; 'None'</code> - Compute and store network statistics.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphworkflowtraffic_matrix_placement_step","title":"ngraph.workflow.traffic_matrix_placement_step","text":"<p>TrafficMatrixPlacement workflow step.</p> <p>Runs Monte Carlo demand placement using a named traffic matrix and produces unified <code>flow_results</code> per iteration under <code>data.flow_results</code>.</p>"},{"location":"reference/api-full/#trafficmatrixplacement","title":"TrafficMatrixPlacement <p>Monte Carlo demand placement using a named traffic matrix.</p> <p>Attributes:     matrix_name: Name of the traffic matrix to analyze.     failure_policy: Optional policy name in scenario.failure_policy_set.     iterations: Number of Monte Carlo iterations.     parallelism: Number of parallel worker processes.     placement_rounds: Placement optimization rounds (int or \"auto\").     baseline: Include baseline iteration without failures first.     seed: Optional seed for reproducibility.     store_failure_patterns: Whether to store failure pattern results.     include_flow_details: When True, include cost_distribution per flow.     include_used_edges: When True, include set of used edges per demand in entry data.     alpha: Numeric scale for demands in the matrix.     alpha_from_step: Optional producer step name to read alpha from.     alpha_from_field: Dotted field path in producer step (default: \"data.alpha_star\").</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>seed</code> (int | None)</li> <li><code>_seed_source</code> (str)</li> <li><code>matrix_name</code> (str)</li> <li><code>failure_policy</code> (str | None)</li> <li><code>iterations</code> (int) = 1</li> <li><code>parallelism</code> (int | str) = auto</li> <li><code>placement_rounds</code> (int | str) = auto</li> <li><code>baseline</code> (bool) = False</li> <li><code>store_failure_patterns</code> (bool) = False</li> <li><code>include_flow_details</code> (bool) = False</li> <li><code>include_used_edges</code> (bool) = False</li> <li><code>alpha</code> (float) = 1.0</li> <li><code>alpha_from_step</code> (str | None)</li> <li><code>alpha_from_field</code> (str) = data.alpha_star</li> </ul> <p>Methods:</p> <ul> <li><code>execute(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step with logging and metadata storage.</li> <li><code>run(self, scenario: \"'Scenario'\") -&gt; 'None'</code> - Execute the workflow step logic.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphdslblueprintsexpand","title":"ngraph.dsl.blueprints.expand","text":"<p>Network topology blueprints and generation.</p>"},{"location":"reference/api-full/#blueprint","title":"Blueprint <p>Represents a reusable blueprint for hierarchical sub-topologies.</p> <p>A blueprint may contain multiple groups of nodes (each can have a node_count and a name_template), plus adjacency rules describing how those groups connect.</p> <p>Attributes:     name (str): Unique identifier of this blueprint.     groups (Dict[str, Any]): A mapping of group_name -&gt; group definition.         Allowed top-level keys in each group definition here are the same         as in normal group definitions (e.g. node_count, name_template,         attrs, disabled, risk_groups, or nested use_blueprint references, etc.).     adjacency (List[Dict[str, Any]]): A list of adjacency definitions         describing how these groups are linked, using the DSL fields         (source, target, pattern, link_params, etc.).</p> <p>Attributes:</p> <ul> <li><code>name</code> (str)</li> <li><code>groups</code> (Dict[str, Any])</li> <li><code>adjacency</code> (List[Dict[str, Any]])</li> </ul>","text":""},{"location":"reference/api-full/#dslexpansioncontext","title":"DSLExpansionContext <p>Carries the blueprint definitions and the final Network instance to be populated during DSL expansion.</p> <p>Attributes:     blueprints (Dict[str, Blueprint]): Dictionary of blueprint-name -&gt; Blueprint.     network (Network): The Network into which expanded nodes/links are inserted.     pending_bp_adj (List[tuple[Dict[str, Any], str]]): Deferred blueprint adjacency         expansions collected as (adj_def, parent_path) to be processed later.</p> <p>Attributes:</p> <ul> <li><code>blueprints</code> (Dict[str, Blueprint])</li> <li><code>network</code> (Network)</li> <li><code>pending_bp_adj</code> (List[tuple[Dict[str, Any], str]]) = []</li> </ul>","text":""},{"location":"reference/api-full/#expand_network_dsldata-dictstr-any-network","title":"expand_network_dsl(data: 'Dict[str, Any]') -&gt; 'Network' <p>Expands a combined blueprint + network DSL into a complete Network object.</p> <p>Overall flow:   1) Parse \"blueprints\" into Blueprint objects.   2) Build a new Network from \"network\" metadata (e.g. name, version).   3) Expand 'network[\"groups\"]' (collect blueprint adjacencies for later).</p> <ul> <li> <p>If a group references a blueprint, incorporate that blueprint's subgroups</p> <p>while merging parent's attrs + disabled + risk_groups into subgroups.    Blueprint adjacency is deferred and processed after node overrides.</p> </li> <li> <p>Otherwise, directly create nodes (a \"direct node group\").</p> </li> </ul> <p>4) Process any direct node definitions (network[\"nodes\"]).   5) Process node overrides (in order if multiple overrides match).   6) Expand deferred blueprint adjacencies.   7) Expand adjacency definitions in 'network[\"adjacency\"]'.   8) Process any direct link definitions (network[\"links\"]).   9) Process link overrides (in order if multiple overrides match).</p> <p>Under the new rules:</p> <ul> <li> <p>Only certain top-level fields are permitted in each structure. Any extra</p> <p>keys raise a ValueError. \"attrs\" is where arbitrary user fields go.</p> </li> <li> <p>For link_params, recognized fields are \"capacity\", \"cost\", \"disabled\",</p> <p>\"risk_groups\", \"attrs\". Everything else must go inside link_params[\"attrs\"].</p> </li> <li> <p>For node/group definitions, recognized fields include \"node_count\",</p> <p>\"name_template\", \"attrs\", \"disabled\", \"risk_groups\" or \"use_blueprint\" for blueprint-based groups.</p> </li> </ul> <p>Args:     data (Dict[str, Any]): The YAML-parsed dictionary containing         optional \"blueprints\" + \"network\".</p> <p>Returns:     Network: The expanded Network object with all nodes and links.</p>","text":""},{"location":"reference/api-full/#ngraphdslblueprintsparse","title":"ngraph.dsl.blueprints.parse","text":"<p>Parsing helpers for the network DSL.</p> <p>This module factors out pure parsing/validation helpers from the expansion module so they can be tested independently and reused.</p>"},{"location":"reference/api-full/#check_adjacency_keysadj_def-dictstr-any-context-str-none","title":"check_adjacency_keys(adj_def: 'Dict[str, Any]', context: 'str') -&gt; 'None' <p>Ensure adjacency definitions only contain recognized keys.</p>","text":""},{"location":"reference/api-full/#check_link_paramslink_params-dictstr-any-context-str-none","title":"check_link_params(link_params: 'Dict[str, Any]', context: 'str') -&gt; 'None' <p>Ensure link_params contain only recognized keys.</p> <p>Link attributes may include \"hardware\" per-end mapping when set under link_params.attrs. This function only validates top-level link_params keys.</p>","text":""},{"location":"reference/api-full/#check_no_extra_keysdata_dict-dictstr-any-allowed-setstr-context-str-none","title":"check_no_extra_keys(data_dict: 'Dict[str, Any]', allowed: 'set[str]', context: 'str') -&gt; 'None' <p>Raise if <code>data_dict</code> contains keys outside <code>allowed</code>.</p> <p>Args:     data_dict: The dict to check.     allowed: Set of recognized keys.     context: Short description used in error messages.</p>","text":""},{"location":"reference/api-full/#expand_name_patternsname-str-liststr","title":"expand_name_patterns(name: 'str') -&gt; 'List[str]' <p>Expand bracket expressions in a group name.</p> <p>Examples:</p> <ul> <li>\"fa[1-3]\" -&gt; [\"fa1\", \"fa2\", \"fa3\"]</li> <li>\"dc[1,3,5-6]\" -&gt; [\"dc1\", \"dc3\", \"dc5\", \"dc6\"]</li> <li>\"fa[1-2]_plane[5-6]\" -&gt; [\"fa1_plane5\", \"fa1_plane6\", \"fa2_plane5\", \"fa2_plane6\"]</li> </ul>","text":""},{"location":"reference/api-full/#join_pathsparent_path-str-rel_path-str-str","title":"join_paths(parent_path: 'str', rel_path: 'str') -&gt; 'str' <p>Join two path segments according to the DSL conventions.</p>","text":""},{"location":"reference/api-full/#ngraphresultsartifacts","title":"ngraph.results.artifacts","text":"<p>Serializable result artifacts for analysis workflows.</p> <p>This module defines dataclasses that capture outputs from analyses and simulations in a JSON-serializable form:</p> <ul> <li><code>PlacementResultSet</code>: aggregated placement results and statistics</li> <li><code>CapacityEnvelope</code>: frequency-based capacity distributions and optional</li> </ul> <p>aggregated flow statistics</p> <ul> <li><code>FailurePatternResult</code>: capacity results for specific failure patterns</li> </ul>"},{"location":"reference/api-full/#capacityenvelope","title":"CapacityEnvelope <p>Frequency-based capacity envelope that stores capacity values as frequencies.</p> <p>This approach is memory-efficient for Monte Carlo analysis where we care about statistical distributions rather than individual sample order.</p> <p>Attributes:     source_pattern: Regex pattern used to select source nodes.     sink_pattern: Regex pattern used to select sink nodes.     mode: Flow analysis mode (\"combine\" or \"pairwise\").     frequencies: Dictionary mapping capacity values to their occurrence counts.     min_capacity: Minimum observed capacity.     max_capacity: Maximum observed capacity.     mean_capacity: Mean capacity across all samples.     stdev_capacity: Standard deviation of capacity values.     total_samples: Total number of samples represented.     flow_summary_stats: Optional dictionary with aggregated FlowSummary statistics.                        Contains cost_distribution_stats and other flow analytics.</p> <p>Attributes:</p> <ul> <li><code>source_pattern</code> (str)</li> <li><code>sink_pattern</code> (str)</li> <li><code>mode</code> (str)</li> <li><code>frequencies</code> (Dict[float, int])</li> <li><code>min_capacity</code> (float)</li> <li><code>max_capacity</code> (float)</li> <li><code>mean_capacity</code> (float)</li> <li><code>stdev_capacity</code> (float)</li> <li><code>total_samples</code> (int)</li> <li><code>flow_summary_stats</code> (Dict[str, Any]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>expand_to_values(self) -&gt; 'List[float]'</code> - Expand frequency map back to individual values.</li> <li><code>from_dict(data: 'Dict[str, Any]') -&gt; \"'CapacityEnvelope'\"</code> - Construct a CapacityEnvelope from a dictionary.</li> <li><code>from_values(source_pattern: 'str', sink_pattern: 'str', mode: 'str', values: 'List[float]', flow_summaries: 'List[Any] | None' = None) -&gt; \"'CapacityEnvelope'\"</code> - Create envelope from capacity values and optional flow summaries.</li> <li><code>get_percentile(self, percentile: 'float') -&gt; 'float'</code> - Calculate percentile from frequency distribution.</li> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code> - Convert to dictionary for JSON serialization.</li> </ul>","text":""},{"location":"reference/api-full/#failurepatternresult","title":"FailurePatternResult <p>Result for a unique failure pattern with associated capacity matrix.</p> <p>Attributes:     excluded_nodes: List of failed node IDs.     excluded_links: List of failed link IDs.     capacity_matrix: Dictionary mapping flow keys to capacity values.     count: Number of times this pattern occurred.     is_baseline: Whether this represents the baseline (no failures) case.</p> <p>Attributes:</p> <ul> <li><code>excluded_nodes</code> (List[str])</li> <li><code>excluded_links</code> (List[str])</li> <li><code>capacity_matrix</code> (Dict[str, float])</li> <li><code>count</code> (int)</li> <li><code>is_baseline</code> (bool) = False</li> <li><code>_pattern_key_cache</code> (str)</li> </ul> <p>Methods:</p> <ul> <li><code>from_dict(data: 'Dict[str, Any]') -&gt; \"'FailurePatternResult'\"</code> - Construct FailurePatternResult from a dictionary.</li> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code> - Convert to dictionary for JSON serialization.</li> </ul>","text":""},{"location":"reference/api-full/#placementenvelope","title":"PlacementEnvelope <p>Per-demand placement envelope keyed like capacity envelopes.</p> <p>Each envelope captures frequency distribution of placement ratio for a specific demand definition across Monte Carlo iterations.</p> <p>Attributes:     source: Source selection regex or node label.     sink: Sink selection regex or node label.     mode: Demand expansion mode (\"combine\" or \"pairwise\").     priority: Demand priority class.     frequencies: Mapping of placement ratio to occurrence count.     min: Minimum observed placement ratio.     max: Maximum observed placement ratio.     mean: Mean placement ratio.     stdev: Standard deviation of placement ratio.     total_samples: Number of iterations represented.</p> <p>Attributes:</p> <ul> <li><code>source</code> (str)</li> <li><code>sink</code> (str)</li> <li><code>mode</code> (str)</li> <li><code>priority</code> (int)</li> <li><code>frequencies</code> (Dict[float, int])</li> <li><code>min</code> (float)</li> <li><code>max</code> (float)</li> <li><code>mean</code> (float)</li> <li><code>stdev</code> (float)</li> <li><code>total_samples</code> (int)</li> </ul> <p>Methods:</p> <ul> <li><code>from_dict(data: 'Dict[str, Any]') -&gt; \"'PlacementEnvelope'\"</code> - Construct a PlacementEnvelope from a dictionary.</li> <li><code>from_values(source: 'str', sink: 'str', mode: 'str', priority: 'int', ratios: 'List[float]', rounding_decimals: 'int' = 4) -&gt; \"'PlacementEnvelope'\"</code></li> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code></li> </ul>","text":""},{"location":"reference/api-full/#placementresultset","title":"PlacementResultSet <p>Aggregated traffic placement results from one or many runs.</p> <p>This immutable dataclass stores traffic placement results organized by case, with overall statistics and per-demand statistics.</p> <p>Attributes:     results_by_case: Dictionary mapping case names to TrafficResult lists.     overall_stats: Dictionary of overall statistics.     demand_stats: Dictionary mapping demand keys to per-demand statistics.</p> <p>Attributes:</p> <ul> <li><code>results_by_case</code> (dict[str, list[TrafficResult]]) = {}</li> <li><code>overall_stats</code> (dict[str, float]) = {}</li> <li><code>demand_stats</code> (dict[tuple[str, str, int], dict[str, float]]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>to_dict(self) -&gt; 'dict[str, Any]'</code> - Convert to dictionary for JSON serialization.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphresultsflow","title":"ngraph.results.flow","text":"<p>Unified flow result containers for failure-analysis iterations.</p> <p>Defines small, serializable dataclasses that capture per-iteration outcomes for capacity and demand-placement style analyses in a unit-agnostic form.</p> <p>Objects expose <code>to_dict()</code> that returns JSON-safe primitives. Float-keyed distributions are normalized to string keys, and arbitrary <code>data</code> payloads are sanitized. These dicts are written under <code>data.flow_results</code> by steps.</p>"},{"location":"reference/api-full/#flowentry","title":"FlowEntry <p>Represents a single source\u2192destination flow outcome within an iteration.</p> <p>Fields are unit-agnostic. Callers can interpret numbers as needed for presentation (e.g., Gbit/s).</p> <p>Args:     source: Source identifier.     destination: Destination identifier.     priority: Priority/class for traffic placement scenarios. Zero when not applicable.     demand: Requested volume for this flow.     placed: Delivered volume for this flow.     dropped: Unmet volume (<code>demand - placed</code>).     cost_distribution: Optional distribution of placed volume by path cost.     data: Optional per-flow details (e.g., min-cut edges, used edges).</p> <p>Attributes:</p> <ul> <li><code>source</code> (str)</li> <li><code>destination</code> (str)</li> <li><code>priority</code> (int)</li> <li><code>demand</code> (float)</li> <li><code>placed</code> (float)</li> <li><code>dropped</code> (float)</li> <li><code>cost_distribution</code> (Dict[float, float]) = {}</li> <li><code>data</code> (Dict[str, Any]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code> - Return a JSON-serializable dictionary representation.</li> </ul>","text":""},{"location":"reference/api-full/#flowiterationresult","title":"FlowIterationResult <p>Container for per-iteration analysis results.</p> <p>Args:     failure_id: Stable identifier for the failure scenario (e.g., \"baseline\" or a hash).     failure_state: Optional excluded components for the iteration.     flows: List of flow entries for this iteration.     summary: Aggregated summary across <code>flows</code>.     data: Optional per-iteration extras.</p> <p>Attributes:</p> <ul> <li><code>failure_id</code> (str)</li> <li><code>failure_state</code> (Optional[Dict[str, List[str]]])</li> <li><code>flows</code> (List[FlowEntry]) = []</li> <li><code>summary</code> (FlowSummary) = FlowSummary(total_demand=0.0, total_placed=0.0, overall_ratio=1.0, dropped_flows=0, num_flows=0)</li> <li><code>data</code> (Dict[str, Any]) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code> - Return a JSON-serializable dictionary representation.</li> </ul>","text":""},{"location":"reference/api-full/#flowsummary_1","title":"FlowSummary <p>Aggregated metrics across all flows in one iteration.</p> <p>Args:     total_demand: Sum of all demands in this iteration.     total_placed: Sum of all delivered volumes in this iteration.     overall_ratio: <code>total_placed / total_demand</code> when demand &gt; 0, else 1.0.     dropped_flows: Number of flow entries with non-zero drop.     num_flows: Total number of flows considered.</p> <p>Attributes:</p> <ul> <li><code>total_demand</code> (float)</li> <li><code>total_placed</code> (float)</li> <li><code>overall_ratio</code> (float)</li> <li><code>dropped_flows</code> (int)</li> <li><code>num_flows</code> (int)</li> </ul> <p>Methods:</p> <ul> <li><code>to_dict(self) -&gt; 'Dict[str, Any]'</code> - Return a JSON-serializable dictionary representation.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphresultsstore","title":"ngraph.results.store","text":"<p>Generic results store for workflow steps and their metadata.</p> <p><code>Results</code> organizes outputs by workflow step name and records <code>WorkflowStepMetadata</code> for execution context. Storage is strictly step-scoped: steps must write two keys under their namespace:</p> <ul> <li><code>metadata</code>: step-level metadata (dict)</li> <li><code>data</code>: step-specific payload (dict)</li> </ul> <p>Export with :meth:<code>Results.to_dict</code>, which returns a JSON-safe structure with shape <code>{workflow, steps, scenario}</code>. During export, objects with a <code>to_dict()</code> method are converted, dictionary keys are coerced to strings, tuples are emitted as lists, and only JSON primitives are produced.</p>"},{"location":"reference/api-full/#results","title":"Results <p>Step-scoped results container with deterministic export shape.</p> <p>Structure:</p> <ul> <li>workflow: step metadata registry</li> <li>steps: per-step results with enforced keys {\"metadata\", \"data\"}</li> <li>scenario: optional scenario snapshot set once at load time</li> </ul> <p>Attributes:</p> <ul> <li><code>_store</code> (Dict) = {}</li> <li><code>_metadata</code> (Dict) = {}</li> <li><code>_active_step</code> (Optional)</li> <li><code>_scenario</code> (Dict) = {}</li> </ul> <p>Methods:</p> <ul> <li><code>enter_step(self, step_name: str) -&gt; None</code> - Enter step scope. Subsequent put/get are scoped to this step.</li> <li><code>exit_step(self) -&gt; None</code> - Exit step scope.</li> <li><code>get(self, key: str, default: Any = None) -&gt; Any</code> - Get a value from the active step scope.</li> <li><code>get_all_step_metadata(self) -&gt; Dict[str, ngraph.results.store.WorkflowStepMetadata]</code> - Get metadata for all workflow steps.</li> <li><code>get_step(self, step_name: str) -&gt; Dict[str, Any]</code> - Return the raw dict for a given step name (for cross-step reads).</li> <li><code>get_step_metadata(self, step_name: str) -&gt; Optional[ngraph.results.store.WorkflowStepMetadata]</code> - Get metadata for a workflow step.</li> <li><code>get_steps_by_execution_order(self) -&gt; list[str]</code> - Get step names ordered by their execution order.</li> <li><code>put(self, key: str, value: Any) -&gt; None</code> - Store a value in the active step under an allowed key.</li> <li><code>put_step_metadata(self, step_name: str, step_type: str, execution_order: int, *, scenario_seed: Optional[int] = None, step_seed: Optional[int] = None, seed_source: str = 'none', active_seed: Optional[int] = None) -&gt; None</code> - Store metadata for a workflow step.</li> <li><code>set_scenario_snapshot(self, snapshot: Dict[str, Any]) -&gt; None</code> - Attach a normalized scenario snapshot for export.</li> <li><code>to_dict(self) -&gt; Dict[str, Any]</code> - Return exported results with shape: {workflow, steps, scenario}.</li> </ul>","text":""},{"location":"reference/api-full/#workflowstepmetadata","title":"WorkflowStepMetadata <p>Metadata for a workflow step execution.</p> <p>Attributes:     step_type: The workflow step class name (e.g., 'CapacityEnvelopeAnalysis').     step_name: The instance name of the step.     execution_order: Order in which this step was executed (0-based).     scenario_seed: Scenario-level seed provided in the YAML (if any).     step_seed: Seed assigned to this step (explicit or scenario-derived).     seed_source: Source for the step seed. One of:</p> <ul> <li>\"scenario-derived\": seed was derived from scenario.seed</li> <li>\"explicit-step\": seed was explicitly provided for the step</li> <li> <p>\"none\": no seed provided/active for this step</p> <p>active_seed: The effective base seed used by the step, if any. For steps     that use Monte Carlo execution, per-iteration seeds are derived from     active_seed (e.g., active_seed + iteration_index).</p> </li> </ul> <p>Attributes:</p> <ul> <li><code>step_type</code> (str)</li> <li><code>step_name</code> (str)</li> <li><code>execution_order</code> (int)</li> <li><code>scenario_seed</code> (Optional)</li> <li><code>step_seed</code> (Optional)</li> <li><code>seed_source</code> (str) = none</li> <li><code>active_seed</code> (Optional)</li> </ul>","text":""},{"location":"reference/api-full/#ngraphmonte_carlofunctions","title":"ngraph.monte_carlo.functions","text":"<p>Picklable Monte Carlo analysis functions for FailureManager simulations.</p> <p>These functions are designed for use with FailureManager.run_monte_carlo_analysis() and follow the pattern: analysis_func(network_view: NetworkView, **kwargs) -&gt; Any.</p> <p>All functions accept only simple, hashable parameters to ensure compatibility with FailureManager's caching and multiprocessing systems for Monte Carlo failure analysis scenarios.</p> <p>This module provides only computation functions. Visualization and notebook analysis live in external packages.</p>"},{"location":"reference/api-full/#demand_placement_analysisnetwork_view-networkview-demands_config-listdictstr-any-placement_rounds-int-str-auto-include_flow_details-bool-false-include_used_edges-bool-false-kwargs-flowiterationresult","title":"demand_placement_analysis(network_view: \"'NetworkView'\", demands_config: 'list[dict[str, Any]]', placement_rounds: 'int | str' = 'auto', include_flow_details: 'bool' = False, include_used_edges: 'bool' = False, **kwargs) -&gt; 'FlowIterationResult' <p>Analyze traffic demand placement success rates.</p> <p>Produces per-demand FlowEntry records and an iteration-level summary suitable for downstream statistics (e.g., delivered percentiles) without reconstructing joint distributions.</p> <p>Additionally exposes placement engine counters to aid performance analysis:</p> <ul> <li>Per-demand: <code>FlowEntry.data.policy_metrics</code> (dict) with totals collected by</li> </ul> <p>the active FlowPolicy (e.g., <code>spf_calls_total</code>, <code>flows_created_total</code>,   <code>reopt_calls_total</code>, <code>place_iterations_total</code>).</p> <ul> <li>Per-iteration: <code>FlowIterationResult.data.iteration_metrics</code> aggregating the</li> </ul> <p>same counters across all demands in the iteration. Use   <code>FlowIterationResult.summary.total_placed</code> for placed volume totals.</p> <p>Args:     network_view: NetworkView with potential exclusions applied.     demands_config: List of demand configurations (serializable dicts).     placement_rounds: Number of placement optimization rounds.     include_flow_details: When True, include cost_distribution per flow.     include_used_edges: When True, include set of used edges per demand in entry data         as <code>FlowEntry.data.edges</code> with <code>edges_kind='used'</code>.     **kwargs: Ignored. Accepted for interface compatibility.</p> <p>Returns:     FlowIterationResult describing this iteration. The <code>data</code> field contains     <code>{\"iteration_metrics\": { ... }}</code>.</p>","text":""},{"location":"reference/api-full/#max_flow_analysisnetwork_view-networkview-source_regex-str-sink_regex-str-mode-str-combine-shortest_path-bool-false-flow_placement-flowplacement-include_flow_details-bool-false-include_min_cut-bool-false-kwargs-flowiterationresult","title":"max_flow_analysis(network_view: \"'NetworkView'\", source_regex: 'str', sink_regex: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = , include_flow_details: 'bool' = False, include_min_cut: 'bool' = False, **kwargs) -&gt; 'FlowIterationResult' <p>Analyze maximum flow capacity between node groups.</p> <p>Args:     network_view: NetworkView with potential exclusions applied.     source_regex: Regex pattern for source node groups.     sink_regex: Regex pattern for sink node groups.     mode: Flow analysis mode (\"combine\" or \"pairwise\").     shortest_path: Whether to use shortest paths only.     flow_placement: Flow placement strategy.     include_flow_details: Whether to collect cost distribution and similar details.     include_min_cut: Whether to include min-cut edge list in entry data.     **kwargs: Ignored. Accepted for interface compatibility.</p> <p>Returns:     FlowIterationResult describing this iteration.</p>","text":""},{"location":"reference/api-full/#sensitivity_analysisnetwork_view-networkview-source_regex-str-sink_regex-str-mode-str-combine-shortest_path-bool-false-flow_placement-flowplacement-kwargs-dictstr-dictstr-float","title":"sensitivity_analysis(network_view: \"'NetworkView'\", source_regex: 'str', sink_regex: 'str', mode: 'str' = 'combine', shortest_path: 'bool' = False, flow_placement: 'FlowPlacement' = , **kwargs) -&gt; 'dict[str, dict[str, float]]' <p>Analyze component sensitivity to failures.</p> <p>Args:     network_view: NetworkView with potential exclusions applied.     source_regex: Regex pattern for source node groups.     sink_regex: Regex pattern for sink node groups.     mode: Flow analysis mode (\"combine\" or \"pairwise\").     shortest_path: Whether to use shortest paths only.     flow_placement: Flow placement strategy.     **kwargs: Ignored. Accepted for interface compatibility.</p> <p>Returns:     Dictionary mapping flow keys (\"src-&gt;dst\") to dictionaries of component     identifiers mapped to sensitivity scores.</p>","text":""},{"location":"reference/api-full/#ngraphmonte_carloresults","title":"ngraph.monte_carlo.results","text":"<p>Structured result objects for FailureManager analysis functions.</p> <p>These classes provide interfaces for accessing Monte Carlo analysis results from FailureManager convenience methods. Visualization is handled by specialized analyzer classes in the workflow.analysis module.</p>"},{"location":"reference/api-full/#capacityenveloperesults","title":"CapacityEnvelopeResults <p>CapacityEnvelopeResults(envelopes: 'Dict[str, CapacityEnvelope]', failure_patterns: 'Dict[str, FailurePatternResult]', source_pattern: 'str', sink_pattern: 'str', mode: 'str', iterations: 'int', metadata: 'Dict[str, Any]')</p> <p>Attributes:</p> <ul> <li><code>envelopes</code> (Dict[str, CapacityEnvelope])</li> <li><code>failure_patterns</code> (Dict[str, FailurePatternResult])</li> <li><code>source_pattern</code> (str)</li> <li><code>sink_pattern</code> (str)</li> <li><code>mode</code> (str)</li> <li><code>iterations</code> (int)</li> <li><code>metadata</code> (Dict[str, Any])</li> </ul> <p>Methods:</p> <ul> <li><code>export_summary(self) -&gt; 'Dict[str, Any]'</code></li> </ul>","text":""},{"location":"reference/api-full/#demandplacementresults","title":"DemandPlacementResults <p>DemandPlacementResults(raw_results: 'dict[str, Any]', iterations: 'int', baseline: 'Optional[dict[str, Any]]' = None, failure_patterns: 'Optional[Dict[str, Any]]' = None, metadata: 'Optional[Dict[str, Any]]' = None)</p> <p>Attributes:</p> <ul> <li><code>raw_results</code> (dict[str, Any])</li> <li><code>iterations</code> (int)</li> <li><code>baseline</code> (Optional[dict[str, Any]])</li> <li><code>failure_patterns</code> (Optional[Dict[str, Any]])</li> <li><code>metadata</code> (Optional[Dict[str, Any]])</li> </ul>","text":""},{"location":"reference/api-full/#sensitivityresults","title":"SensitivityResults <p>Results from sensitivity Monte Carlo analysis.</p> <p>Attributes:     raw_results: Raw results from FailureManager     iterations: Number of Monte Carlo iterations     baseline: Optional baseline result (no failures)     component_scores: Aggregated component impact scores by flow     failure_patterns: Dictionary mapping pattern keys to failure pattern results     source_pattern: Source node regex pattern used in analysis     sink_pattern: Sink node regex pattern used in analysis     mode: Flow analysis mode (\"combine\" or \"pairwise\")     metadata: Additional analysis metadata from FailureManager</p> <p>Attributes:</p> <ul> <li><code>raw_results</code> (dict[str, Any])</li> <li><code>iterations</code> (int)</li> <li><code>baseline</code> (Optional[dict[str, Any]])</li> <li><code>component_scores</code> (Optional[Dict[str, Dict[str, Dict[str, float]]]])</li> <li><code>failure_patterns</code> (Optional[Dict[str, Any]])</li> <li><code>source_pattern</code> (Optional[str])</li> <li><code>sink_pattern</code> (Optional[str])</li> <li><code>mode</code> (Optional[str])</li> <li><code>metadata</code> (Optional[Dict[str, Any]])</li> </ul> <p>Methods:</p> <ul> <li><code>component_impact_distribution(self) -&gt; 'pd.DataFrame'</code> - Get component impact distribution as DataFrame.</li> <li><code>export_summary(self) -&gt; 'Dict[str, Any]'</code> - Export summary for serialization.</li> <li><code>flow_keys(self) -&gt; 'List[str]'</code> - Get list of all flow keys in results.</li> <li><code>get_failure_pattern_summary(self) -&gt; 'pd.DataFrame'</code> - Get summary of failure patterns if available.</li> <li><code>get_flow_sensitivity(self, flow_key: 'str') -&gt; 'Dict[str, Dict[str, float]]'</code> - Get component sensitivity scores for a specific flow.</li> <li><code>summary_statistics(self) -&gt; 'Dict[str, Dict[str, float]]'</code> - Get summary statistics for component impact across all flows.</li> <li><code>to_dataframe(self) -&gt; 'pd.DataFrame'</code> - Convert sensitivity results to DataFrame for analysis.</li> </ul>","text":""},{"location":"reference/api-full/#ngraphmonte_carlotypes","title":"ngraph.monte_carlo.types","text":"<p>Typed protocols for Monte Carlo analysis IPC payloads.</p> <p>Defines lightweight, serializable structures used across worker boundaries.</p>"},{"location":"reference/api-full/#flowresult","title":"FlowResult <p>Normalized result record for a flow pair in one iteration.</p> <p>Keys:     src: Source label     dst: Destination label     metric: Name of metric ('capacity' or 'placement_ratio')     value: Numeric value for the metric     stats: Optional FlowStats with compact details     priority: Optional demand priority (only for placement results)</p>","text":""},{"location":"reference/api-full/#flowstats","title":"FlowStats <p>Compact per-flow statistics for aggregation.</p> <p>Keys:     cost_distribution: Mapping of path cost to flow volume.     edges: List of edge identifiers (string form).     edges_kind: Meaning of edges list: 'min_cut' for capacity analysis,         'used' for demand placement edge usage.</p>","text":""},{"location":"reference/api-full/#ngraphprofilingprofiler","title":"ngraph.profiling.profiler","text":"<p>Profiling for NetGraph workflow execution.</p> <p>Provides CPU and wall-clock timing per workflow step using <code>cProfile</code> and optionally peak memory via <code>tracemalloc</code>. Aggregates results into structured summaries and identifies time-dominant steps (bottlenecks).</p>"},{"location":"reference/api-full/#performanceprofiler","title":"PerformanceProfiler <p>CPU profiler for NetGraph workflow execution.</p> <p>Profiles workflow steps using cProfile and identifies bottlenecks.</p> <p>Methods:</p> <ul> <li><code>analyze_performance(self) -&gt; 'None'</code> - Analyze profiling results and identify bottlenecks.</li> <li><code>end_scenario(self) -&gt; 'None'</code> - End profiling for the entire scenario execution.</li> <li><code>get_top_functions(self, step_name: 'str', limit: 'int' = 10) -&gt; 'List[Tuple[str, float, int]]'</code> - Get the top CPU-consuming functions for a specific step.</li> <li><code>merge_child_profiles(self, profile_dir: 'Path', step_name: 'str') -&gt; 'None'</code> - Merge child worker profiles into the parent step profile.</li> <li><code>profile_step(self, step_name: 'str', step_type: 'str') -&gt; 'Generator[None, None, None]'</code> - Context manager for profiling individual workflow steps.</li> <li><code>save_detailed_profile(self, output_path: 'Path', step_name: 'Optional[str]' = None) -&gt; 'None'</code> - Save detailed profiling data to a file.</li> <li><code>start_scenario(self) -&gt; 'None'</code> - Start profiling for the entire scenario execution.</li> </ul>","text":""},{"location":"reference/api-full/#performancereporter","title":"PerformanceReporter <p>Format and render performance profiling results.</p> <p>Generates plain-text reports with timing analysis, bottleneck identification, and practical performance tuning suggestions.</p> <p>Methods:</p> <ul> <li><code>generate_report(self) -&gt; 'str'</code> - Generate performance report.</li> </ul>","text":""},{"location":"reference/api-full/#profileresults","title":"ProfileResults <p>Profiling results for a scenario execution.</p> <p>Attributes:     step_profiles: List of individual step performance profiles.     total_wall_time: Total wall-clock time for entire scenario.     total_cpu_time: Total CPU time across all steps.     total_function_calls: Total function calls across all steps.     bottlenecks: List of performance bottlenecks (&gt;10% execution time).     analysis_summary: Performance metrics and statistics.</p> <p>Attributes:</p> <ul> <li><code>step_profiles</code> (List[StepProfile]) = []</li> <li><code>total_wall_time</code> (float) = 0.0</li> <li><code>total_cpu_time</code> (float) = 0.0</li> <li><code>total_function_calls</code> (int) = 0</li> <li><code>bottlenecks</code> (List[Dict[str, Any]]) = []</li> <li><code>analysis_summary</code> (Dict[str, Any]) = {}</li> </ul>","text":""},{"location":"reference/api-full/#stepprofile","title":"StepProfile <p>Performance profile data for a single workflow step.</p> <p>Attributes:     step_name: Name of the workflow step.     step_type: Type/class name of the workflow step.     wall_time: Total wall-clock time in seconds.     cpu_time: CPU time spent in step execution.     function_calls: Number of function calls during execution.     memory_peak: Peak memory usage during step in bytes (if available).     cprofile_stats: Detailed cProfile statistics object.     worker_profiles_merged: Number of worker profiles merged into this step.</p> <p>Attributes:</p> <ul> <li><code>step_name</code> (str)</li> <li><code>step_type</code> (str)</li> <li><code>wall_time</code> (float)</li> <li><code>cpu_time</code> (float)</li> <li><code>function_calls</code> (int)</li> <li><code>memory_peak</code> (Optional[float])</li> <li><code>cprofile_stats</code> (Optional[pstats.Stats])</li> <li><code>worker_profiles_merged</code> (int) = 0</li> </ul>","text":""},{"location":"reference/api-full/#ngraphprofilingreporter","title":"ngraph.profiling.reporter","text":""},{"location":"reference/api-full/#ngraphutilsids","title":"ngraph.utils.ids","text":""},{"location":"reference/api-full/#new_base64_uuid-str","title":"new_base64_uuid() -&gt; 'str' <p>Return a 22-character URL-safe Base64-encoded UUID without padding.</p> <p>The function generates a random version 4 UUID, encodes the 16 raw bytes using URL-safe Base64, removes the two trailing padding characters, and decodes to ASCII. The resulting string length is 22 characters.</p> <p>Returns:     A 22-character URL-safe Base64 representation of a UUID4 without     padding.</p>","text":""},{"location":"reference/api-full/#ngraphutilsoutput_paths","title":"ngraph.utils.output_paths","text":"<p>Utilities for building CLI artifact output paths.</p> <p>This module centralizes logic for composing file and directory paths for artifacts produced by the NetGraph CLI. Paths are built from an optional output directory, a prefix (usually derived from the scenario file or results file), and a per-artifact suffix.</p>"},{"location":"reference/api-full/#build_artifact_pathoutput_dir-optionalpath-prefix-str-suffix-str-path","title":"build_artifact_path(output_dir: 'Optional[Path]', prefix: 'str', suffix: 'str') -&gt; 'Path' <p>Compose an artifact path as output_dir / (prefix + suffix).</p> <p>If <code>output_dir</code> is None, the path is created relative to the current working directory.</p> <p>Args:     output_dir: Base directory for outputs; if None, use CWD.     prefix: Filename prefix; usually derived from scenario or results stem.     suffix: Per-artifact suffix including the dot (e.g. \".results.json\").</p> <p>Returns:     The composed path.</p>","text":""},{"location":"reference/api-full/#ensure_parent_dirpath-path-none","title":"ensure_parent_dir(path: 'Path') -&gt; 'None' <p>Ensure the parent directory exists for a file path.</p>","text":""},{"location":"reference/api-full/#profiles_dir_for_runscenario_path-path-output_dir-optionalpath-path","title":"profiles_dir_for_run(scenario_path: 'Path', output_dir: 'Optional[Path]') -&gt; 'Path' <p>Return the directory for child worker profiles for <code>run --profile</code>.</p> <p>Args:     scenario_path: The scenario YAML path.     output_dir: Optional base output directory.</p> <p>Returns:     Directory path where worker profiles should be stored.</p>","text":""},{"location":"reference/api-full/#resolve_override_pathoverride-optionalpath-output_dir-optionalpath-optionalpath","title":"resolve_override_path(override: 'Optional[Path]', output_dir: 'Optional[Path]') -&gt; 'Optional[Path]' <p>Resolve an override path with respect to an optional output directory.</p> <ul> <li>Absolute override paths are returned as-is.</li> <li>Relative override paths are interpreted as relative to <code>output_dir</code></li> </ul> <p>when provided; otherwise relative to the current working directory.</p> <p>Args:     override: Path provided by the user to override the default.     output_dir: Optional base directory for relative overrides.</p> <p>Returns:     The resolved path or None if no override was provided.</p>","text":""},{"location":"reference/api-full/#results_path_for_runscenario_path-path-output_dir-optionalpath-results_override-optionalpath-path","title":"results_path_for_run(scenario_path: 'Path', output_dir: 'Optional[Path]', results_override: 'Optional[Path]') -&gt; 'Path' <p>Determine the results JSON path for the <code>run</code> command.</p> <p>Behavior:</p> <ul> <li>If <code>results_override</code> is provided, return it (resolved relative to</li> </ul> <p><code>output_dir</code> when that is specified, otherwise as-is).</p> <ul> <li>Else if <code>output_dir</code> is provided, return <code>output_dir/&lt;prefix&gt;.results.json</code>.</li> <li>Else, return <code>&lt;scenario_stem&gt;.results.json</code> in the current working directory.</li> </ul> <p>Args:     scenario_path: The scenario YAML file path.     output_dir: Optional base output directory.     results_override: Optional explicit results file path.</p> <p>Returns:     The path where results should be written.</p>","text":""},{"location":"reference/api-full/#scenario_prefix_from_pathscenario_path-path-str","title":"scenario_prefix_from_path(scenario_path: 'Path') -&gt; 'str' <p>Return a safe prefix derived from a scenario file path.</p> <p>Args:     scenario_path: The scenario YAML file path.</p> <p>Returns:     The scenario filename stem, trimmed of extensions.</p>","text":""},{"location":"reference/api-full/#error-handling","title":"Error Handling","text":"<p>NetGraph uses standard Python exceptions:</p> <ul> <li><code>ValueError</code> - For validation errors</li> <li><code>KeyError</code> - For missing required fields</li> <li><code>RuntimeError</code> - For runtime errors</li> </ul> <p>For complete method signatures and detailed documentation, use Python's help system:</p> <pre><code>help(ngraph.scenario.Scenario)\nhelp(ngraph.network.Network.max_flow)\n</code></pre> <p>This documentation was auto-generated from the NetGraph source code.</p>"},{"location":"reference/api/","title":"API Reference","text":"<p>Quick links:</p> <ul> <li>Design \u2014 architecture, model, algorithms, workflow</li> <li>DSL Reference \u2014 YAML syntax for scenario definition</li> <li>Workflow Reference \u2014 analysis workflow configuration and execution</li> <li>CLI Reference \u2014 command-line tools for running scenarios</li> <li>Auto-Generated API Reference \u2014 complete class and method documentation</li> </ul> <p>This section provides a curated guide to NetGraph's Python API, organized by typical usage patterns.</p>"},{"location":"reference/api/#1-fundamentals","title":"1. Fundamentals","text":"<p>The core components that form the foundation of most NetGraph programs.</p>"},{"location":"reference/api/#scenario","title":"Scenario","text":"<p>Purpose: The main orchestrator that coordinates network topology, analysis workflows, and result collection.</p> <p>When to use: Every NetGraph program starts with a Scenario - either loaded from YAML or built programmatically.</p> <pre><code>from pathlib import Path\nfrom ngraph.scenario import Scenario\n\n# Load complete scenario from YAML text\nyaml_text = Path(\"scenarios/square_mesh.yaml\").read_text()\nscenario = Scenario.from_yaml(yaml_text)\n\n# Execute the scenario\nscenario.run()\n\n# Export results\nexported = scenario.results.to_dict()\nprint(exported[\"workflow\"].keys())\n</code></pre> <p>Key Methods:</p> <ul> <li><code>from_yaml(yaml_content)</code> - Load scenario from YAML string/file</li> <li><code>run()</code> - Execute the complete analysis workflow</li> </ul> <p>Integration: Scenario coordinates Network topology, workflow execution, and Results collection. Components can also be used independently for direct programmatic access.</p>"},{"location":"reference/api/#network","title":"Network","text":"<p>Purpose: Represents network topology and provides fundamental analysis capabilities like maximum flow calculation.</p> <p>When to use: Core component for representing network structure. Used directly for programmatic topology creation or accessed via <code>scenario.network</code>.</p> <pre><code>from ngraph.model.network import Network, Node, Link\n\n# Create a tiny network\nnetwork = Network()\nnetwork.add_node(Node(name=\"n1\"))\nnetwork.add_node(Node(name=\"n2\"))\nnetwork.add_link(Link(source=\"n1\", target=\"n2\", capacity=100.0))\n\n# Calculate maximum flow (returns dict)\nmax_flow = network.max_flow(\n    source_path=\"n1\",\n    sink_path=\"n2\"\n)\nprint(max_flow)\n</code></pre> <p>Key Methods:</p> <ul> <li><code>add_node(node)</code>, <code>add_link(link)</code> - Build topology programmatically</li> <li><code>max_flow(source_path, sink_path, **options)</code> - Calculate maximum flow (returns dict)</li> <li><code>nodes</code>, <code>links</code> - Access topology as dictionaries</li> </ul> <p>Key Concepts:</p> <ul> <li>Node.disabled/Link.disabled: Scenario-level configuration that persists across analyses</li> <li>Node selection: Use regex patterns like <code>\"datacenter.*\"</code> or attribute directives like <code>attr:role</code> to group nodes by attribute (see DSL Node Selection)</li> </ul> <p>Integration: Foundation for all analysis. Used directly or through NetworkView for filtered analysis.</p>"},{"location":"reference/api/#results","title":"Results","text":"<p>Purpose: Centralized container for storing and retrieving analysis results from workflow steps.</p> <p>When to use: Automatically managed by <code>scenario.results</code>. Used for storing custom analysis results and retrieving outputs from workflow steps.</p> <pre><code># Access results from scenario\nresults = scenario.results\n\n# Export all results for serialization\nall_data = results.to_dict()\nprint(list(all_data[\"steps\"].keys()))\n</code></pre> <p>Key Methods:</p> <ul> <li><code>enter_step(step_name)</code> / <code>exit_step()</code> - Scope mutations to a step (managed by WorkflowStep)</li> <li><code>put(key, value)</code> - Store under active step; key is <code>\"metadata\"</code> or <code>\"data\"</code></li> <li><code>get_step(step_name)</code> - Read a step\u2019s raw dict (for explicit cross-step reads)</li> <li><code>to_dict()</code> - Export with shape <code>{workflow, steps, scenario}</code> (JSON-safe)</li> </ul> <p>Integration: Used by all workflow steps for result storage. Provides consistent access pattern for analysis outputs.</p>"},{"location":"reference/api/#2-basic-analysis","title":"2. Basic Analysis","text":"<p>Essential analysis capabilities for network evaluation.</p>"},{"location":"reference/api/#flow-analysis","title":"Flow Analysis","text":"<p>Purpose: Calculate network flows between source and sink groups with various policies and constraints.</p> <p>When to use: Fundamental analysis for understanding network capacity, bottlenecks, and traffic engineering scenarios.</p> <pre><code>from ngraph.algorithms.base import FlowPlacement\n\n# Maximum flow between group patterns (combine all sources/sinks)\nmax_flow = network.max_flow(\n    source_path=\"^metro1/.*\",\n    sink_path=\"^metro5/.*\",\n    mode=\"combine\"\n)\n\n# Detailed flow analysis with cost distribution\nresult = network.max_flow_with_summary(\n    source_path=\"^metro1/.*\",\n    sink_path=\"^metro5/.*\",\n    mode=\"combine\"\n)\n(src_label, sink_label), (flow_value, summary) = next(iter(result.items()))\nprint(summary.cost_distribution)\n</code></pre> <p>Key Options:</p> <ul> <li><code>mode</code>: <code>\"combine\"</code> (aggregate flows) or <code>\"pairwise\"</code> (individual pair flows)</li> <li><code>shortest_path</code>: <code>True</code> (shortest only) or <code>False</code> (all available paths)</li> <li><code>flow_placement</code>: <code>FlowPlacement.PROPORTIONAL</code> (WCMP) or <code>FlowPlacement.EQUAL_BALANCED</code> (ECMP)</li> </ul> <p>Advanced Features:</p> <ul> <li>Cost Distribution: <code>FlowSummary.cost_distribution</code> provides flow volume breakdown by path cost for latency span analysis and performance characterization</li> <li>Analytics: Edge flows, residual capacities, min-cut analysis, and reachability information</li> </ul> <p>Integration: Available on both Network and NetworkView objects. Foundation for FailureManager Monte Carlo analysis.</p>"},{"location":"reference/api/#networkview","title":"NetworkView","text":"<p>Purpose: Provides filtered view of network topology for failure analysis without modifying the base network.</p> <p>When to use: Simulate component failures, analyze degraded network states, or perform parallel analysis with different exclusions.</p> <pre><code>from ngraph.model.view import NetworkView\n\n# Create view with failed components (for failure simulation)\nfailed_view = NetworkView.from_excluded_sets(\n    network,\n    excluded_nodes={\"n2\"},\n    excluded_links=set()\n)\n\n# Analyze degraded network\ndegraded_flow = failed_view.max_flow(\"n1\", \"n2\")\nprint(degraded_flow)\n</code></pre> <p>Key Features:</p> <ul> <li>Read-only overlay: Combines scenario-disabled and analysis-excluded elements</li> <li>Concurrent analysis: Supports different failure scenarios in parallel</li> <li>Identical API: Same analysis methods as Network</li> </ul> <p>Integration: Used internally by FailureManager for Monte Carlo analysis. Enables concurrent failure simulations without network state conflicts.</p>"},{"location":"reference/api/#3-advanced-analysis","title":"3. Advanced Analysis","text":"<p>Sophisticated analysis capabilities using Monte Carlo methods and parallel processing.</p>"},{"location":"reference/api/#failuremanager","title":"FailureManager","text":"<p>Purpose: Authoritative Monte Carlo failure analysis engine with parallel processing and result aggregation.</p> <p>When to use: Capacity envelope analysis, demand placement studies, component sensitivity analysis, or custom Monte Carlo simulations.</p> <pre><code>from ngraph.failure.manager.manager import FailureManager\nfrom ngraph.failure.policy import FailurePolicy, FailureRule\nfrom ngraph.failure.policy_set import FailurePolicySet\n\npolicy_set = FailurePolicySet()\npolicy = FailurePolicy(modes=[\n    # One mode with a single random link failure\n    {\n        \"weight\": 1.0,\n        \"rules\": [FailureRule(entity_scope=\"link\", rule_type=\"choice\", count=1)]\n    }\n])\npolicy_set.add(\"one_link\", policy)\n\nmanager = FailureManager(\n    network=network,\n    failure_policy_set=policy_set,\n    policy_name=\"one_link\"\n)\n\nresults = manager.run_max_flow_monte_carlo(\n    source_path=\"n1\",\n    sink_path=\"n2\",\n    iterations=10,\n    parallelism=1,\n    baseline=True\n)\n</code></pre> <p>Key Methods:</p> <ul> <li><code>run_max_flow_monte_carlo()</code> - Capacity envelope analysis under failures</li> <li><code>run_demand_placement_monte_carlo()</code> - Traffic demand placement success analysis</li> <li><code>run_sensitivity_monte_carlo()</code> - Component criticality and impact analysis</li> <li><code>run_monte_carlo_analysis()</code> - Generic Monte Carlo with custom analysis functions</li> </ul> <p>Key Features:</p> <ul> <li>Parallel processing with worker caching for performance</li> <li>Automatic result aggregation into rich statistical objects</li> <li>Reproducible results with seed support</li> <li>Failure policy integration for realistic failure scenarios</li> </ul> <p>Integration: Uses NetworkView for isolated failure simulation. Returns specialized result objects for statistical analysis.</p>"},{"location":"reference/api/#monte-carlo-results","title":"Monte Carlo Results","text":"<p>Purpose: Rich result objects with statistical analysis and visualization capabilities.</p> <p>When to use: Analyzing outputs from FailureManager convenience methods - provides pandas integration and statistical summaries.</p> <pre><code>from ngraph.results.flow import FlowEntry, FlowIterationResult, FlowSummary\n\nflows = [\n    FlowEntry(\n        source=\"n1\", destination=\"n2\", priority=0,\n        demand=10.0, placed=10.0, dropped=0.0,\n        cost_distribution={2.0: 6.0, 4.0: 4.0}, data={}\n    )\n]\nsummary = FlowSummary(\n    total_demand=10.0, total_placed=10.0, overall_ratio=1.0,\n    dropped_flows=0, num_flows=len(flows)\n)\niteration = FlowIterationResult(flows=flows, summary=summary)\niteration_dict = iteration.to_dict()\n</code></pre> <p>Key Result Types:</p> <ul> <li><code>FlowIterationResult</code> - Per-iteration flow results (flows + summary)</li> <li><code>FlowEntry</code> - Per-flow entry (source, destination, volumes, cost distribution)</li> <li><code>FlowSummary</code> - Aggregate totals for an iteration</li> <li><code>SensitivityResults</code> - Component criticality rankings</li> </ul> <p>Integration: Returned by FailureManager convenience methods. Analyze exported JSON results using external scripts.</p>"},{"location":"reference/api/#4-data-results","title":"4. Data &amp; Results","text":"<p>Working with analysis outputs and implementing custom result storage.</p>"},{"location":"reference/api/#result-artifacts","title":"Result Artifacts","text":"<p>Purpose: Serializable data structures that store analysis results with consistent interfaces for export and reconstruction.</p> <p>When to use: Working with stored analysis results, implementing custom workflow steps, or exporting data for external analysis.</p> <pre><code>from ngraph.results.store import Results\n\n# Access exported results\nexported = scenario.results.to_dict()\nprint(exported[\"steps\"].keys())\n</code></pre> <p>Key Classes:</p> <ul> <li><code>CapacityEnvelope</code> - Frequency-based capacity distributions with percentile analysis</li> <li><code>FailurePatternResult</code> - Failure scenario details with capacity impact</li> <li><code>FailurePolicySet</code> - Collections of named failure policies</li> </ul> <p>Integration: Used by workflow steps and FailureManager. All provide <code>to_dict()</code> and <code>from_dict()</code> for serialization.</p>"},{"location":"reference/api/#export-patterns","title":"Export Patterns","text":"<p>Purpose: Best practices for storing results in custom workflow steps and analysis functions.</p> <pre><code>from ngraph.workflow.base import WorkflowStep\n\nclass CustomAnalysis(WorkflowStep):\n    def run(self, scenario):\n        # Simple metrics\n        scenario.results.put(\"metadata\", {})\n        scenario.results.put(\"data\", {\"node_count\": len(scenario.network.nodes)})\n\n        # Complex objects - convert to dict first\n        analysis_result = self.perform_analysis(scenario.network)\n        payload = analysis_result.to_dict() if hasattr(analysis_result, 'to_dict') else analysis_result\n        scenario.results.put(\"data\", {\"analysis\": payload})\n</code></pre> <p>Storage Conventions:</p> <ul> <li>Use <code>self.name</code> as step identifier for result storage</li> <li>Convert complex objects using <code>to_dict()</code> before storage</li> <li>Use descriptive keys like <code>\"capacity_envelopes\"</code>, <code>\"network_statistics\"</code></li> <li>Results are automatically serialized via <code>results.to_dict()</code></li> </ul>"},{"location":"reference/api/#5-automation","title":"5. Automation","text":"<p>Workflow orchestration and reusable network templates.</p>"},{"location":"reference/api/#workflow-steps","title":"Workflow Steps","text":"<p>Purpose: Automated analysis sequences with standardized result storage and execution order.</p> <p>When to use: Complex multi-step analysis, reproducible analysis pipelines, or when you need automatic result collection and metadata tracking.</p> <p>Available workflow steps:</p> <ul> <li><code>BuildGraph</code> - Exports graph in node-link JSON under <code>data.graph</code></li> <li><code>NetworkStats</code> - Basic topology statistics under <code>data</code></li> <li><code>MaxFlow</code> - Monte Carlo flow capacity analysis under <code>data.flow_results</code></li> <li><code>TrafficMatrixPlacement</code> - Monte Carlo demand placement under <code>data.flow_results</code></li> <li><code>MaximumSupportedDemand</code> - Alpha search results under <code>data</code></li> </ul> <p>Integration: Defined in YAML scenarios or created programmatically. Each step stores results using consistent naming patterns in <code>scenario.results</code>.</p>"},{"location":"reference/api/#blueprint-system","title":"Blueprint System","text":"<p>Purpose: Reusable network topology templates defined in YAML for complex, hierarchical network structures.</p> <p>When to use: Creating standardized network architectures, multi-pod topologies, or when you need parameterized network generation.</p> <pre><code># Blueprints are typically defined in YAML and used via Scenario\n# For programmatic topology creation, use Network class directly\n</code></pre> <p>Integration: Blueprints are processed during scenario creation. See DSL Reference for YAML blueprint syntax and examples.</p>"},{"location":"reference/api/#6-extensions","title":"6. Extensions","text":"<p>Advanced capabilities for custom analysis and low-level operations.</p>"},{"location":"reference/api/#utilities-helpers","title":"Utilities &amp; Helpers","text":"<p>Purpose: Graph format conversion and direct access to low-level algorithms.</p> <p>When to use: Custom analysis requiring NetworkX integration, performance-critical algorithms, or when you need direct control over graph operations.</p> <pre><code>from ngraph.graph.convert import to_digraph, from_digraph\nfrom ngraph.algorithms.spf import spf\nfrom ngraph.algorithms.max_flow import calc_max_flow\n\n# Convert to NetworkX for custom algorithms\nnx_graph = to_digraph(scenario.network.to_strict_multidigraph())\n\n# Direct algorithm access\ncosts, predecessors = spf(graph, source_node)\nmax_flow_value = calc_max_flow(graph, source, sink)\n</code></pre> <p>Integration: Provides bridge between NetGraph and NetworkX ecosystems. Used when built-in analysis methods are insufficient.</p>"},{"location":"reference/api/#error-handling","title":"Error Handling","text":"<p>Purpose: Exception handling patterns and result validation for reliable analysis.</p> <pre><code>try:\n    scenario = Scenario.from_yaml(yaml_content)\n    scenario.run()\n\n    # Validate expected results\n    exported = scenario.results.to_dict()\n    assert \"steps\" in exported and exported[\"steps\"], \"No steps present in results\"\n\nexcept ValueError as e:\n    print(f\"YAML validation failed: {e}\")\nexcept Exception as e:\n    print(f\"Analysis error: {e}\")\n</code></pre> <p>Common Patterns:</p> <ul> <li>Use <code>results.get()</code> with <code>default</code></li> </ul>"},{"location":"reference/cli/","title":"Command Line Interface","text":"<p>Quick links:</p> <ul> <li>Design \u2014 architecture, model, algorithms, workflow</li> <li>DSL Reference \u2014 YAML syntax for scenario definition</li> <li>Workflow Reference \u2014 analysis workflow configuration and execution</li> <li>API Reference \u2014 Python API for programmatic scenario creation</li> <li>Auto-Generated API Reference \u2014 complete class and method documentation</li> </ul> <p>NetGraph provides a command-line interface for inspecting, running, and analyzing scenarios from the terminal.</p>"},{"location":"reference/cli/#basic-usage","title":"Basic Usage","text":"<p>The CLI provides two primary commands:</p> <ul> <li><code>inspect</code>: Analyze and validate scenario files without running them</li> <li><code>run</code>: Execute scenario files and generate results</li> </ul> <p>Global options (must be placed before the command):</p> <ul> <li><code>--verbose</code>, <code>-v</code>: Enable debug logging</li> <li><code>--quiet</code>: Suppress console output (logs only)</li> </ul>"},{"location":"reference/cli/#quick-start","title":"Quick Start","text":"<pre><code># Inspect a provided scenario\nngraph inspect scenarios/square_mesh.yaml\n\n# Run a scenario (creates square_mesh.results.json by default)\nngraph run scenarios/square_mesh.yaml\n</code></pre>"},{"location":"reference/cli/#command-reference","title":"Command Reference","text":""},{"location":"reference/cli/#inspect","title":"<code>inspect</code>","text":"<p>Analyze and validate a NetGraph scenario file without executing it.</p> <p>Syntax:</p> <pre><code>ngraph [--verbose|--quiet] inspect &lt;scenario_file&gt; [options]\n</code></pre> <p>Arguments:</p> <ul> <li><code>scenario_file</code>: Path to the YAML scenario file to inspect</li> </ul> <p>Options:</p> <ul> <li><code>--detail</code>, <code>-d</code>: Show detailed information including complete node/link tables and step parameters</li> <li><code>--output</code>, <code>-o</code>: Output directory for generated artifacts (e.g., profiles)</li> </ul> <p>What it does:</p> <p>The <code>inspect</code> command loads and validates a scenario file, then provides information about:</p> <ul> <li>Scenario metadata: Seed configuration and deterministic behavior</li> <li>Network structure: Node/link counts, enabled/disabled breakdown, hierarchy analysis</li> <li>Capacity statistics: Link and node capacity analysis with min/max/mean/total values</li> <li>Risk groups: Network resilience groupings and their status</li> <li>Components library: Available components for network modeling</li> <li>Failure policies: Configured failure scenarios and their rules</li> <li>Traffic matrices: Demand patterns and traffic flows</li> <li>Workflow steps: Analysis pipeline and step-by-step execution plan</li> </ul> <p>In detail mode (<code>--detail</code>), shows complete tables for all nodes and links with capacity and connectivity information.</p> <p>Examples:</p> <pre><code># Basic inspection\nngraph inspect scenarios/backbone_clos.yml\n\n# Detailed inspection with complete node/link tables and step parameters\nngraph inspect scenarios/nsfnet.yaml --detail\n\n# Inspect with verbose logging (note: global option placement)\nngraph --verbose inspect scenarios/square_mesh.yaml\n</code></pre> <p>Use cases:</p> <ul> <li>Scenario validation: Verify YAML syntax and structure</li> <li>Network debugging: Analyze blueprint expansion and node/link creation</li> <li>Capacity analysis: Review network capacity distribution and connectivity</li> <li>Workflow preview: Examine analysis steps before execution</li> </ul>"},{"location":"reference/cli/#run","title":"<code>run</code>","text":"<p>Execute a NetGraph scenario file.</p> <p>Syntax:</p> <pre><code>ngraph [--verbose|--quiet] run &lt;scenario_file&gt; [options]\n</code></pre> <p>Arguments:</p> <ul> <li><code>scenario_file</code>: Path to the YAML scenario file to execute</li> </ul> <p>Options:</p> <ul> <li><code>--results</code>, <code>-r</code>: Path to export results as JSON (default: <code>&lt;scenario_name&gt;.results.json</code>)</li> <li><code>--no-results</code>: Disable results file generation</li> <li><code>--stdout</code>: Print results to stdout in addition to saving file</li> <li><code>--keys</code>, <code>-k</code>: Space-separated list of workflow step names to include in output</li> <li><code>--profile</code>: Enable performance profiling with CPU analysis and bottleneck detection</li> <li><code>--profile-memory</code>: Also track peak memory per step</li> <li><code>--output</code>, <code>-o</code>: Output directory for generated artifacts</li> </ul>"},{"location":"reference/cli/#examples","title":"Examples","text":""},{"location":"reference/cli/#basic-execution","title":"Basic Execution","text":"<pre><code># Run a scenario (creates square_mesh.results.json by default)\nngraph run scenarios/square_mesh.yaml\n\n# Run a scenario and save results to custom file\nngraph run scenarios/backbone_clos.yml --results clos_analysis.json\n\n# Run a scenario without creating any files\nngraph run scenarios/nsfnet.yaml --no-results\n</code></pre>"},{"location":"reference/cli/#save-results-to-file","title":"Save Results to File","text":"<pre><code># Save results to a custom JSON file\nngraph run scenarios/backbone_clos.yml --results analysis.json\n\n# Save to file AND print to stdout\nngraph run scenarios/backbone_clos.yml --results analysis.json --stdout\n\n# Use default filename and also print to stdout\nngraph run scenarios/square_mesh.yaml --stdout\n</code></pre>"},{"location":"reference/cli/#running-test-scenarios","title":"Running Test Scenarios","text":"<pre><code># Run one of the provided scenarios with results export\nngraph run scenarios/backbone_clos.yml --results results.json\n</code></pre>"},{"location":"reference/cli/#filtering-results-by-step-names","title":"Filtering Results by Step Names","text":"<p>You can filter the output to include only specific workflow steps using the <code>--keys</code> option:</p> <pre><code># Only include results from the MSD step\nngraph run scenarios/square_mesh.yaml --keys msd_baseline --stdout\n\n# Include multiple specific steps and save to custom file\nngraph run scenarios/backbone_clos.yml --keys network_statistics tm_placement --results filtered.json\n\n# Filter and print to stdout while using default file\nngraph run scenarios/backbone_clos.yml --keys network_statistics --stdout\n</code></pre> <p>The <code>--keys</code> option filters by the <code>name</code> field of workflow steps defined in your scenario YAML file. For example, if your scenario has:</p> <pre><code>workflow:\n  - step_type: NetworkStats\n    name: network_statistics\n  - step_type: MaximumSupportedDemand\n    name: msd_baseline\n</code></pre> <p>Then <code>--keys build_graph</code> will include only the results from the BuildGraph step, and <code>--keys capacity_analysis</code> will include only the MaxFlow results.</p>"},{"location":"reference/cli/#performance-profiling","title":"Performance Profiling","text":"<p>Enable performance profiling to identify bottlenecks and analyze execution time:</p> <pre><code># Run scenario with profiling\nngraph run scenarios/backbone_clos.yml --profile\n\n# Combine profiling with results export\nngraph run scenarios/backbone_clos.yml --profile --results analysis.json\n\n# Profile specific workflow steps and track memory\nngraph run scenarios/backbone_clos.yml --profile --profile-memory --keys tm_placement\n</code></pre> <p>The profiling output includes:</p> <ul> <li>Summary: Total execution time, CPU efficiency, function call statistics</li> <li>Step timing: Time spent in each workflow step with percentage breakdown</li> <li>Bottlenecks: Steps consuming &gt;10% of total execution time</li> <li>Function analysis: Top CPU-consuming functions within bottlenecks</li> <li>Recommendations: Specific suggestions for each bottleneck</li> </ul> <p>When to use profiling:</p> <ul> <li>Performance analysis during development</li> <li>Identifying bottlenecks in complex workflows</li> <li>Benchmarking before/after changes</li> </ul>"},{"location":"reference/cli/#output-format","title":"Output Format","text":"<p>The CLI outputs results as JSON with a fixed top-level shape:</p> <pre><code>{\n  \"workflow\": { \"&lt;step&gt;\": { \"step_type\": \"...\", \"execution_order\": 0, \"step_name\": \"...\" } },\n  \"steps\": {\n    \"network_statistics\": { \"metadata\": {}, \"data\": { \"node_count\": 42, \"link_count\": 84 } },\n    \"msd_baseline\": { \"metadata\": {}, \"data\": { \"alpha_star\": 1.23, \"context\": { \"matrix_name\": \"baseline_traffic_matrix\" } } },\n    \"tm_placement\": { \"metadata\": { \"iterations\": 1000 }, \"data\": { \"flow_results\": [ { \"flows\": [], \"summary\": {} } ], \"context\": { \"matrix_name\": \"baseline_traffic_matrix\" } } }\n  },\n  \"scenario\": { \"seed\": 42, \"failure_policy_set\": { }, \"traffic_matrices\": { } }\n}\n</code></pre> <ul> <li>BuildGraph: stores <code>data.graph</code> in node-link JSON format</li> <li>MaxFlow and TrafficMatrixPlacement: store <code>data.flow_results</code> as lists of per-iteration results (flows + summary)</li> <li>NetworkStats: stores capacity and degree statistics under <code>data</code></li> </ul>"},{"location":"reference/cli/#output-behavior","title":"Output Behavior","text":"<p>NetGraph CLI generates results by default for analysis workflows:</p>"},{"location":"reference/cli/#default-behavior-results-generated","title":"Default Behavior (Results Generated)","text":"<pre><code>ngraph run scenarios/square_mesh.yaml\n</code></pre> <ul> <li>Executes the scenario</li> <li>Logs execution progress to the terminal</li> <li>Creates <code>&lt;scenario_name&gt;.results.json</code> by default</li> <li>Shows success message with file location</li> </ul>"},{"location":"reference/cli/#custom-results-file","title":"Custom Results File","text":"<pre><code># Save to custom file\nngraph run scenarios/square_mesh.yaml --results my_analysis.json\n</code></pre> <ul> <li>Creates specified JSON file instead of results.json</li> <li>Useful for organizing multiple analysis runs</li> </ul>"},{"location":"reference/cli/#print-to-terminal","title":"Print to Terminal","text":"<pre><code>ngraph run scenarios/square_mesh.yaml --stdout\n</code></pre> <ul> <li>Creates results.json AND prints JSON to stdout</li> <li>Useful for viewing results immediately while also saving them</li> </ul>"},{"location":"reference/cli/#combined-output","title":"Combined Output","text":"<pre><code>ngraph run scenarios/square_mesh.yaml --results analysis.json --stdout\n</code></pre> <ul> <li>Creates custom JSON file AND prints to stdout</li> <li>Provides flexibility for different workflows</li> </ul>"},{"location":"reference/cli/#disable-file-generation-edge-cases","title":"Disable File Generation (Edge Cases)","text":"<pre><code>ngraph run scenarios/square_mesh.yaml --no-results\n</code></pre> <ul> <li>Executes scenario without creating any output files</li> <li>Only shows execution logs and completion status</li> <li>Useful for testing, CI/CD validation, or when only logs are needed</li> </ul>"},{"location":"reference/cli/#integration-with-workflows","title":"Integration with Workflows","text":"<p>The CLI executes the complete workflow defined in your scenario file, running all steps in sequence and accumulating results. This runs complex network analysis tasks without manual intervention.</p>"},{"location":"reference/cli/#recommended-workflow","title":"Recommended Workflow","text":"<ol> <li>Inspect first: Always use <code>inspect</code> to validate and understand your scenario</li> <li>Debug issues: Use detailed inspection to troubleshoot network expansion problems</li> <li>Run after validation: Execute scenarios after successful inspection</li> <li>Iterate: Use inspection during scenario development to verify changes</li> </ol> <pre><code># Development workflow\nngraph inspect scenarios/backbone_clos.yml --detail\nngraph run scenarios/backbone_clos.yml\n</code></pre>"},{"location":"reference/cli/#debugging-scenarios","title":"Debugging Scenarios","text":"<p>When developing complex scenarios with blueprints and hierarchical structures:</p> <pre><code># Check if scenario loads correctly\nngraph inspect scenarios/square_mesh.yaml\n\n# Debug network expansion issues (note: global option placement)\nngraph --verbose inspect scenarios/backbone_clos.yml --detail\n\n# Verify workflow steps are configured correctly\nngraph inspect scenarios/backbone_clos.yml --detail | grep -A 5 \"WORKFLOW STEPS\"\n</code></pre> <p>The <code>inspect</code> command will catch common issues like:</p> <ul> <li>Invalid YAML syntax</li> <li>Missing blueprint references</li> <li>Incorrect node/link patterns</li> <li>Workflow step configuration errors</li> <li>Risk group and policy definition problems</li> </ul>"},{"location":"reference/design/","title":"NetGraph Design and Implementation","text":"<p>This document describes NetGraph's internal design: scenario DSL, data models, execution flow, algorithms, manager components, and result handling. It focuses on architecture and key implementation details.</p>"},{"location":"reference/design/#overview","title":"Overview","text":"<p>NetGraph is a network scenario analysis engine. It takes a scenario (defined in a YAML DSL) as input, builds a directed multigraph model of the network, and runs a configurable workflow of analysis steps (like traffic placement or max-flow capacity) to produce structured results. Key components include:</p> <ul> <li> <p>CLI and API: Entry points to load scenarios and invoke analyses.</p> </li> <li> <p>Scenario DSL Parser: Validates and expands the YAML scenario into an internal model.</p> </li> <li> <p>Domain Model: In-memory representation of nodes, links, risk groups, etc., with selection and grouping utilities.</p> </li> <li> <p>NetworkView: A read-only overlay on the model to simulate failures or what-if scenarios without altering the base network.</p> </li> <li> <p>Graph construction: Builds a <code>StrictMultiDiGraph</code> (a <code>networkx.MultiDiGraph</code> subclass) from the <code>Network</code> or <code>NetworkView</code> for consumption by SPF/KSP/MaxFlow (compact or full, optional reverse edges).</p> </li> <li> <p>Algorithms: Core graph algorithms: shortest paths (SPF and KSP, k-shortest paths) and max-flow, with configurable edge selection and flow splitting strategies.</p> </li> <li> <p>Managers: Orchestrators for higher-level behaviors, e.g., expanding demands over time or enumerating failure cases.</p> </li> <li> <p>Workflow Engine: Composes steps (graph build, demand placement, max flow, etc.) into end-to-end analyses, storing outputs in a results store.</p> </li> <li> <p>Results Store: Collects outputs and metadata from each step, enabling structured JSON export for post-analysis.</p> </li> </ul>"},{"location":"reference/design/#execution-flow","title":"Execution Flow","text":"<p>The diagram below shows simplified end-to-end execution flow from scenario input to results.</p> <p></p>"},{"location":"reference/design/#scenario-dsl-and-input-expansion","title":"Scenario DSL and Input Expansion","text":"<p>NetGraph scenarios are defined in YAML using a declarative DSL (see DSL Reference). The DSL allows concise specification of network topologies, traffic demands, failure policies, and analysis workflows. Before execution, scenario files are validated against a JSON Schema to catch errors early (unknown keys, type mismatches), enforcing strict definitions.</p> <p>Key elements of the DSL include:</p> <ul> <li> <p>Seed: A master random seed for the scenario to ensure deterministic behavior across runs.</p> </li> <li> <p>Blueprints: Reusable templates for subsets of the topology. A blueprint defines internal node types, roles, and optional internal links. Blueprints enable defining a complex multi-node topology once and instantiating it multiple times with different parameters.</p> </li> <li> <p>Groups: Definitions of groups of nodes in the topology, either explicitly or via patterns. Groups can use a blueprint (use_blueprint) with parameters, or define a number of nodes (node_count) with a naming template.</p> </li> <li> <p>Adjacency: Rules to generate links between groups of nodes. Instead of enumerating every link, an adjacency rule specifies source and target selectors (by path pattern), a wiring pattern (e.g. mesh for full mesh or one_to_one for paired links), number of parallel links (link_count), and link parameters (capacity, cost, attributes like distance, hardware, risk group tags, etc.). Advanced matching allows filtering nodes by attributes with logical conditions (AND/OR) to apply adjacency rules to selected nodes only. A single rule can thus expand into many concrete links.</p> </li> <li> <p>Overrides: Optional modifications applied after the initial expansion. node_overrides or link_overrides can match specific nodes or links (by path or endpoints) and change their attributes or disable them. This allows fine-tuning or simulating removals without changing the base definitions.</p> </li> <li> <p>Risk Groups: Named shared-risk groups (potentially nested) that nodes or links can belong to. These are used in failure scenarios to correlate failures (e.g. all links in a risk group fail together).</p> </li> <li> <p>Traffic Matrices: Demand definitions specifying source node sets, sink node sets (by regex or attribute path selectors), and demand volume. Each demand can also include priority or custom flow placement policy.</p> </li> <li> <p>Failure Policies: Definitions of failure scenarios or modes, possibly with weights (probabilities). For example, a policy might say \"with 5% chance, fail any single core node\" or \"fail all links in risk_group X\". The failure manager uses these policies to generate specific failure combinations for simulation.</p> </li> <li> <p>Workflow: An ordered list of analysis steps to execute. Each step has a step_type (the analysis to perform, such as \"MaxFlow\" or \"TrafficMatrixPlacement\"), a unique name, and parameters (like number of iterations, etc.). The workflow definition orchestrates the analysis pipeline.</p> </li> </ul>"},{"location":"reference/design/#dsl-expansion-process","title":"DSL Expansion Process","text":"<p>The loader validates and expands DSL definitions into concrete nodes and links. Unknown fields or schema violations cause an immediate error before any expansion. After schema validation, blueprints are resolved (each blueprint group becomes actual Node objects), group name patterns are expanded into individual names, and adjacency rules are iterated over matching source-target node sets to create Link objects. All nodes and links are then validated in runtime to ensure they are valid (e.g., no duplicate node names, all link endpoints exist).</p>"},{"location":"reference/design/#data-model","title":"Data Model","text":"<p>Once the scenario is parsed and expanded, NetGraph represents the network with a set of core model classes. These define the authoritative in-memory representation of the scenario and enforce invariants (like unique names).</p>"},{"location":"reference/design/#node","title":"Node","text":"<p>A Node represents a network node (vertex). Each node has:</p> <ul> <li> <p>a unique name (string identifier),</p> </li> <li> <p>a disabled flag (if the node is turned off in the scenario),</p> </li> <li> <p>a set of risk_groups (associating the node with any failure domains), and</p> </li> <li> <p>an attrs dictionary for arbitrary metadata (e.g., region, device type, hardware info)</p> </li> </ul>"},{"location":"reference/design/#link","title":"Link","text":"<p>A Link represents a directed link between a source and target node. Each link has:</p> <ul> <li> <p>source and target node names,</p> </li> <li> <p>capacity (float, e.g. in some bandwidth unit),</p> </li> <li> <p>cost (float, e.g. distance or latency metric),</p> </li> <li> <p>disabled flag,</p> </li> <li> <p>risk_groups set,</p> </li> <li> <p>attrs dict for metadata (e.g. distance_km, fiber type), and</p> </li> <li> <p>an auto-generated unique id</p> </li> </ul> <p>The id is constructed as \"source|target|\", ensuring each link has a distinct identifier. The model stores each link as directed (source -&gt; target). When the analysis graph is built, a reverse edge is added by default so algorithms see bidirectional connectivity."},{"location":"reference/design/#riskgroup","title":"RiskGroup","text":"<p>A RiskGroup represents a named failure domain or shared-risk link group (SRLG). Risk groups can be hierarchical (a risk group may have children risk groups). Each RiskGroup has:</p> <ul> <li> <p>a name,</p> </li> <li> <p>list of children RiskGroups (which inherit the failure domain property),</p> </li> <li> <p>disabled flag (if the entire group is considered initially failed in the scenario), and</p> </li> <li> <p>an attrs dict for any metadata</p> </li> </ul> <p>Hierarchical risk groups allow, for example, defining a large domain composed of smaller sub-domains. A failure event could disable an entire group, implicitly affecting all its descendants.</p>"},{"location":"reference/design/#network","title":"Network","text":"<p>A Network is the container class that holds all nodes, links, and top-level risk groups for the scenario. The Network class maintains:</p> <ul> <li> <p>nodes: Dict[name, Node],</p> </li> <li> <p>links: Dict[id, Link],</p> </li> <li> <p>risk_groups: Dict[name, RiskGroup],</p> </li> </ul> <p>The Network is the authoritative source of truth for the topology. It provides methods to add nodes and links, enforcing invariants. For example, adding a link checks that the source and target nodes exist in the network, and prevents duplicate node additions. The Network also never removes nodes or links; instead, disabled flags are used to mark elements inactive.</p>"},{"location":"reference/design/#node-and-link-selection","title":"Node and Link Selection","text":"<p>A powerful feature of the model is the ability to select groups of nodes by pattern, which is used by algorithms to choose source/sink sets matching on their structured names or attributes. Network.select_node_groups_by_path(pattern) accepts either a regex or an attribute query:</p> <p>If the pattern is of the form <code>attr:&lt;name&gt;</code>, it groups nodes by the value of the given attribute name. For example, <code>attr:role</code> might group nodes by their role attribute (like \"core\", \"leaf\", etc.), returning a dict mapping each distinct value to the list of nodes with that value. Nodes missing the attribute are excluded.</p> <p>Otherwise, the pattern is treated as an anchored regular expression on the node's name. If the regex contains capturing groups, the concatenated capture groups form the group label; otherwise, the entire pattern string is used as the label. For instance, the pattern <code>r\"(\\w+)-(\\d+)\"</code> on node names could produce group labels like \"metroA-1\" etc. If no nodes match, an empty mapping is returned (with a debug log) instead of an error, so higher-level logic can handle it.</p> <p>This selection mechanism allows workflow steps and API calls to refer to nodes flexibly (using human-readable patterns instead of explicit lists), which is particularly useful in large topologies.</p>"},{"location":"reference/design/#disabled-elements","title":"Disabled Elements","text":"<p>Nodes or links marked as disabled=True represent elements present in the design but out of service for the analysis. The base model keeps them in the collection but they will be ignored when building the analysis graph or when creating views (the disabled flag is always checked and such elements filtered out). This design preserves topology information (e.g., you know a link exists but is just turned off) and allows easily enabling it later if needed.</p>"},{"location":"reference/design/#networkview","title":"NetworkView","text":"<p>To simulate failures or other what-if scenarios without modifying the base network, NetGraph uses the NetworkView class. A NetworkView is essentially a read-only filtered view of a Network.</p> <p>You create a NetworkView by specifying a base Network and sets of nodes and links to exclude. For example:</p> <pre><code>view = NetworkView.from_excluded_sets(base_network,\n                                     excluded_nodes={\"Node5\"},\n                                     excluded_links={\"A|B|xyz123\"})\n</code></pre> <p>This will behave like the original network except that Node5 and the link with id \"A|B|xyz123\" are considered \"hidden\".</p> <p>The view is read-only: it does not allow adding or removing nodes or links. It delegates attribute access to the base network but filters out anything in the excluded sets or disabled in the scenario. For example, view.nodes returns a dict of Node objects excluding any hidden node.</p> <p>Similarly, view.links provides only links not hidden. This means algorithms run on a view automatically ignore the failed components.</p> <p>Multiple concurrent views can be created on the same base network. This is important for performing parallel simulations (e.g., analyzing many failure combinations in a Monte Carlo) without copying the entire network each time. Each view carries its own exclusion sets.</p> <p>Importantly, a NetworkView can be converted into a graph just like a full Network. NetworkView.to_strict_multidigraph(add_reverse=True, compact=True) will build the directed graph of the visible portion of the network. Internally, the view uses the base network's graph-building function with the exclusion sets applied. The first time this is called for a given parameter combination, the result is cached inside the view. Subsequent calls with the same flags retrieve the cached graph instead of rebuilding. This caching avoids redundant work when running multiple algorithms on the same view (e.g., running many flow computations on the same failed topology) and is crucial for performance.</p> <p>The NetworkView overlay avoids mutating the base graph when simulating failures (e.g., deleting nodes or toggling flags). It separates the static scenario (base network) from dynamic conditions (the view), enabling thread-safe parallel analyses and eliminating deep copies for each failure scenario. This improves performance and keeps semantics clear.</p>"},{"location":"reference/design/#graph-construction-strictmultidigraph","title":"Graph Construction (StrictMultiDiGraph)","text":"<p>NetGraph uses a custom graph implementation, StrictMultiDiGraph, to represent the network topology for analysis algorithms. This class is a subclass of networkx.MultiDiGraph with stricter semantics and performance tweaks.</p> <ul> <li> <p>Explicit node management: The graph does not auto-create nodes. If you try to add an edge with a non-existent node, it raises an error instead of silently adding the node. This ensures that any edge references a valid node from the model (catching bugs where a node might be misspelled or not added).</p> </li> <li> <p>No duplicate nodes; unique edge keys: Adding an existing node raises a ValueError. Parallel edges are allowed, but each edge key must be unique. If an explicit key is provided to <code>add_edge</code> and it's already in use, an error is raised; if no key is provided, the graph generates a new unique key.</p> </li> <li> <p>Stable edge identifiers: The edge keys (IDs) are monotonically increasing integers assigned in insertion order and never reused. This provides globally unique, stable keys, simplifying flow analysis and result mapping.</p> </li> <li> <p>Fast deep copy: Copying large graphs in Python can be expensive. StrictMultiDiGraph.copy() by default uses a pickle-based deep copy (serializing and deserializing the graph), which in many cases outperforms the iterative copy provided by NetworkX. This is especially beneficial when duplicating graphs for separate computations.</p> </li> <li> <p>Compatibility with NetworkX: StrictMultiDiGraph is compatible with NetworkX's MultiDiGraph API. It can be used as a drop-in replacement for MultiDiGraph in NetworkX code. All NetworkX algorithms and utilities supporting MultiDiGraph can be used with StrictMultiDiGraph.</p> </li> </ul> <p>The Network (or NetworkView) produces a StrictMultiDiGraph via to_strict_multidigraph(add_reverse=True, compact=...).</p> <p>If compact=True, the graph is built with minimal attributes: only each edge's capacity and cost are set, and edge keys are auto-assigned integers. Node attributes are omitted in this mode. The original link ID and any custom attributes are not carried to reduce overhead. If compact=False, the graph includes full fidelity: nodes carry their attrs, and each edge is added with the original link's id (link_id) and all its attrs from the model. In full mode, the edge key in the StrictMultiDiGraph is still a unique integer, but the original link id is stored as an attribute on the edge for traceability.</p> <p>If add_reverse=True (the default), for every Link in the network, a reverse edge is also added. This effectively makes the analysis graph bidirectional even though the model stores directed links. In other words, the algorithms will consider traffic flowing in both directions on each physical link unless add_reverse is turned off. The reverse edge uses the same link attributes; however, it is a distinct edge object in the graph with its own unique key.</p> <p>The rationale for compact=True by default in analyses is performance: stripping down to just capacity and cost (which are floats) yields a lighter-weight graph, which improves algorithm speed by reducing Python overhead (fewer attributes to copy or inspect).</p>"},{"location":"reference/design/#analysis-algorithms","title":"Analysis Algorithms","text":"<p>NetGraph's core algorithms revolve around path-finding and flow computation on the graph. These algorithms are designed to handle the multi-graph nature (parallel edges), cost metrics, and varying selection policies. Performance is critical, so certain specialized code paths and heuristics are used.</p>"},{"location":"reference/design/#shortest-path-first-spf-algorithm","title":"Shortest-Path First (SPF) Algorithm","text":"<p>NetGraph uses a Dijkstra-like algorithm with pluggable edge selection and optional multipath predecessor recording. Key features of <code>ngraph.algorithms.spf.spf</code> include:</p> <p>Edge Selection Policies: Rather than always choosing a single smallest-weight edge per step, the algorithm evaluates edges per neighbor. The behavior is governed by an EdgeSelect policy. For example:</p> <ul> <li> <p>EdgeSelect.ALL_MIN_COST (default): for each neighbor v, include all parallel edges u-&gt;v that achieve the minimal edge cost among u-&gt;v edges.</p> </li> <li> <p>EdgeSelect.SINGLE_MIN_COST: for each neighbor v, choose a single u-&gt;v edge with minimal edge cost (ties broken deterministically).</p> </li> <li> <p>EdgeSelect.ALL_MIN_COST_WITH_CAP_REMAINING: for each neighbor v, consider only u-&gt;v edges with residual capacity and include all with minimal edge cost among those.</p> </li> </ul> <p>Other policies include capacity-aware single-edge, load-factored single-edge, and <code>USER_DEFINED</code> via a callback.</p> <p>Capturing equal-cost predecessors: With multipath=True, SPF stores all minimal-cost predecessors: <code>pred[node][predecessor] = [edge_id, ...]</code>. New equal-cost routes extend the predecessor set rather than overwrite.</p> <p>This predecessor DAG is essential for later flow splitting: it retains all equal-cost paths in a compact form.</p> <p>Early destination stop: If <code>dst</code> is provided, once <code>dst</code> is popped at minimal distance, SPF does not expand from <code>dst</code> and continues only while the heap front cost equals that minimal distance. This preserves equal-cost predecessors and terminates early.</p> <p>This optimization saves time when only a specific target's distance is needed.</p> <p>Specialized fast path: With no exclusions and <code>ALL_MIN_COST</code> or <code>ALL_MIN_COST_WITH_CAP_REMAINING</code>, SPF uses optimized loops (<code>_spf_fast_*</code>) that inline per-neighbor scanning and skip callbacks.</p> <p>Complexity: Using a binary heap, time is (O((V+E) \\log V)); memory is (O(V+E)) for costs and predecessors.</p>"},{"location":"reference/design/#pseudocode-for-edgeselectall_min_cost-no-exclusions","title":"Pseudocode (for EdgeSelect.ALL_MIN_COST, no exclusions)","text":"<pre><code>function SPF_AllMinCost(graph, src, dst=None, multipath=True):\n    costs = { src: 0 }\n    pred  = { src: {} }            # no predecessor for source\n    pq = [(0, src)]               # min-heap of (cost, node)\n    best_dst_cost = None\n\n    while pq:\n        (c, u) = heappop(pq)\n        if c &gt; costs[u]:\n            continue               # stale entry in pq\n        if dst is not None and u == dst and best_dst_cost is None:\n            best_dst_cost = c      # found shortest path to dst\n\n        if dst is None or u != dst:\n            # Relax edges from u\n            for v, edges_map in graph._adj[u].items():\n                # find minimal cost among edges u-&gt;v\n                min_cost = inf\n                min_edges = []\n                for e_id, e_attr in edges_map.items():\n                    ec = e_attr[\"cost\"]\n                    if ec &lt; min_cost:\n                        min_cost = ec\n                        min_edges = [e_id]\n                    elif multipath and ec == min_cost:\n                        min_edges.append(e_id)\n                if min_cost == inf:\n                    continue  # no edges\n                new_cost = c + min_cost\n                if v not in costs or new_cost &lt; costs[v]:\n                    costs[v] = new_cost\n                    pred[v] = { u: min_edges }\n                    heappush(pq, (new_cost, v))\n                elif multipath and new_cost == costs[v]:\n                    pred[v][u] = min_edges\n\n        if best_dst_cost is not None:\n            # If next closest node is farther than dst, done\n            if not pq or pq[0][0] &gt; best_dst_cost:\n                break\n\n    return costs, pred\n</code></pre> <p>This pseudocode corresponds to the implementation. With EdgeSelect.ALL_MIN_COST_WITH_CAP_REMAINING, edges with no residual capacity are skipped when computing min_edges. When multipath=False, only a single predecessor is stored per node.</p>"},{"location":"reference/design/#maximum-flow-algorithm","title":"Maximum Flow Algorithm","text":"<p>NetGraph's max-flow uses iterative shortest-path augmentation, blending Edmonds-Karp (augment along shortest paths) and Dinic (push blocking flows on a level graph) with cost awareness and configurable flow splitting across equal-cost parallels. It is implemented in <code>ngraph.algorithms.max_flow.calc_max_flow</code>. The goal is to compute the maximum feasible flow between a provided source and sink under edge capacity constraints.</p> <p>Multi-source/multi-sink is handled by callers when needed (e.g., Demand Manager in <code>combine</code> mode) by introducing pseudo-source and pseudo-sink nodes with infinite-capacity, zero-cost edges to/from the real endpoints. <code>calc_max_flow</code> itself operates on a single source and single sink and does not create pseudo nodes.</p> <p>The residual network is implicit on the flow-aware graph. For a physical edge u-&gt;v:</p> <ul> <li>Forward residual arc u-&gt;v has capacity <code>capacity(u,v) - flow(u,v)</code>.</li> <li>Reverse residual arc v-&gt;u (implicit, not stored) has capacity <code>flow(u,v)</code>. No physical reverse edge is required for residual traversal. SPF traverses only forward residual arcs u-&gt;v. Reverse residual arcs v-&gt;u are used when computing reachability for the min-cut and within blocking-flow computations; they are not considered by SPF. This is distinct from <code>add_reverse=True</code> during graph construction, which adds an actual reverse physical edge with its own capacity and cost.</li> </ul> <p>Reverse residual arcs are not stored as edges in the <code>StrictMultiDiGraph</code>. They are derived on the fly from edge attributes:</p> <ul> <li>For reachability/min-cut, we traverse incoming edges and treat v-&gt;u as available when <code>flow(u,v) &gt; eps</code>.</li> <li>For blocking-flow, <code>calc_graph_capacity</code> builds a reversed adjacency from the SPF predecessor DAG and computes residual capacities from <code>capacity - flow</code> (forward) and <code>flow</code> (reverse) without mutating the graph.</li> </ul> <p>The core loop finds augmenting paths using the cost-aware SPF described above:</p> <p>Run SPF from the source to the sink with edge selection ALL_MIN_COST_WITH_CAP_REMAINING. This computes shortest-path distances and a predecessor DAG to the sink over forward residual edges with residual capacity &gt; 0 (no reverse arcs). The edge cost can represent distance or preference; SPF selects minimum cumulative cost.</p> <p>If the pseudo-sink is not reached (i.e., no augmenting path exists), stop: the max flow is achieved.</p> <p>Otherwise, determine how much flow can be sent along the found paths:</p> <p>Using the pred DAG from SPF, compute a blocking flow with consideration of parallel edges and the chosen splitting policy. This is done by <code>calc_graph_capacity</code> (Dinic-like): it builds a reversed residual view from the sink, assigns BFS levels, and uses DFS to push blocking flow. With parallel equal-cost edges, flow is split proportionally to residual capacity (PROPORTIONAL) or equally (EQUAL_BALANCED) until a bottleneck is reached.</p> <p>This yields a value f (flow amount) and a per-edge flow assignment on the predecessor DAG (fractions that sum to 1 along outgoing splits).</p> <p>We then augment the flow: for each edge on those shortest paths, increase its flow attribute by the assigned portion of f. The algorithm updates both per-edge flow and aggregate node flow for bookkeeping, and marks which edges carried flow.</p> <p>Add f to the total flow counter.</p> <p>If f is below a small tolerance eps (meaning no meaningful flow could be added, perhaps due to rounding or all residual capacity being negligible), break out and treat it as saturated.</p> <p>Repeat to find the next augmenting path (back to step 1).</p> <p>If <code>shortest_path=True</code>, the algorithm performs only one augmentation pass and returns (useful when the goal is a single cheapest augmentation rather than maximum flow).</p> <p>After the loop, if detailed results are requested, the algorithm computes a FlowSummary which includes:</p> <ul> <li> <p>total_flow: the sum of flow from source to sink achieved</p> </li> <li> <p>edge_flow: a dictionary of each edge (u,v,key) to the flow on that edge</p> </li> <li> <p>residual_cap: remaining capacity on each edge = capacity - flow</p> </li> <li> <p>reachable: the set of nodes reachable from the source in the final residual network (this identifies the source side of the min-cut)</p> </li> <li> <p>min_cut: the list of edges that are saturated and go from reachable to non-reachable (these form the minimum cut)</p> </li> <li> <p>cost_distribution: how much flow was sent in each augmentation step cost (e.g., X flow units were sent along paths of cost Y)</p> </li> </ul> <p>This is returned along with the total flow value. If a flow-assigned graph copy is requested, that is also returned.</p>"},{"location":"reference/design/#flow-placement-strategies","title":"Flow Placement Strategies","text":"<p>NetGraph's max-flow differs from classical augmenting-path implementations by controlling how flow is split across equal-cost parallel edges in each augmentation. Governed by <code>FlowPlacement</code>:</p> <ul> <li> <p>PROPORTIONAL (default): If multiple parallel edges have equal cost on a path segment, distribute flow among them in proportion to their remaining capacities. This mimics how weighted equal-cost multi-path (W-ECMP or WCMP) routing splits flow based on link bandwidth.</p> </li> <li> <p>EQUAL_BALANCED: Split flow equally across all equal-cost parallel edges, regardless of capacity differences (up to capacity limits). This may under-utilize a higher-capacity link if paired with a lower-capacity one, but it maintains an even load balance until one link saturates. This matches IP forwarding with equal-cost multi-path (ECMP), which splits flow based on the number of parallel paths.</p> </li> </ul> <p><code>calc_graph_capacity</code> implements these strategies:</p> <ul> <li> <p>PROPORTIONAL: Build a reversed residual view from the sink. Assign BFS levels and push blocking flows with DFS, summing capacities across parallel equal-cost edges in each segment. Convert reversed flows back to forward orientation.</p> </li> <li> <p>EQUAL_BALANCED: Build reversed adjacency from the sink. Push a nominal unit flow from the source equally across outgoing reversed arcs, then scale by the minimum capacity-to-assignment ratio to respect capacities; normalize back to forward orientation.</p> </li> </ul> <p>Support for these placement strategies together with control over the path selection and edge selection policies enables realistic modeling of different forwarding and traffic engineering scenarios.</p>"},{"location":"reference/design/#pseudocode-simplified-max-flow-loop","title":"Pseudocode (simplified max-flow loop)","text":"<pre><code>function MAX_FLOW(graph, S, T, placement=PROPORTIONAL):\n    initialize flow_graph with 0 flow on all edges\n    total_flow = 0\n    do:\n        costs, pred = SPF(graph, src=S, dst=T, edge_select=ALL_MIN_COST_WITH_CAP_REMAINING)\n        if T not reachable in pred:\n            break\n        f, flow_dict = calc_graph_capacity(flow_graph, S, T, pred, placement)\n        if f &lt;= eps:\n            break\n        for each edge in flow_dict:\n            add flow on that edge as per flow_dict\n        total_flow += f\n    while True\n    return total_flow, (and optionally summary, flow_graph)\n</code></pre> <p>Here <code>eps</code> denotes a small tolerance (default 1e-10; configurable via parameter).</p> <p>In practice, each augmentation performs one SPF (O((V+E) \\log V)) and one blocking-flow computation over the pred DAG and residual view (typically (O(V+E))). If we pushed one path at a time the worst case would be (O(E)) augmentations, giving (O(E^2 \\log V)). Because we push blocking flows, the number of augmentations is usually far smaller than (E). A practical upper bound is (O(\\min\\{E, F\\} \\cdot (E \\log V))), where (F) is the max-flow value.</p>"},{"location":"reference/design/#managers-and-workflow-orchestration","title":"Managers and Workflow Orchestration","text":"<p>Managers handle scenario dynamics and prepare inputs for algorithmic steps.</p> <p>Demand Manager (<code>ngraph.demand.manager</code>): Expands <code>TrafficDemand</code> entries into concrete <code>Demand</code> objects and places them on a <code>StrictMultiDiGraph</code> derived from the <code>Network</code> (or a <code>NetworkView</code>).</p> <ul> <li>Expansion is deterministic: source/sink node lists are sorted; no randomization is used.</li> <li>Modes: <code>combine</code> (one aggregate demand via pseudo source/sink nodes) and <code>pairwise</code> (one demand per (src, dst) pair, excluding self-pairs, with even volume split).</li> <li>Expanded demands are sorted by ascending priority before placement.</li> <li>Placement uses a priority-aware round-robin scheduler. <code>placement_rounds=\"auto\"</code> performs up to 3 passes with early stop based on progress and fairness.</li> <li>Provides summaries (per-demand placement, link usage) and does not mutate the base <code>Network</code> (operates on the built flow graph).</li> </ul> <p>Failure Manager (<code>ngraph.failure.manager</code>): Applies a <code>FailurePolicy</code> to compute exclusion sets and runs analyses on <code>NetworkView</code> instances.</p> <ul> <li>Supports baseline (no failures), serial or process-parallel execution, and per-worker network caching (the network is serialized once per worker).</li> <li>Deterministic when a seed is supplied (each iteration receives <code>seed + iteration_index</code>).</li> <li>Deduplication: iterations are grouped by a key built from sorted excluded node IDs, sorted excluded link IDs, analysis function name, and analysis parameters. Only one representative per group is executed; results are replicated to all members.</li> <li>This reduces effective executions from I to U, where U is the number of unique failure patterns for the chosen policy and parameters (e.g., 10,000 samples over 250 unique single-link failures execute as 250 tasks, not 10,000).</li> <li>Parameter validation: with no effective failure rules, <code>iterations &gt; 1</code> without <code>baseline=True</code> is rejected; <code>baseline=True</code> requires <code>iterations &gt;= 2</code>.</li> <li>Parallelism auto-adjusts to 1 if the analysis function cannot be pickled (e.g., defined in <code>__main__</code>).</li> </ul> <p>Both managers separate policy (how to expand demands or pick failures) from core algorithms. They prepare concrete inputs (expanded demands or <code>NetworkView</code>s) for each workflow iteration.</p>"},{"location":"reference/design/#workflow-engine-and-steps","title":"Workflow Engine and Steps","text":"<p>NetGraph workflows (see Workflow Reference) are essentially recipes of analysis steps to run in sequence. Each step is typically a pure function: it takes the current model (or view) and possibly prior results, performs an analysis, and stores its outputs. The workflow engine coordinates these steps, using a Results store to record data.</p> <p>Common built-in steps:</p> <ul> <li> <p>BuildGraph: builds a <code>StrictMultiDiGraph</code> from the Network (or view) and stores node-link JSON plus <code>{context: {add_reverse}}</code>. Often an initial step.</p> </li> <li> <p>NetworkStats: computes node/link counts, capacity statistics, cost statistics, and degree statistics. Supports optional <code>excluded_nodes</code>/<code>excluded_links</code> and <code>include_disabled</code>.</p> </li> <li> <p>TrafficMatrixPlacement: runs Monte Carlo placement using a named traffic matrix and the Failure Manager. Supports <code>baseline</code>, <code>iterations</code>, <code>parallelism</code>, <code>placement_rounds</code>, <code>store_failure_patterns</code>, <code>include_flow_details</code>, <code>include_used_edges</code>, and <code>alpha</code> or <code>alpha_from_step</code> (default <code>data.alpha_star</code>). Produces <code>data.flow_results</code> per iteration.</p> </li> <li> <p>MaxFlow: runs Monte Carlo maximum-flow analysis between node groups using the Failure Manager. Supports <code>mode</code> (combine/pairwise), <code>baseline</code>, <code>iterations</code>, <code>parallelism</code>, <code>shortest_path</code>, <code>flow_placement</code>, and optional <code>include_flow_details</code>/<code>include_min_cut</code>. Produces <code>data.flow_results</code> per iteration.</p> </li> <li> <p>MaximumSupportedDemand (MSD): uses bracketing and bisection on alpha to find the maximum multiplier such that alpha * demand is feasible. Stores <code>data.alpha_star</code>, <code>data.context</code>, <code>data.base_demands</code>, and <code>data.probes</code>.</p> </li> <li> <p>CostPower: aggregates platform and per-end optics capex/power by hierarchy level (0..N). Respects <code>include_disabled</code> and <code>aggregation_level</code>. Stores <code>data.levels</code> and <code>data.context</code>.</p> </li> </ul> <p>Each step is implemented in the code (in ngraph.workflow module) and has a corresponding step_type name. Steps are generally pure in that they don't modify the Network (except perhaps to disable something if that's the nature of the step, but usually they operate on views and copies). They take inputs, often including references to prior steps' results (the workflow engine allows one step to use another step's output). For instance, a placement step might need the value of alpha* from an MSD step; the workflow definition can specify that link.</p>"},{"location":"reference/design/#results-storage","title":"Results storage","text":"<p>The Results object is a container that the workflow passes through steps. When a step runs, it \"enters\" a scope in the Results (by step name) and writes any outputs to either metadata or data within that scope.</p> <p>For example, the MaxFlow step named \"maxflow_between_metros\" will put the total flow and details under <code>results.steps[\"maxflow_between_metros\"][\"data\"]</code> and perhaps record parameters in metadata. The Results store also captures each step's execution metadata (like step order, type, seeds) in a workflow registry. At the end of the workflow, a single nested dictionary can be exported via Results.to_dict() containing all step outputs in a structured way.</p> <p>This design ensures consistency (every step has metadata and data keys) and JSON serialization (handles custom objects via to_dict() when available, converts keys to strings). The results often include artifacts like tables or lists of flows for reporting.</p>"},{"location":"reference/design/#design-elements-and-comparisons","title":"Design Elements and Comparisons","text":"<p>NetGraph's design includes several features that differentiate it from traditional network analysis tools:</p> <ul> <li> <p>Declarative Scenario DSL: A YAML DSL with blueprints and programmatic expansion allows abstract definitions (e.g., a fully meshed Clos) to be expanded into concrete nodes and links. Strict schema validation ensures that scenarios are well-formed and rejects unknown or invalid fields.</p> </li> <li> <p>NetworkView overlays vs graph copying: Read-only overlays avoid copying large structures for each scenario. The view is designed for availability toggles and caches built graphs for algorithms.</p> </li> <li> <p>Strict graph with stable edge IDs: Extends <code>MultiDiGraph</code> with explicit node management and monotonic edge keys, simplifying correlation of results to original links.</p> </li> <li> <p>Flow placement strategies (proportional and equal): During augmentation, split flow across equal-cost paths and parallel links, modeling ECMP/WCMP behavior without linear programming.</p> </li> <li> <p>Cost-aware augmentation: Prefer cheapest capacity first. It does not re-route previously placed flow.</p> </li> <li> <p>User-defined edge selection: Custom edge selection logic is supported (EdgeSelect.USER_DEFINED with a callback), enabling custom routing heuristics.</p> </li> <li> <p>Deterministic simulation with seeding: Random aspects (e.g., failure sampling) are controlled by explicit seeds that propagate through steps. Runs are reproducible given the same scenario and seed.</p> </li> <li> <p>Structured results store: Collects results with metadata in a consistent format for JSON export and downstream analysis.</p> </li> </ul>"},{"location":"reference/design/#performance-considerations","title":"Performance Considerations","text":"<p>Throughout the design, performance has been considered:</p> <p>SPF uses Python heapq and optimized loops. Internal profiling shows expected scaling for typical network sizes.</p> <p>Caching graphs in views avoids O(N+E) rebuild costs repeatedly when analyzing many failures.</p> <p>Monte Carlo deduplication collapses identical failure patterns (plus analysis parameters) into single executions. Runtime scales with the number of unique patterns U rather than requested iterations I; in many policies U &lt;&lt; I.</p> <p>Pickle-based deep copy for StrictMultiDiGraph was faster than the default iterative copy for large graphs in local measurements. This reduces the cost of creating multiple independent graph instances.</p> <p>The complexity of algorithms has been kept polynomial and usually near-linear. For instance, typical network max flows (with unit capacities) can be O(VE^2), but by using shortest path (cost) and splitting, NetGraph's algorithm often uses far fewer augmentations than worst-case. Benchmarks on Clos topologies and grid graphs confirm the algorithms perform within expected growth rates and can handle networks of thousands of nodes and edges efficiently.</p> <p>Summary: The design combines a declarative scenario model, reproducible views, a strict graph with stable IDs, cost-aware SPF and augmentation, and a structured results store. It adapts standard algorithms to network engineering use cases (flow splitting, failure simulation, traceable outputs).</p>"},{"location":"reference/design/#cross-references","title":"Cross-references","text":"<ul> <li>DSL Reference</li> <li>Workflow Reference</li> <li>CLI Reference</li> <li>API Reference</li> <li>Auto-Generated API Reference</li> </ul>"},{"location":"reference/dsl/","title":"Domain-Specific Language (DSL)","text":"<p>Quick links:</p> <ul> <li>Design \u2014 architecture, model, algorithms, workflow</li> <li>Workflow Reference \u2014 analysis workflow configuration and execution</li> <li>CLI Reference \u2014 command-line tools for running scenarios</li> <li>API Reference \u2014 Python API for programmatic scenario creation</li> <li>Auto-Generated API Reference \u2014 complete class and method documentation</li> </ul> <p>This document describes the DSL for defining network scenarios in NetGraph. Scenarios are YAML files that describe network topology, traffic demands, and analysis workflows.</p>"},{"location":"reference/dsl/#overview","title":"Overview","text":"<p>A scenario file defines a complete network simulation including:</p> <ul> <li>Network topology: Nodes, links, and their relationships, as well as risk groups</li> <li>Analysis configuration: Traffic demands, failure policies, workflows</li> <li>Reusable components: Blueprints, hardware definitions</li> </ul> <p>The DSL enables both simple direct definitions and complex hierarchical structures with templates and parameters.</p>"},{"location":"reference/dsl/#top-level-keys","title":"Top-Level Keys","text":"<pre><code>network:                 # Network topology (required)\nblueprints:              # Reusable network templates\ncomponents:              # Hardware component library\nrisk_groups:             # Failure correlation groups\nvars:                    # YAML anchors and variables for reuse\ntraffic_matrix_set:      # Traffic demand definitions\nfailure_policy_set:      # Failure simulation policies\nworkflow:                # Analysis execution steps\n</code></pre>"},{"location":"reference/dsl/#network-core-foundation","title":"<code>network</code> - Core Foundation","text":"<p>The only required section. Defines network topology through nodes and links.</p>"},{"location":"reference/dsl/#direct-node-and-link-definitions","title":"Direct Node and Link Definitions","text":"<p>Individual Nodes:</p> <pre><code>network:\n  nodes:\n    SEA:\n      disabled: true\n      risk_groups: [\"RiskGroup1\", \"RiskGroup2\"]\n      attrs:\n        coords: [47.6062, -122.3321]\n        hardware:\n          component: \"LeafRouter\"\n          count: 1\n    SFO:\n      attrs:\n        coords: [37.7749, -122.4194]\n        hardware:\n          component: \"SpineRouter\"\n          count: 1\n</code></pre> <p>Recognized keys for each node entry:</p> <ul> <li><code>disabled</code>: boolean (optional)</li> <li><code>attrs</code>: mapping of attributes (optional)</li> <li><code>risk_groups</code>: list of risk-group names (optional)</li> </ul> <p>Individual Links:</p> <pre><code>network:\n  links:\n    - source: SEA\n      target: SFO\n       link_params:\n         capacity: 200\n         cost: 6846\n         risk_groups: [\"RiskGroup1\", \"RiskGroup2\"]\n         attrs:\n           distance_km: 1369.13\n           media_type: \"fiber\"\n           hardware:\n             source: {component: \"800G-ZR+\", count: 1}\n             target: {component: \"1600G-2xDR4\", count: 1}\n</code></pre> <p>Recognized keys for each link entry:</p> <ul> <li><code>source</code>, <code>target</code>: node names (required)</li> <li><code>link_params</code>: mapping with only these keys allowed: <code>capacity</code>, <code>cost</code>, <code>disabled</code>, <code>risk_groups</code>, <code>attrs</code></li> <li><code>link_count</code>: integer number of parallel links to create (optional; default 1)</li> </ul>"},{"location":"reference/dsl/#group-based-definitions","title":"Group-Based Definitions","text":"<p>Node Groups:</p> <pre><code>network:\n  groups:\n    leaf:\n      node_count: 4\n      name_template: \"leaf-{node_num}\"\n      risk_groups: [\"RG-Leaf\"]\n      attrs:\n        role: \"leaf\"\n    spine:\n      node_count: 2\n      name_template: \"spine-{node_num}\"\n      risk_groups: [\"RG-Spine\"]\n      attrs:\n        role: \"spine\"\n</code></pre> <p>Adjacency Rules:</p> <pre><code>network:\n  adjacency:\n    - source: /leaf\n      target: /spine\n      pattern: \"mesh\"           # Connect every leaf to every spine\n      link_params:\n        capacity: 3200\n        cost: 1\n        # Only the following keys are allowed inside link_params:\n        # capacity, cost, disabled, risk_groups, attrs\n    - source: /spine\n      target: /spine\n      pattern: \"one_to_one\"     # Connect spines pairwise\n      link_count: 2              # Create 2 parallel links per adjacency (optional)\n      link_params:\n        capacity: 1600\n        cost: 1\n        attrs:\n          hardware:\n            source: {component: \"800G-DR4\", count: 2}\n            target: {component: \"800G-DR4\", count: 2}\n    # Tip: In selector objects, 'path' also supports 'attr:&lt;name&gt;' (see Node Selection)\n</code></pre>"},{"location":"reference/dsl/#attribute-filtered-adjacency-selector-objects","title":"Attribute-filtered Adjacency (selector objects)","text":"<p>You can filter the source or target node sets by attributes using the same condition syntax as failure policies. Replace a string <code>source</code>/<code>target</code> with an object that has <code>path</code> and optional <code>match</code>:</p> <pre><code>network:\n  adjacency:\n    - source:\n        path: \"/leaf\"\n        match:\n          logic: \"and\"         # default: \"or\"\n          conditions:\n            - attr: \"role\"\n              operator: \"==\"\n              value: \"leaf\"\n      target:\n        path: \"/spine\"\n        match:\n          conditions:\n            - attr: \"role\"\n              operator: \"==\"\n              value: \"spine\"\n      pattern: \"mesh\"\n      link_params:\n        capacity: 100\n        cost: 1\n</code></pre> <p>Notes:</p> <ul> <li><code>path</code> uses the same semantics as runtime: regex on node name or <code>attr:&lt;name&gt;</code> directive grouping (see Node Selection).</li> <li><code>match.conditions</code> uses the shared condition operators implemented in code: <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>contains</code>, <code>not_contains</code>, <code>any_value</code>, <code>no_value</code>.</li> <li>Conditions evaluate over a flat view of node attributes combining top-level fields (<code>name</code>, <code>disabled</code>, <code>risk_groups</code>) and <code>node.attrs</code>.</li> <li><code>logic</code> in the <code>match</code> block accepts \"and\" or \"or\" (default \"or\").</li> <li>Selectors filter node candidates before the adjacency <code>pattern</code> is applied.</li> <li>Cross-endpoint predicates (e.g., comparing a source attribute to a target attribute) are not supported.</li> <li>Node overrides run before adjacency expansion; link overrides run after adjacency expansion.</li> </ul> <p>Path semantics inside blueprints:</p> <ul> <li>Within a blueprint's <code>adjacency</code>, a leading <code>/</code> is treated as relative to the blueprint instantiation path, not a global root. For example, if a blueprint is used under group <code>pod1</code>, then <code>source: /leaf</code> resolves to <code>pod1/leaf</code>.</li> </ul> <p>Example with OR logic to match multiple roles:</p> <pre><code>network:\n  adjacency:\n    - source:\n        path: \"/metro1/dc[1-1]\"\n        match:\n          conditions:\n            - attr: \"role\"\n              operator: \"==\"\n              value: \"dc\"\n      target:\n        path: \"/metro1/pop[1-2]\"\n        match:\n          logic: \"or\"\n          conditions:\n            - attr: \"role\"\n              operator: \"==\"\n              value: \"leaf\"\n            - attr: \"role\"\n              operator: \"==\"\n              value: \"core\"\n      pattern: \"mesh\"\n</code></pre> <p>Connectivity Patterns:</p> <ul> <li><code>mesh</code>: Full connectivity between all source and target nodes</li> <li><code>one_to_one</code>: Pairwise connections. Compatible sizes means max(|S|,|T|) must be an integer multiple of min(|S|,|T|); mapping wraps modulo the smaller set (e.g., 4\u00d72 and 6\u00d73 valid; 3\u00d72 invalid).</li> </ul>"},{"location":"reference/dsl/#bracket-expansion","title":"Bracket Expansion","text":"<p>Create multiple similar groups using bracket notation:</p> <pre><code>network:\n  groups:\n    dc[1-3]/rack[a,b]:     # Creates dc1/racka, dc1/rackb, dc2/racka, etc.\n      node_count: 4\n      name_template: \"srv-{node_num}\"\n</code></pre> <p>Expansion Types:</p> <ul> <li>Numeric ranges: <code>[1-4]</code> \u2192 1, 2, 3, 4</li> <li>Explicit lists: <code>[red,blue,green]</code> \u2192 red, blue, green</li> </ul>"},{"location":"reference/dsl/#variable-expansion-in-adjacency","title":"Variable Expansion in Adjacency","text":"<pre><code>adjacency:\n  - source: \"plane{p}/rack{r}\"\n    target: \"spine{s}\"\n    expand_vars:\n      p: [1, 2]\n      r: [\"a\", \"b\"]\n      s: [1, 2, 3]\n    expansion_mode: \"cartesian\"  # All combinations\n    pattern: \"mesh\"\n\n  - source: \"server{idx}\"\n    target: \"switch{idx}\"\n    expand_vars:\n      idx: [1, 2, 3, 4]\n    expansion_mode: \"zip\"        # Paired by index\n    pattern: \"one_to_one\"\n</code></pre>"},{"location":"reference/dsl/#blueprints-reusable-templates","title":"<code>blueprints</code> - Reusable Templates","text":"<p>Templates for network segments that can be instantiated multiple times:</p> <pre><code>blueprints:\n  leaf_spine:\n    groups:\n      leaf:\n        node_count: 4\n        name_template: \"leaf-{node_num}\"\n      spine:\n        node_count: 2\n        name_template: \"spine-{node_num}\"\n    adjacency:\n      - source: /leaf\n        target: /spine\n        pattern: mesh\n        link_params:\n          capacity: 40\n          cost: 1\n\nnetwork:\n  groups:\n    pod1:\n      use_blueprint: leaf_spine\n    pod2:\n      use_blueprint: leaf_spine\n      parameters:                # Override blueprint parameters\n        leaf.node_count: 6\n        spine.name_template: \"core-{node_num}\"\n</code></pre> <p>Blueprint Features:</p> <ul> <li>Define groups and adjacency rules once, reuse multiple times</li> <li>Override parameters using dot notation during instantiation</li> <li>Hierarchical naming: <code>pod1/leaf/leaf-1</code>, <code>pod2/spine/core-1</code></li> </ul>"},{"location":"reference/dsl/#node-and-link-overrides","title":"Node and Link Overrides","text":"<p>Modify specific nodes or links after initial creation:</p> <pre><code>network:\n  node_overrides:\n    - path: \"^pod1/spine/.*$\"           # Regex pattern matching\n      disabled: true\n      attrs:\n        maintenance_mode: \"active\"\n    - path: \"server-[1-3]$\"             # Specific node subset\n      attrs:\n        priority: \"high\"\n\n  link_overrides:\n    - source: \"^pod1/leaf/.*$\"\n      target: \"^pod1/spine/.*$\"\n      link_params:\n        capacity: 100                   # Override capacity\n    - source: \".*/spine/.*\"\n      target: \".*/spine/.*\"\n      any_direction: true               # Bidirectional matching\n      link_params:\n        cost: 5\n        attrs:\n          link_type: \"backbone\"\n\nNotes:\n\n- For `link_overrides`, only the keys `source`, `target`, `link_params`, and optional `any_direction` are allowed at the top level. All parameter changes must be nested under `link_params`.\n- `any_direction` defaults to `true` if omitted.\n- Ordering: `node_overrides` run after node creation (groups and direct nodes) and before any adjacency expansion; `link_overrides` run after adjacency and direct links.\n</code></pre>"},{"location":"reference/dsl/#components-hardware-library","title":"<code>components</code> - Hardware Library","text":"<p>Define hardware components with attributes for cost and power modeling:</p> <pre><code>components:\n  SpineRouter:\n    component_type: \"chassis\"\n    cost: 50000.0\n    power_watts: 2500.0\n    capacity: 64000.0           # Gbps\n    ports: 64\n    attrs:\n      vendor: \"VendorName\"\n      model: \"Model-9000\"\n    children:\n      LineCard400G:\n        component_type: \"linecard\"\n        cost: 8000.0\n        power_watts: 400.0\n        capacity: 12800.0\n        ports: 32\n        count: 4\n\n  Optic400G:\n    component_type: \"optic\"\n    cost: 2500.0\n    power_watts: 12.0\n    capacity: 400.0\n    attrs:\n      reach: \"10km\"\n      wavelength: \"1310nm\"\n</code></pre> <p>Component Usage:</p> <pre><code>network:\n  nodes:\n    spine-1:\n      attrs:\n        hardware:\n          component: \"SpineRouter\"\n          count: 2   # Optional multiplier; defaults to 1 if not set\n  links:\n    - source: spine-1\n      target: leaf-1\n      link_params:\n        attrs:\n          hardware:\n            source: {component: \"Optic400G\", count: 4}\n            target: {component: \"Optic400G\", count: 4}\n</code></pre>"},{"location":"reference/dsl/#risk_groups-risk-modeling","title":"<code>risk_groups</code> - Risk Modeling","text":"<p>Define hierarchical failure correlation groups:</p> <pre><code>risk_groups:\n  - name: \"Rack1\"\n    attrs:\n      location: \"DC1_Floor2\"\n    children:\n      - name: \"Card1.1\"\n        children:\n          - name: \"PortGroup1.1.1\"\n      - name: \"Card1.2\"\n  - name: \"PowerSupplyA\"\n    attrs:\n      type: \"power_infrastructure\"\n</code></pre> <p>Nodes and links reference risk groups via <code>risk_groups</code> attribute:</p> <pre><code>network:\n  nodes:\n    server-1:\n      risk_groups: [\"Rack1\"]\n      attrs:\n        hardware:\n          component: \"ServerChassis\"\n</code></pre>"},{"location":"reference/dsl/#vars-yaml-anchors","title":"<code>vars</code> - YAML Anchors","text":"<p>Defines reusable values using YAML anchors (<code>&amp;name</code>) and aliases (<code>*name</code>) for deduplicating complex scenarios:</p> <pre><code>vars:\n  default_cap: &amp;cap 10000\n  base_attrs: &amp;attrs {cost: 100, region: \"dc1\"}\n  spine_config: &amp;spine_cfg\n    hardware:\n      component: \"SpineRouter\"\n      count: 1\n    power_budget: 2500\n\nnetwork:\n  nodes:\n    spine-1: {attrs: {&lt;&lt;: *attrs, &lt;&lt;: *spine_cfg, capacity: *cap}}\n    spine-2: {attrs: {&lt;&lt;: *attrs, &lt;&lt;: *spine_cfg, capacity: *cap, region: \"dc2\"}}\n</code></pre> <p>Anchor Types:</p> <ul> <li>Scalar: <code>&amp;cap 10000</code> - Reference primitive values</li> <li>Mapping: <code>&amp;attrs {cost: 100}</code> - Reference objects</li> <li>Merge: <code>&lt;&lt;: *attrs</code> - Merge properties with override capability</li> </ul> <p>Processing Behavior:</p> <ul> <li>Anchors are resolved during YAML parsing, before schema validation</li> <li>The <code>vars</code> section itself is ignored by NetGraph runtime logic</li> <li>Anchors can be defined in any section, not just <code>vars</code></li> <li>Merge operations follow YAML 1.1 semantics (later keys override earlier ones)</li> </ul>"},{"location":"reference/dsl/#traffic_matrix_set-traffic-analysis","title":"<code>traffic_matrix_set</code> - Traffic Analysis","text":"<p>Define traffic demand patterns for capacity analysis:</p> <pre><code>traffic_matrix_set:\n  production:\n    - name: \"server_to_storage\"\n      source_path: \"^servers/.*\"\n      sink_path: \"^storage/.*\"\n      demand: 1000               # Traffic volume\n      mode: \"combine\"            # Aggregate demand\n      priority: 1\n      flow_policy_config: \"SHORTEST_PATHS_ECMP\"\n\n    - name: \"inter_dc_backup\"\n      source_path: \"^dc1/.*\"\n      sink_path: \"^dc2/.*\"\n      demand: 500\n      mode: \"pairwise\"           # Distributed demand\n      priority: 2\n</code></pre> <p>Traffic Modes:</p> <ul> <li><code>combine</code>: Single aggregate flow between source and sink groups</li> <li><code>pairwise</code>: Individual flows between all source-sink node pairs</li> </ul> <p>Flow Policies:</p> <ul> <li><code>SHORTEST_PATHS_ECMP</code>: Equal-cost multi-path (ECMP) over shortest paths; equal split across paths.</li> <li><code>SHORTEST_PATHS_WCMP</code>: Weighted ECMP (WCMP) over equal-cost shortest paths; weighted split (proportional).</li> <li><code>TE_WCMP_UNLIM</code>: Traffic engineering weighted multipath (WCMP) with capacity-aware selection; unlimited LSPs.</li> <li><code>TE_ECMP_16_LSP</code>: Traffic engineering with 16 ECMP LSPs; equal split across LSPs.</li> <li><code>TE_ECMP_UP_TO_256_LSP</code>: Traffic engineering with up to 256 ECMP LSPs; equal split across LSPs.</li> </ul>"},{"location":"reference/dsl/#failure_policy_set-failure-simulation","title":"<code>failure_policy_set</code> - Failure Simulation","text":"<p>Define failure policies for resilience testing:</p> <pre><code>failure_policy_set:\n  single_link_failure:\n    modes:                       # Weighted modes; exactly one mode fires per iteration\n      - weight: 1.0\n        rules:\n          - entity_scope: \"link\"\n            rule_type: \"choice\"\n            count: 1\n  weighted_modes:                # Example of weighted multi-mode policy\n    modes:\n      - weight: 0.30\n        rules:\n          - entity_scope: \"risk_group\"\n            rule_type: \"choice\"\n            count: 1\n            weight_by: distance_km\n      - weight: 0.35\n        rules:\n          - entity_scope: \"link\"\n            rule_type: \"choice\"\n            count: 3\n            conditions:\n              - attr: link_type\n                operator: \"==\"\n                value: dc_to_pop\n            logic: and\n            weight_by: target_capacity\n      - weight: 0.25\n        rules:\n          - entity_scope: \"node\"\n            rule_type: \"choice\"\n            count: 1\n            conditions:\n              - attr: node_type\n                operator: \"!=\"\n                value: dc_region\n            logic: and\n            weight_by: attached_capacity_gbps\n      - weight: 0.10\n        rules:\n          - entity_scope: \"link\"\n            rule_type: \"choice\"\n            count: 4\n            conditions:\n              - attr: link_type\n                operator: \"==\"\n                value: leaf_spine\n              - attr: link_type\n                operator: \"==\"\n                value: intra_group\n              - attr: link_type\n                operator: \"==\"\n                value: inter_group\n              - attr: link_type\n                operator: \"==\"\n                value: internal_mesh\n            logic: or\n</code></pre> <p>Rule Types:</p> <ul> <li><code>all</code>: Select all matching entities</li> <li><code>choice</code>: Select specific count of entities</li> <li><code>random</code>: Select entities with given probability</li> </ul> <p>Notes:</p> <ul> <li>Policies are mode-based. Each mode has a non-negative <code>weight</code>. One mode is chosen per iteration with probability proportional to weights, then all rules in that mode are applied and their selections are unioned.</li> <li>Each rule has <code>entity_scope</code> (\"node\" | \"link\" | \"risk_group\"), optional <code>logic</code> (\"and\" | \"or\"; defaults to \"or\"), optional <code>conditions</code>, and one of <code>rule_type</code> parameters (<code>count</code> for choice, <code>probability</code> for random). <code>weight_by</code> can be provided for weighted sampling in <code>choice</code> rules.</li> <li>Condition language is the same as used in adjacency <code>match</code> selectors (see below) and supports: <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>contains</code>, <code>not_contains</code>, <code>any_value</code>, <code>no_value</code>. Conditions evaluate on a flat attribute mapping that includes top-level fields and <code>attrs</code>.</li> </ul>"},{"location":"reference/dsl/#workflow-execution-steps","title":"<code>workflow</code> - Execution Steps","text":"<p>Define analysis workflow steps:</p> <pre><code>workflow:\n  - step_type: NetworkStats\n    name: network_statistics\n  - step_type: MaximumSupportedDemand\n    name: msd_baseline\n    matrix_name: baseline_traffic_matrix\n  - step_type: TrafficMatrixPlacement\n    name: tm_placement\n    matrix_name: baseline_traffic_matrix\n    failure_policy: weighted_modes\n    iterations: 1000\n    baseline: true\n</code></pre> <p>Note: Workflow <code>source_path</code> and <code>sink_path</code> accept either regex on node names or <code>attr:&lt;name&gt;</code> directive to group by node attributes (see Node Selection).</p> <p>Common Steps:</p> <ul> <li><code>BuildGraph</code>: Export graph to JSON (node-link) for external analysis</li> <li><code>NetworkStats</code>: Compute basic statistics</li> <li><code>MaxFlow</code>: Monte Carlo capacity analysis between node groups</li> <li><code>TrafficMatrixPlacement</code>: Monte Carlo demand placement for a named matrix</li> <li><code>MaximumSupportedDemand</code>: Search for <code>alpha_star</code> for a named matrix</li> </ul> <p>See Workflow Reference for detailed configuration.</p>"},{"location":"reference/dsl/#node-selection","title":"Node Selection","text":"<p>NetGraph supports two ways to select and group nodes:</p> <ol> <li>Regex on node name (anchored at the start using <code>re.match()</code>)</li> <li>Attribute directive <code>attr:&lt;name&gt;</code> to group by a node attribute</li> </ol> <p>Note: The attribute directive is node-only. It applies only in contexts that select nodes:</p> <ul> <li>Workflow paths: <code>source_path</code> and <code>sink_path</code></li> <li>Adjacency selectors: the <code>path</code> field in <code>source</code>/<code>target</code> selector objects</li> </ul> <p>For links, risk groups, and failure policies, use <code>conditions</code> with an <code>attr</code> field in rules (see Failure Simulation) rather than <code>attr:&lt;name&gt;</code>.</p> <p>Regex Examples:</p> <pre><code># Exact match\npath: \"spine-1\"\n\n# Prefix match\npath: \"dc1/spine/\"\n\n# Wildcard patterns\npath: \"dc1/leaf.*\"\n\n# Anchored patterns\npath: \"^dc1/spine/switch-[1-3]$\"\n\n# Alternation\npath: \"^dc1/(spine|leaf)/.*$\"\n</code></pre> <p>Regex Capturing Groups:</p> <p>Regex capturing groups create node groupings for analysis:</p> <pre><code># Single group: (dc\\d+)\n# Creates groups: \"dc1\", \"dc2\", etc.\n\n# Multiple groups: (dc\\d+)/(spine|leaf)/switch-(\\d+)\n# Creates groups: \"dc1|spine|1\", \"dc1|leaf|2\", etc.\n</code></pre> <p>Group Behavior:</p> <ul> <li>Single capturing group: Group by captured value</li> <li>Multiple capturing groups: Join with <code>|</code> separator</li> <li>No capturing groups: Group by original pattern string</li> </ul>"},{"location":"reference/dsl/#attribute-directive-for-node-selection","title":"Attribute Directive For Node Selection","text":"<p>Write <code>attr:&lt;name&gt;</code> to group nodes by the value of <code>node.attrs[&lt;name&gt;]</code>. Supported contexts in the DSL:</p> <ul> <li>Workflow: <code>source_path</code> and <code>sink_path</code></li> <li>Adjacency selectors: the <code>path</code> in <code>source</code>/<code>target</code> selector objects</li> </ul> <p>Notes:</p> <ul> <li>Blueprint scoping: In blueprints, <code>attr:</code> paths are global and are not   prefixed by the parent blueprint path.</li> <li>Attribute name: <code>name</code> must be a simple identifier (<code>[A-Za-z_]\\w*</code>), and it   refers to a key in <code>node.attrs</code>. Nested keys are not supported here.</li> <li> <p>Non-node entities: For links and risk groups (e.g., in failure policies), use   rule <code>conditions</code> with an <code>attr</code> field instead of <code>attr:&lt;name&gt;</code>.</p> </li> <li> <p>Strict detection: Only a full match of <code>attr:&lt;name&gt;</code> (where <code>&lt;name&gt;</code> matches <code>[A-Za-z_]\\w*</code>) triggers attribute grouping. Everything else is treated as a normal regex.</p> </li> <li>Missing attributes: Nodes without the attribute are omitted.</li> <li>Labels: Group labels are the string form of the attribute value.</li> </ul> <p>Examples:</p> <pre><code>workflow:\n  - step_type: MaxFlow\n    source_path: \"attr:metro\"  # groups by metro attribute\n    sink_path:   \"^metro2/.*\"\n    mode: \"pairwise\"\n</code></pre> <p>Adjacency example using <code>attr:</code>:</p> <pre><code>network:\n  adjacency:\n    - source: { path: \"attr:role\" }\n      target: { path: \"^dc2/leaf/.*\" }\n      pattern: mesh\n</code></pre>"},{"location":"reference/schemas/","title":"JSON Schema Validation","text":"<p>Quick links:</p> <ul> <li>Design \u2014 architecture, model, algorithms, workflow</li> <li>DSL Reference \u2014 YAML syntax for scenario definition</li> <li>Workflow Reference \u2014 analysis workflow configuration and execution</li> <li>CLI Reference \u2014 command-line tools for running scenarios</li> <li>API Reference \u2014 Python API for programmatic scenario creation</li> <li>Auto-Generated API Reference \u2014 complete class and method documentation</li> </ul> <p>NetGraph includes JSON Schema definitions for YAML scenario files, providing IDE validation, autocompletion, and automated testing.</p>"},{"location":"reference/schemas/#schema-location","title":"Schema Location","text":"<p>The schema is packaged with the library at: <code>ngraph/schemas/scenario.json</code>.</p> <p>This file validates NetGraph scenario YAML structure including network topology, blueprints, risk groups, failure policies, traffic matrices, workflows, and components.</p>"},{"location":"reference/schemas/#validation-scope","title":"Validation Scope","text":"<p>The schema validates:</p> <ul> <li>YAML syntax and data types</li> <li>Required fields and property structure</li> <li>Top-level section organization</li> <li>Basic constraint checking</li> </ul> <p>Runtime: The schema is applied unconditionally during load in <code>ngraph.scenario.Scenario.from_yaml</code>. Additional business rules are enforced in code (e.g., blueprint expansion) and may still raise errors for semantically invalid inputs.</p>"},{"location":"reference/schemas/#ide-integration-vs-code","title":"IDE Integration (VS Code)","text":"<p>Automatic configuration via <code>.vscode/settings.json</code>:</p> <pre><code>{\n  \"yaml.schemas\": {\n    \"./ngraph/schemas/scenario.json\": [\n      \"scenarios/**/*.yaml\",\n      \"scenarios/**/*.yml\"\n    ]\n  }\n}\n</code></pre> <p>Provides real-time validation, autocompletion, inline documentation, and error highlighting.</p>"},{"location":"reference/schemas/#automated-validation","title":"Automated Validation","text":""},{"location":"reference/schemas/#development-workflow","title":"Development Workflow","text":"<pre><code># Validate all scenarios\nmake validate\n\n# Full validation and tests\nmake check\n</code></pre>"},{"location":"reference/schemas/#integration-points","title":"Integration Points","text":"<ul> <li>Pre-commit hooks: Validates modified <code>scenarios/*.yaml</code> files</li> <li>CI pipeline: Validates scenarios on push/PR</li> <li>Test suite: Validation exercised in integration tests</li> </ul>"},{"location":"reference/schemas/#python-api","title":"Python API","text":"<pre><code>import json\nimport yaml\nimport jsonschema\n\n# Load and validate\nfrom importlib import resources as res\n\nwith res.files('ngraph.schemas').joinpath('scenario.json').open('r', encoding='utf-8') as f:\n    schema = json.load(f)\n\nwith open('scenarios/square_mesh.yaml') as f:\n    data = yaml.safe_load(f)\n\njsonschema.validate(data, schema)\n</code></pre>"},{"location":"reference/schemas/#schema-structure","title":"Schema Structure","text":"<p>Top-level sections (only these keys allowed):</p> <ul> <li><code>network</code> - Network topology definition</li> <li><code>blueprints</code> - Reusable network templates</li> <li><code>risk_groups</code> - Risk group definitions</li> <li><code>failure_policy_set</code> - Named failure policies</li> <li><code>traffic_matrix_set</code> - Named traffic matrices</li> <li><code>workflow</code> - Workflow step definitions</li> <li><code>components</code> - Hardware component library</li> </ul>"},{"location":"reference/schemas/#schema-maintenance","title":"Schema Maintenance","text":"<p>Update triggers:</p> <ul> <li>New top-level sections added</li> <li>Property types or validation rules change</li> <li>New workflow step types</li> </ul> <p>Update process:</p> <ol> <li>Implement feature in <code>ngraph/scenario.py</code> validation logic</li> <li>Test runtime validation</li> <li>Update JSON Schema to match implementation</li> <li>Run <code>make test</code> to verify schema tests</li> <li>Update documentation</li> </ol> <p>Authority: code implementation in <code>ngraph/scenario.py</code> and <code>ngraph/dsl/blueprints/expand.py</code> is authoritative, not the schema.</p>"},{"location":"reference/workflow/","title":"Workflow Reference","text":"<p>Quick links:</p> <ul> <li>Design \u2014 architecture, model, algorithms, workflow</li> <li>DSL Reference \u2014 YAML syntax for scenario definition</li> <li>CLI Reference \u2014 command-line tools for running scenarios</li> <li>API Reference \u2014 Python API for programmatic scenario creation</li> <li>Auto-Generated API Reference \u2014 complete class and method documentation</li> </ul> <p>This document describes NetGraph workflows \u2013 analysis execution pipelines that perform capacity analysis, demand placement, and statistics computation.</p>"},{"location":"reference/workflow/#overview","title":"Overview","text":"<p>Workflows are ordered steps executed on a scenario. Each step computes a result (e.g., stats, Monte Carlo analysis, export) and writes it under its step name in the results store.</p> <pre><code>workflow:\n  - step_type: NetworkStats\n    name: network_statistics\n  - step_type: MaximumSupportedDemand\n    name: msd_baseline\n    matrix_name: baseline_traffic_matrix\n  - step_type: TrafficMatrixPlacement\n    name: tm_placement\n    matrix_name: baseline_traffic_matrix\n    failure_policy: weighted_modes\n    iterations: 1000\n    baseline: true\n</code></pre>"},{"location":"reference/workflow/#execution-model","title":"Execution Model","text":"<ul> <li>Steps run sequentially via <code>WorkflowStep.execute()</code>, which records timing and metadata and stores outputs under <code>{metadata, data}</code> for the step.</li> <li>Monte Carlo steps (<code>MaxFlow</code>, <code>TrafficMatrixPlacement</code>) execute iterations using the Failure Manager. Each iteration analyzes a <code>NetworkView</code> that masks failed nodes/links without mutating the base network. Workers are controlled by <code>parallelism: auto|int</code>.</li> <li>Seeding: a scenario-level <code>seed</code> derives per-step seeds unless a step sets an explicit <code>seed</code>. Metadata includes <code>scenario_seed</code>, <code>step_seed</code>, <code>seed_source</code>, and <code>active_seed</code>.</li> </ul>"},{"location":"reference/workflow/#core-workflow-steps","title":"Core Workflow Steps","text":""},{"location":"reference/workflow/#buildgraph","title":"BuildGraph","text":"<p>Export the network graph to node-link JSON for external analysis. Optional for other steps.</p> <pre><code>- step_type: BuildGraph\n  name: build_graph\n</code></pre>"},{"location":"reference/workflow/#networkstats","title":"NetworkStats","text":"<p>Compute node, link, and degree metrics. Supports temporary exclusions.</p> <pre><code>- step_type: NetworkStats\n  name: baseline_stats\n</code></pre>"},{"location":"reference/workflow/#maxflow","title":"MaxFlow","text":"<p>Monte Carlo maximum flow analysis between node groups.</p> <pre><code>- step_type: MaxFlow\n  name: capacity_analysis\n  source_path: \"^servers/.*\"\n  sink_path: \"^storage/.*\"\n  mode: \"combine\"              # combine | pairwise\n  failure_policy: random_failures\n  iterations: 1000\n  parallelism: auto             # or an integer\n  baseline: true\n  shortest_path: false\n  flow_placement: PROPORTIONAL  # or EQUAL_BALANCED\n  store_failure_patterns: false\n  include_flow_details: false   # cost_distribution per flow\n  include_min_cut: false        # per-flow min-cut edge list\n</code></pre>"},{"location":"reference/workflow/#trafficmatrixplacement","title":"TrafficMatrixPlacement","text":"<p>Monte Carlo placement of a named traffic matrix with optional alpha scaling.</p> <pre><code>- step_type: TrafficMatrixPlacement\n  name: tm_placement\n  matrix_name: default\n  iterations: 100\n  parallelism: auto\n  baseline: false\n  include_flow_details: true      # cost_distribution per flow\n  include_used_edges: false       # include per-demand used edge lists\n  store_failure_patterns: false\n  # Alpha scaling \u2013 explicit or from another step\n  alpha: 1.0\n  # alpha_from_step: msd_default\n  # alpha_from_field: data.alpha_star\n</code></pre> <p>Outputs:</p> <ul> <li>metadata: iterations, parallelism, baseline, analysis_function, policy_name,   execution_time, unique_patterns</li> <li>data.context: matrix_name, placement_rounds, include_flow_details,   include_used_edges, base_demands, alpha, alpha_source</li> </ul>"},{"location":"reference/workflow/#maximumsupporteddemand","title":"MaximumSupportedDemand","text":"<p>Search for the maximum uniform traffic multiplier <code>alpha_star</code> that is fully placeable.</p> <pre><code>- step_type: MaximumSupportedDemand\n  name: msd_default\n  matrix_name: default\n  acceptance_rule: hard\n  alpha_start: 1.0\n  growth_factor: 2.0\n  resolution: 0.01\n  max_bracket_iters: 32\n  max_bisect_iters: 32\n  seeds_per_alpha: 1\n  placement_rounds: auto\n</code></pre> <p>Outputs:</p> <ul> <li>data.alpha_star: maximum uniform scaling factor</li> <li>data.context: search parameters</li> <li>data.base_demands: serialized base demands prior to scaling</li> <li>data.probes: bracket/bisect evaluations with feasibility and min ratios</li> </ul>"},{"location":"reference/workflow/#costpower","title":"CostPower","text":"<p>Aggregate platform and optics capex/power by hierarchy level (split by <code>/</code>).</p> <pre><code>- step_type: CostPower\n  name: cost_power\n  include_disabled: false\n  aggregation_level: 2\n</code></pre> <p>Outputs:</p> <ul> <li>data.context: include_disabled, aggregation_level</li> <li>data.levels: mapping level-&gt;list of {path, platform_capex, platform_power_watts,   optics_capex, optics_power_watts, capex_total, power_total_watts}</li> </ul>"},{"location":"reference/workflow/#node-selection-mechanism","title":"Node Selection Mechanism","text":"<p>Select nodes by regex on <code>node.name</code> (anchored at start via Python <code>re.match</code>) or by attribute directive <code>attr:&lt;name&gt;</code> which groups nodes by <code>node.attrs[&lt;name&gt;]</code>.</p>"},{"location":"reference/workflow/#basic-pattern-matching","title":"Basic Pattern Matching","text":"<pre><code># Exact match\nsource_path: \"spine-1\"\n\n# Prefix match\nsource_path: \"datacenter/servers/\"\n\n# Pattern match\nsource_path: \"^pod[1-3]/leaf/.*$\"\n</code></pre>"},{"location":"reference/workflow/#capturing-groups-for-node-grouping","title":"Capturing Groups for Node Grouping","text":"<p>No Capturing Groups: All matching nodes form one group labeled by the pattern.</p> <pre><code>source_path: \"edge/.*\"\n# Creates one group: \"edge/.*\" containing all matching nodes\n</code></pre> <p>Single Capturing Group: Each unique captured value creates a separate group.</p> <pre><code>source_path: \"(dc[1-3])/servers/.*\"\n# Creates groups: \"dc1\", \"dc2\", \"dc3\"\n# Each group contains servers from that datacenter\n</code></pre> <p>Multiple Capturing Groups: Group labels join captured values with <code>|</code>.</p> <pre><code>source_path: \"(dc[1-3])/(spine|leaf)/switch-(\\d+)\"\n# Creates groups: \"dc1|spine|1\", \"dc1|leaf|2\", \"dc2|spine|1\", etc.\n</code></pre>"},{"location":"reference/workflow/#attribute-based-grouping","title":"Attribute-based Grouping","text":"<pre><code># Group by node attribute value (e.g., node.attrs[\"dc\"]) \u2014 groups labeled by attribute value\nsource_path: \"attr:dc\"\n</code></pre>"},{"location":"reference/workflow/#flow-analysis-modes","title":"Flow Analysis Modes","text":"<p><code>combine</code> Mode: Aggregates all source matches into one virtual source, all sink matches into one virtual sink. Produces single flow value.</p> <p><code>pairwise</code> Mode: Computes flow between each source group and sink group pair. Produces flow matrix keyed by <code>(source_group, sink_group)</code>.</p>"},{"location":"reference/workflow/#maxflow-parameters","title":"MaxFlow Parameters","text":""},{"location":"reference/workflow/#required-parameters","title":"Required Parameters","text":"<ul> <li><code>source_path</code>: Regex pattern for source node selection</li> <li><code>sink_path</code>: Regex pattern for sink node selection</li> </ul>"},{"location":"reference/workflow/#analysis-configuration","title":"Analysis Configuration","text":"<pre><code>mode: combine                    # combine | pairwise (default: combine)\niterations: 1000                 # Monte Carlo trials (default: 1)\nfailure_policy: policy_name      # Name in failure_policy_set (default: null)\nbaseline: true                   # Include baseline iteration first (default: false)\nparallelism: auto                # Worker processes (default: auto)\nshortest_path: false             # Restrict to shortest paths (default: false)\nflow_placement: PROPORTIONAL     # PROPORTIONAL | EQUAL_BALANCED\nstore_failure_patterns: false    # Store failure patterns in results\ninclude_flow_details: false      # Emit cost_distribution per flow\ninclude_min_cut: false           # Emit min-cut edge list per flow\n</code></pre>"},{"location":"reference/workflow/#results-export-shape","title":"Results Export Shape","text":"<p>Exported results have a fixed top-level structure. Keys under <code>workflow</code> and <code>steps</code> are step names.</p> <pre><code>{\n  \"workflow\": {\n    \"network_statistics\": {\n      \"step_type\": \"NetworkStats\",\n      \"step_name\": \"network_statistics\",\n      \"execution_order\": 0,\n      \"scenario_seed\": 42,\n      \"step_seed\": 42,\n      \"seed_source\": \"scenario-derived\",\n      \"active_seed\": 42\n    }\n  },\n  \"steps\": {\n    \"network_statistics\": {\n      \"metadata\": { \"duration_sec\": 0.012 },\n      \"data\": { \"node_count\": 42, \"link_count\": 84 }\n    },\n    \"msd_baseline\": {\n      \"metadata\": { \"duration_sec\": 1.234 },\n      \"data\": {\n        \"alpha_star\": 1.37,\n        \"context\": { \"matrix_name\": \"baseline_traffic_matrix\" }\n      }\n    },\n    \"tm_placement\": {\n      \"metadata\": { \"iterations\": 1000, \"parallelism\": 8 },\n      \"data\": {\n        \"flow_results\": [\n          {\n            \"failure_id\": \"baseline\",\n            \"failure_state\": null,\n            \"flows\": [],\n            \"summary\": { \"total_demand\": 0.0, \"total_placed\": 0.0, \"overall_ratio\": 1.0, \"dropped_flows\": 0, \"num_flows\": 0 },\n            \"data\": {}\n          }\n        ],\n        \"context\": { \"matrix_name\": \"baseline_traffic_matrix\" }\n      }\n    }\n  },\n  \"scenario\": { \"seed\": 42, \"failure_policy_set\": { }, \"traffic_matrices\": { } }\n}\n</code></pre> <ul> <li><code>MaxFlow</code> and <code>TrafficMatrixPlacement</code> write per-iteration entries under <code>data.flow_results</code>:</li> </ul> <pre><code>{\n  \"flow_results\": [\n    {\n      \"failure_id\": \"baseline\",\n      \"failure_state\": null,\n      \"flows\": [\n        {\n          \"source\": \"A\", \"destination\": \"B\", \"priority\": 0,\n          \"demand\": 10.0, \"placed\": 10.0, \"dropped\": 0.0,\n          \"cost_distribution\": { \"2\": 6.0, \"4\": 4.0 },\n          \"data\": { \"edges\": [\"(u,v,k)\"] }\n        }\n      ],\n      \"summary\": {\n        \"total_demand\": 10.0, \"total_placed\": 10.0,\n        \"overall_ratio\": 1.0, \"dropped_flows\": 0, \"num_flows\": 1\n      },\n      \"data\": { }\n    },\n    { \"failure_id\": \"d0eea3f4d06413a2\", \"failure_state\": null, \"flows\": [],\n      \"summary\": { \"total_demand\": 0.0, \"total_placed\": 0.0, \"overall_ratio\": 1.0, \"dropped_flows\": 0, \"num_flows\": 0 },\n      \"data\": {} }\n  ],\n  \"context\": { ... }\n}\n</code></pre> <p>Notes:</p> <ul> <li>Baseline: when <code>baseline: true</code>, the first entry has <code>failure_id: \"baseline\"</code>.</li> <li><code>failure_state</code> may be <code>null</code> or an object with <code>excluded_nodes</code> and <code>excluded_links</code> lists.</li> <li>Per-iteration <code>data</code> can include instrumentation (e.g., <code>iteration_metrics</code>).</li> <li>Per-flow <code>data</code> can include instrumentation (e.g., <code>policy_metrics</code>).</li> <li><code>cost_distribution</code> uses string keys for JSON stability; values are numeric.</li> <li>Effective <code>parallelism</code> and other execution fields are recorded in step metadata.</li> </ul>"}]}